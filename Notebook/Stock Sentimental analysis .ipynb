{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9236c48c-ebcf-4019-a2be-e3caf01e5de1",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d31f3db1-3563-4609-832d-3e731f1b7fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ed28e918-7012-4bef-89e6-e6018fadc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url='https://raw.githubusercontent.com/Kamalesh1512/datasets/main/stock_sentiment.csv'\n",
    "# reading data\n",
    "df=pd.read_csv(data_url,encoding='latin')\n",
    "\n",
    "#converting to datetime\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "## set data as index\n",
    "df.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4f8b4ca3-3246-4928-95fd-26d5f7d7f374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>Top9</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>Hughes' instant hit buoys Blues</td>\n",
       "      <td>Jack gets his skates on at ice-cold Alex</td>\n",
       "      <td>Chaos as Maracana builds up for United</td>\n",
       "      <td>Depleted Leicester prevail as Elliott spoils E...</td>\n",
       "      <td>Hungry Spurs sense rich pickings</td>\n",
       "      <td>Gunners so wide of an easy target</td>\n",
       "      <td>Derby raise a glass to Strupar's debut double</td>\n",
       "      <td>...</td>\n",
       "      <td>Flintoff injury piles on woe for England</td>\n",
       "      <td>Hunters threaten Jospin with new battle of the...</td>\n",
       "      <td>Kohl's successor drawn into scandal</td>\n",
       "      <td>The difference between men and women</td>\n",
       "      <td>Sara Denver, nurse turned solicitor</td>\n",
       "      <td>Diana's landmine crusade put Tories in a panic</td>\n",
       "      <td>Yeltsin's resignation caught opposition flat-f...</td>\n",
       "      <td>Russian roulette</td>\n",
       "      <td>Sold out</td>\n",
       "      <td>Recovering a title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>The best lake scene</td>\n",
       "      <td>Leader: German sleaze inquiry</td>\n",
       "      <td>Cheerio, boyo</td>\n",
       "      <td>The main recommendations</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Hopkins 'furious' at Foster's lack of Hannibal...</td>\n",
       "      <td>...</td>\n",
       "      <td>On the critical list</td>\n",
       "      <td>The timing of their lives</td>\n",
       "      <td>Dear doctor</td>\n",
       "      <td>Irish court halts IRA man's extradition to Nor...</td>\n",
       "      <td>Burundi peace initiative fades after rebels re...</td>\n",
       "      <td>PE points the way forward to the ECB</td>\n",
       "      <td>Campaigners keep up pressure on Nazi war crime...</td>\n",
       "      <td>Jane Ratcliffe</td>\n",
       "      <td>Yet more things you wouldn't know without the ...</td>\n",
       "      <td>Millennium bug fails to bite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>Coventry caught on counter by Flo</td>\n",
       "      <td>United's rivals on the road to Rio</td>\n",
       "      <td>Thatcher issues defence before trial by video</td>\n",
       "      <td>Police help Smith lay down the law at Everton</td>\n",
       "      <td>Tale of Trautmann bears two more retellings</td>\n",
       "      <td>England on the rack</td>\n",
       "      <td>Pakistan retaliate with call for video of Walsh</td>\n",
       "      <td>Cullinan continues his Cape monopoly</td>\n",
       "      <td>McGrath puts India out of their misery</td>\n",
       "      <td>...</td>\n",
       "      <td>South Melbourne (Australia)</td>\n",
       "      <td>Necaxa (Mexico)</td>\n",
       "      <td>Real Madrid (Spain)</td>\n",
       "      <td>Raja Casablanca (Morocco)</td>\n",
       "      <td>Corinthians (Brazil)</td>\n",
       "      <td>Tony's pet project</td>\n",
       "      <td>Al Nassr (Saudi Arabia)</td>\n",
       "      <td>Ideal Holmes show</td>\n",
       "      <td>Pinochet leaves hospital after tests</td>\n",
       "      <td>Useful links</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>1</td>\n",
       "      <td>Pilgrim knows how to progress</td>\n",
       "      <td>Thatcher facing ban</td>\n",
       "      <td>McIlroy calls for Irish fighting spirit</td>\n",
       "      <td>Leicester bin stadium blueprint</td>\n",
       "      <td>United braced for Mexican wave</td>\n",
       "      <td>Auntie back in fashion, even if the dress look...</td>\n",
       "      <td>Shoaib appeal goes to the top</td>\n",
       "      <td>Hussain hurt by 'shambles' but lays blame on e...</td>\n",
       "      <td>England's decade of disasters</td>\n",
       "      <td>...</td>\n",
       "      <td>Putin admits Yeltsin quit to give him a head s...</td>\n",
       "      <td>BBC worst hit as digital TV begins to bite</td>\n",
       "      <td>How much can you pay for...</td>\n",
       "      <td>Christmas glitches</td>\n",
       "      <td>Upending a table, Chopping a line and Scoring ...</td>\n",
       "      <td>Scientific evidence 'unreliable', defence claims</td>\n",
       "      <td>Fusco wins judicial review in extradition case</td>\n",
       "      <td>Rebels thwart Russian advance</td>\n",
       "      <td>Blair orders shake-up of failing NHS</td>\n",
       "      <td>Lessons of law's hard heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>1</td>\n",
       "      <td>Hitches and Horlocks</td>\n",
       "      <td>Beckham off but United survive</td>\n",
       "      <td>Breast cancer screening</td>\n",
       "      <td>Alan Parker</td>\n",
       "      <td>Guardian readers: are you all whingers?</td>\n",
       "      <td>Hollywood Beyond</td>\n",
       "      <td>Ashes and diamonds</td>\n",
       "      <td>Whingers - a formidable minority</td>\n",
       "      <td>Alan Parker - part two</td>\n",
       "      <td>...</td>\n",
       "      <td>Most everywhere:  UDIs</td>\n",
       "      <td>Most wanted:  Chloe lunettes</td>\n",
       "      <td>Return of the cane 'completely off the agenda'</td>\n",
       "      <td>From Sleepy Hollow to Greeneland</td>\n",
       "      <td>Blunkett outlines vision for over 11s</td>\n",
       "      <td>Embattled Dobson attacks 'play now, pay later'...</td>\n",
       "      <td>Doom and the Dome</td>\n",
       "      <td>What is the north-south divide?</td>\n",
       "      <td>Aitken released from jail</td>\n",
       "      <td>Gone aloft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Label                                               Top1  \\\n",
       "Date                                                                   \n",
       "2000-01-03      0  A 'hindrance to operations': extracts from the...   \n",
       "2000-01-04      0                                          Scorecard   \n",
       "2000-01-05      0                  Coventry caught on counter by Flo   \n",
       "2000-01-06      1                      Pilgrim knows how to progress   \n",
       "2000-01-07      1                               Hitches and Horlocks   \n",
       "\n",
       "                                          Top2  \\\n",
       "Date                                             \n",
       "2000-01-03                           Scorecard   \n",
       "2000-01-04                 The best lake scene   \n",
       "2000-01-05  United's rivals on the road to Rio   \n",
       "2000-01-06                 Thatcher facing ban   \n",
       "2000-01-07      Beckham off but United survive   \n",
       "\n",
       "                                                     Top3  \\\n",
       "Date                                                        \n",
       "2000-01-03                Hughes' instant hit buoys Blues   \n",
       "2000-01-04                  Leader: German sleaze inquiry   \n",
       "2000-01-05  Thatcher issues defence before trial by video   \n",
       "2000-01-06        McIlroy calls for Irish fighting spirit   \n",
       "2000-01-07                        Breast cancer screening   \n",
       "\n",
       "                                                     Top4  \\\n",
       "Date                                                        \n",
       "2000-01-03       Jack gets his skates on at ice-cold Alex   \n",
       "2000-01-04                                  Cheerio, boyo   \n",
       "2000-01-05  Police help Smith lay down the law at Everton   \n",
       "2000-01-06                Leicester bin stadium blueprint   \n",
       "2000-01-07                                    Alan Parker   \n",
       "\n",
       "                                                   Top5  \\\n",
       "Date                                                      \n",
       "2000-01-03       Chaos as Maracana builds up for United   \n",
       "2000-01-04                     The main recommendations   \n",
       "2000-01-05  Tale of Trautmann bears two more retellings   \n",
       "2000-01-06               United braced for Mexican wave   \n",
       "2000-01-07      Guardian readers: are you all whingers?   \n",
       "\n",
       "                                                         Top6  \\\n",
       "Date                                                            \n",
       "2000-01-03  Depleted Leicester prevail as Elliott spoils E...   \n",
       "2000-01-04                             Has Cubie killed fees?   \n",
       "2000-01-05                                England on the rack   \n",
       "2000-01-06  Auntie back in fashion, even if the dress look...   \n",
       "2000-01-07                                   Hollywood Beyond   \n",
       "\n",
       "                                                       Top7  \\\n",
       "Date                                                          \n",
       "2000-01-03                 Hungry Spurs sense rich pickings   \n",
       "2000-01-04                           Has Cubie killed fees?   \n",
       "2000-01-05  Pakistan retaliate with call for video of Walsh   \n",
       "2000-01-06                    Shoaib appeal goes to the top   \n",
       "2000-01-07                               Ashes and diamonds   \n",
       "\n",
       "                                                         Top8  \\\n",
       "Date                                                            \n",
       "2000-01-03                  Gunners so wide of an easy target   \n",
       "2000-01-04                             Has Cubie killed fees?   \n",
       "2000-01-05               Cullinan continues his Cape monopoly   \n",
       "2000-01-06  Hussain hurt by 'shambles' but lays blame on e...   \n",
       "2000-01-07                   Whingers - a formidable minority   \n",
       "\n",
       "                                                         Top9  ...  \\\n",
       "Date                                                           ...   \n",
       "2000-01-03      Derby raise a glass to Strupar's debut double  ...   \n",
       "2000-01-04  Hopkins 'furious' at Foster's lack of Hannibal...  ...   \n",
       "2000-01-05             McGrath puts India out of their misery  ...   \n",
       "2000-01-06                      England's decade of disasters  ...   \n",
       "2000-01-07                             Alan Parker - part two  ...   \n",
       "\n",
       "                                                        Top16  \\\n",
       "Date                                                            \n",
       "2000-01-03           Flintoff injury piles on woe for England   \n",
       "2000-01-04                               On the critical list   \n",
       "2000-01-05                        South Melbourne (Australia)   \n",
       "2000-01-06  Putin admits Yeltsin quit to give him a head s...   \n",
       "2000-01-07                             Most everywhere:  UDIs   \n",
       "\n",
       "                                                        Top17  \\\n",
       "Date                                                            \n",
       "2000-01-03  Hunters threaten Jospin with new battle of the...   \n",
       "2000-01-04                          The timing of their lives   \n",
       "2000-01-05                                    Necaxa (Mexico)   \n",
       "2000-01-06         BBC worst hit as digital TV begins to bite   \n",
       "2000-01-07                       Most wanted:  Chloe lunettes   \n",
       "\n",
       "                                                     Top18  \\\n",
       "Date                                                         \n",
       "2000-01-03             Kohl's successor drawn into scandal   \n",
       "2000-01-04                                     Dear doctor   \n",
       "2000-01-05                             Real Madrid (Spain)   \n",
       "2000-01-06                     How much can you pay for...   \n",
       "2000-01-07  Return of the cane 'completely off the agenda'   \n",
       "\n",
       "                                                        Top19  \\\n",
       "Date                                                            \n",
       "2000-01-03               The difference between men and women   \n",
       "2000-01-04  Irish court halts IRA man's extradition to Nor...   \n",
       "2000-01-05                          Raja Casablanca (Morocco)   \n",
       "2000-01-06                                 Christmas glitches   \n",
       "2000-01-07                   From Sleepy Hollow to Greeneland   \n",
       "\n",
       "                                                        Top20  \\\n",
       "Date                                                            \n",
       "2000-01-03                Sara Denver, nurse turned solicitor   \n",
       "2000-01-04  Burundi peace initiative fades after rebels re...   \n",
       "2000-01-05                               Corinthians (Brazil)   \n",
       "2000-01-06  Upending a table, Chopping a line and Scoring ...   \n",
       "2000-01-07              Blunkett outlines vision for over 11s   \n",
       "\n",
       "                                                        Top21  \\\n",
       "Date                                                            \n",
       "2000-01-03     Diana's landmine crusade put Tories in a panic   \n",
       "2000-01-04               PE points the way forward to the ECB   \n",
       "2000-01-05                                 Tony's pet project   \n",
       "2000-01-06   Scientific evidence 'unreliable', defence claims   \n",
       "2000-01-07  Embattled Dobson attacks 'play now, pay later'...   \n",
       "\n",
       "                                                        Top22  \\\n",
       "Date                                                            \n",
       "2000-01-03  Yeltsin's resignation caught opposition flat-f...   \n",
       "2000-01-04  Campaigners keep up pressure on Nazi war crime...   \n",
       "2000-01-05                            Al Nassr (Saudi Arabia)   \n",
       "2000-01-06     Fusco wins judicial review in extradition case   \n",
       "2000-01-07                                  Doom and the Dome   \n",
       "\n",
       "                                      Top23  \\\n",
       "Date                                          \n",
       "2000-01-03                 Russian roulette   \n",
       "2000-01-04                   Jane Ratcliffe   \n",
       "2000-01-05                Ideal Holmes show   \n",
       "2000-01-06    Rebels thwart Russian advance   \n",
       "2000-01-07  What is the north-south divide?   \n",
       "\n",
       "                                                        Top24  \\\n",
       "Date                                                            \n",
       "2000-01-03                                           Sold out   \n",
       "2000-01-04  Yet more things you wouldn't know without the ...   \n",
       "2000-01-05               Pinochet leaves hospital after tests   \n",
       "2000-01-06               Blair orders shake-up of failing NHS   \n",
       "2000-01-07                          Aitken released from jail   \n",
       "\n",
       "                                   Top25  \n",
       "Date                                      \n",
       "2000-01-03            Recovering a title  \n",
       "2000-01-04  Millennium bug fails to bite  \n",
       "2000-01-05                  Useful links  \n",
       "2000-01-06   Lessons of law's hard heart  \n",
       "2000-01-07                    Gone aloft  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f3852e90-b9b9-487b-b506-a514d35edac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4101, 26)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3941e8c1-00b0-4279-b86e-aab90fcd3eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4101 entries, 2000-01-03 to 2016-07-01\n",
      "Data columns (total 26 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Label   4101 non-null   int64 \n",
      " 1   Top1    4101 non-null   object\n",
      " 2   Top2    4101 non-null   object\n",
      " 3   Top3    4101 non-null   object\n",
      " 4   Top4    4101 non-null   object\n",
      " 5   Top5    4101 non-null   object\n",
      " 6   Top6    4101 non-null   object\n",
      " 7   Top7    4101 non-null   object\n",
      " 8   Top8    4101 non-null   object\n",
      " 9   Top9    4101 non-null   object\n",
      " 10  Top10   4101 non-null   object\n",
      " 11  Top11   4101 non-null   object\n",
      " 12  Top12   4101 non-null   object\n",
      " 13  Top13   4101 non-null   object\n",
      " 14  Top14   4101 non-null   object\n",
      " 15  Top15   4101 non-null   object\n",
      " 16  Top16   4101 non-null   object\n",
      " 17  Top17   4101 non-null   object\n",
      " 18  Top18   4101 non-null   object\n",
      " 19  Top19   4101 non-null   object\n",
      " 20  Top20   4101 non-null   object\n",
      " 21  Top21   4101 non-null   object\n",
      " 22  Top22   4101 non-null   object\n",
      " 23  Top23   4100 non-null   object\n",
      " 24  Top24   4098 non-null   object\n",
      " 25  Top25   4098 non-null   object\n",
      "dtypes: int64(1), object(25)\n",
      "memory usage: 865.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0cdfcc26-6221-4f3b-9d63-75da5236b70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label    0\n",
       "Top1     0\n",
       "Top2     0\n",
       "Top3     0\n",
       "Top4     0\n",
       "Top5     0\n",
       "Top6     0\n",
       "Top7     0\n",
       "Top8     0\n",
       "Top9     0\n",
       "Top10    0\n",
       "Top11    0\n",
       "Top12    0\n",
       "Top13    0\n",
       "Top14    0\n",
       "Top15    0\n",
       "Top16    0\n",
       "Top17    0\n",
       "Top18    0\n",
       "Top19    0\n",
       "Top20    0\n",
       "Top21    0\n",
       "Top22    0\n",
       "Top23    1\n",
       "Top24    3\n",
       "Top25    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "885f2f63-1527-41b4-8918-fc522f6376c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label    0\n",
      "Top1     0\n",
      "Top2     0\n",
      "Top3     0\n",
      "Top4     0\n",
      "Top5     0\n",
      "Top6     0\n",
      "Top7     0\n",
      "Top8     0\n",
      "Top9     0\n",
      "Top10    0\n",
      "Top11    0\n",
      "Top12    0\n",
      "Top13    0\n",
      "Top14    0\n",
      "Top15    0\n",
      "Top16    0\n",
      "Top17    0\n",
      "Top18    0\n",
      "Top19    0\n",
      "Top20    0\n",
      "Top21    0\n",
      "Top22    0\n",
      "Top23    0\n",
      "Top24    0\n",
      "Top25    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def handle_missing_data(df):\n",
    "    if (df.isna().sum().any())>0:\n",
    "        percent=(df.isnull().sum()/df.shape[0])*100\n",
    "        if (percent.any()<15) | (percent.any()>75):\n",
    "            df.dropna(inplace=True)\n",
    "        else:\n",
    "            df.fillna(method='bfill',inplace=True)\n",
    "    print(df.isnull().sum())\n",
    "handle_missing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "de927095-061a-4b2e-9f9e-ecdff6a1b22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# checking for duplicate data\n",
    "def handle_duplicate(data):\n",
    "    if data.duplicated().sum()>0:\n",
    "        data.drop_duplicates(inplace=True)\n",
    "    print(data.duplicated().sum())\n",
    "handle_duplicate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d940a5b0-b06c-400f-a1c7-53531a12c0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### combine text columns into one\n",
    "def combine_cols(data,columns):\n",
    "    data['Text']=data[columns].agg(' '.join,axis=1)\n",
    "    return data['Text']\n",
    "df['Text']=combine_cols(df,df.columns[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc903293-ecf2-4a9f-b4ee-8a36648d7cf3",
   "metadata": {},
   "source": [
    "## Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "5742397e-d455-44ed-86bc-7a3ea5137dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0</td>\n",
       "      <td>Scorecard The best lake scene Leader: German s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>Coventry caught on counter by Flo United's riv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>1</td>\n",
       "      <td>Pilgrim knows how to progress Thatcher facing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>1</td>\n",
       "      <td>Hitches and Horlocks Beckham off but United su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Label                                               Text\n",
       "Date                                                                \n",
       "2000-01-03      0  A 'hindrance to operations': extracts from the...\n",
       "2000-01-04      0  Scorecard The best lake scene Leader: German s...\n",
       "2000-01-05      0  Coventry caught on counter by Flo United's riv...\n",
       "2000-01-06      1  Pilgrim knows how to progress Thatcher facing ...\n",
       "2000-01-07      1  Hitches and Horlocks Beckham off but United su..."
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df[['Label','Text']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "eb363335-f3eb-4405-8441-3f93dae4e017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4098 entries, 2000-01-03 to 2016-07-01\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Label   4098 non-null   int64 \n",
      " 1   Text    4098 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 96.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7f0e8703-76b3-4a40-a8a0-38f41588ecb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    52.781845\n",
       "0    47.218155\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking for imbalance in the dataset\n",
    "100*(data['Label'].value_counts()/data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a761bcb3-d60e-4d22-a540-000a4248461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Text Lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Noise Removal / Punctuations removal\n",
    "    tokens = [re.sub(r\"[^a-zA-Z0-9]\", \"\", token.strip()) for token in tokens]\n",
    "\n",
    "    # Stopword Removal\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    ## Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "1d5442fa-00a0-40d3-8e81-757877d9a831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAMALESH M\\AppData\\Local\\Temp\\ipykernel_36180\\2533511564.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Preprocessed_text']=data['Text'].apply(preprocess)\n"
     ]
    }
   ],
   "source": [
    "data['Preprocessed_text']=data['Text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0714d29c-f719-4407-8bc2-35beddaf7ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>Preprocessed_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "      <td>hindrance operation   extract leaked report sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>0</td>\n",
       "      <td>Scorecard The best lake scene Leader: German s...</td>\n",
       "      <td>scorecard best lake scene leader  german sleaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>Coventry caught on counter by Flo United's riv...</td>\n",
       "      <td>coventry caught counter flo united rival road ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>1</td>\n",
       "      <td>Pilgrim knows how to progress Thatcher facing ...</td>\n",
       "      <td>pilgrim know progress thatcher facing ban mcil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>1</td>\n",
       "      <td>Hitches and Horlocks Beckham off but United su...</td>\n",
       "      <td>hitch horlocks beckham united survive breast c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Label                                               Text  \\\n",
       "Date                                                                   \n",
       "2000-01-03      0  A 'hindrance to operations': extracts from the...   \n",
       "2000-01-04      0  Scorecard The best lake scene Leader: German s...   \n",
       "2000-01-05      0  Coventry caught on counter by Flo United's riv...   \n",
       "2000-01-06      1  Pilgrim knows how to progress Thatcher facing ...   \n",
       "2000-01-07      1  Hitches and Horlocks Beckham off but United su...   \n",
       "\n",
       "                                            Preprocessed_text  \n",
       "Date                                                           \n",
       "2000-01-03  hindrance operation   extract leaked report sc...  \n",
       "2000-01-04  scorecard best lake scene leader  german sleaz...  \n",
       "2000-01-05  coventry caught counter flo united rival road ...  \n",
       "2000-01-06  pilgrim know progress thatcher facing ban mcil...  \n",
       "2000-01-07  hitch horlocks beckham united survive breast c...  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "17a99642-8ee9-4b1a-8e52-312b8839f1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Accuracy of training data: 0.96\n",
      "\n",
      "Logistic Regression Accuracy of testing data: 0.52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.27      0.34       476\n",
      "           1       0.54      0.74      0.62       549\n",
      "\n",
      "    accuracy                           0.52      1025\n",
      "   macro avg       0.51      0.50      0.48      1025\n",
      "weighted avg       0.51      0.52      0.49      1025\n",
      "\n",
      "\n",
      "Naive Bayes Accuracy of training data: 0.76\n",
      "\n",
      "Naive Bayes Accuracy of testing data: 0.54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       476\n",
      "           1       0.54      1.00      0.70       549\n",
      "\n",
      "    accuracy                           0.54      1025\n",
      "   macro avg       0.27      0.50      0.35      1025\n",
      "weighted avg       0.29      0.54      0.37      1025\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAMALESH M\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\KAMALESH M\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\KAMALESH M\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Accuracy of training data: 1.00\n",
      "\n",
      "SVM Accuracy of testing data: 0.53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.07      0.13       476\n",
      "           1       0.53      0.92      0.67       549\n",
      "\n",
      "    accuracy                           0.53      1025\n",
      "   macro avg       0.49      0.50      0.40      1025\n",
      "weighted avg       0.49      0.53      0.42      1025\n",
      "\n",
      "\n",
      "Random Forest Accuracy of training data: 1.00\n",
      "\n",
      "Random Forest Accuracy of testing data: 0.51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.33      0.39       476\n",
      "           1       0.53      0.66      0.59       549\n",
      "\n",
      "    accuracy                           0.51      1025\n",
      "   macro avg       0.50      0.50      0.49      1025\n",
      "weighted avg       0.50      0.51      0.50      1025\n",
      "\n",
      "\n",
      "Gradient Boosting Accuracy of training data: 0.83\n",
      "\n",
      "Gradient Boosting Accuracy of testing data: 0.50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.29      0.35       476\n",
      "           1       0.53      0.69      0.60       549\n",
      "\n",
      "    accuracy                           0.50      1025\n",
      "   macro avg       0.48      0.49      0.47      1025\n",
      "weighted avg       0.49      0.50      0.48      1025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a DataFrame df with columns 'text' and 'label'\n",
    "train_size=int(len(data)*0.75)\n",
    "train_data=data.iloc[:train_size]\n",
    "test_data=data.iloc[train_size:]\n",
    "\n",
    "#training data\n",
    "X_train=train_data['Preprocessed_text']\n",
    "y_train=train_data['Label']\n",
    "# testing data\n",
    "X_test=test_data['Preprocessed_text']\n",
    "y_test=test_data['Label']\n",
    "\n",
    "# Preprocess the text (use the preprocess_text function from the previous code snippet)\n",
    "X_train_preprocessed = [' '.join(preprocess_text(text)) for text in X_train]\n",
    "X_test_preprocessed = [' '.join(preprocess_text(text)) for text in X_test]\n",
    "\n",
    "# Convert text to numerical features using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_preprocessed)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_preprocessed)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'SVM': SVC(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    y_pred_train = model.predict(X_train_tfidf)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    print(f'\\n{model_name} Accuracy of training data: {train_accuracy:.2f}')\n",
    "    \n",
    "    y_pred_test = model.predict(X_test_tfidf)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    print(f'\\n{model_name} Accuracy of testing data: {test_accuracy:.2f}')\n",
    "    \n",
    "    # Display classification report\n",
    "    print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "cdf7e807-26a5-4fc9-b4c1-ab53523e191f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af7f30a-df56-4fe6-ab1d-55ce846ad090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "edb71f76-61a4-4619-935a-3ad7a92d5027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc1bae1-c84b-479c-ae12-d88e954e9f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812d66f-a0ff-4f11-8b70-9cb14b5371a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b70167-8470-48e9-851d-d4a8866f6fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3baa3d0-c1ba-464c-aba2-c3feedfad87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48533468-d241-4e58-a85b-75875dda048c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dfad5a-dd7e-4b3a-a281-cb851bb738d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0dea6e-1b24-4c06-a7ab-8cb200c35c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
