{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "### please check out the Final Code section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from datetime import timedelta,datetime\n",
    "import yfinance as yf\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from keras import layers,Sequential\n",
    "from keras.layers import SimpleRNN,LSTM,Dense,Dropout,Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url='https://raw.githubusercontent.com/Kamalesh1512/datasets/main/VOLTAS.NS.csv'\n",
    "\n",
    "def read_data(url):\n",
    "    df=pd.read_csv(url,index_col='Date')\n",
    "    print(\"shape of the dataset\",df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset (2468, 6)\n"
     ]
    }
   ],
   "source": [
    "df=read_data(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-10</th>\n",
       "      <td>118.099998</td>\n",
       "      <td>124.699997</td>\n",
       "      <td>114.800003</td>\n",
       "      <td>123.699997</td>\n",
       "      <td>114.717346</td>\n",
       "      <td>6406819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-11</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>123.699997</td>\n",
       "      <td>114.400002</td>\n",
       "      <td>117.550003</td>\n",
       "      <td>109.013939</td>\n",
       "      <td>6545655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-12</th>\n",
       "      <td>117.000000</td>\n",
       "      <td>119.199997</td>\n",
       "      <td>114.050003</td>\n",
       "      <td>117.250000</td>\n",
       "      <td>108.735733</td>\n",
       "      <td>5385410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-13</th>\n",
       "      <td>115.949997</td>\n",
       "      <td>116.699997</td>\n",
       "      <td>112.599998</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>105.258041</td>\n",
       "      <td>3445000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-16</th>\n",
       "      <td>113.400002</td>\n",
       "      <td>115.750000</td>\n",
       "      <td>112.849998</td>\n",
       "      <td>114.650002</td>\n",
       "      <td>106.324524</td>\n",
       "      <td>1992818.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2013-12-10  118.099998  124.699997  114.800003  123.699997  114.717346   \n",
       "2013-12-11  123.000000  123.699997  114.400002  117.550003  109.013939   \n",
       "2013-12-12  117.000000  119.199997  114.050003  117.250000  108.735733   \n",
       "2013-12-13  115.949997  116.699997  112.599998  113.500000  105.258041   \n",
       "2013-12-16  113.400002  115.750000  112.849998  114.650002  106.324524   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2013-12-10  6406819.0  \n",
       "2013-12-11  6545655.0  \n",
       "2013-12-12  5385410.0  \n",
       "2013-12-13  3445000.0  \n",
       "2013-12-16  1992818.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-04</th>\n",
       "      <td>844.000000</td>\n",
       "      <td>848.450012</td>\n",
       "      <td>830.549988</td>\n",
       "      <td>837.849976</td>\n",
       "      <td>837.849976</td>\n",
       "      <td>995617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-05</th>\n",
       "      <td>841.900024</td>\n",
       "      <td>846.950012</td>\n",
       "      <td>825.400024</td>\n",
       "      <td>832.500000</td>\n",
       "      <td>832.500000</td>\n",
       "      <td>1388896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-06</th>\n",
       "      <td>839.000000</td>\n",
       "      <td>849.900024</td>\n",
       "      <td>833.700012</td>\n",
       "      <td>845.049988</td>\n",
       "      <td>845.049988</td>\n",
       "      <td>1717573.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>845.549988</td>\n",
       "      <td>869.950012</td>\n",
       "      <td>833.099976</td>\n",
       "      <td>866.049988</td>\n",
       "      <td>866.049988</td>\n",
       "      <td>2356938.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>872.000000</td>\n",
       "      <td>878.599976</td>\n",
       "      <td>844.849976</td>\n",
       "      <td>855.450012</td>\n",
       "      <td>855.450012</td>\n",
       "      <td>2817604.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2023-12-04  844.000000  848.450012  830.549988  837.849976  837.849976   \n",
       "2023-12-05  841.900024  846.950012  825.400024  832.500000  832.500000   \n",
       "2023-12-06  839.000000  849.900024  833.700012  845.049988  845.049988   \n",
       "2023-12-07  845.549988  869.950012  833.099976  866.049988  866.049988   \n",
       "2023-12-08  872.000000  878.599976  844.849976  855.450012  855.450012   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2023-12-04   995617.0  \n",
       "2023-12-05  1388896.0  \n",
       "2023-12-06  1717573.0  \n",
       "2023-12-07  2356938.0  \n",
       "2023-12-08  2817604.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2468 entries, 2013-12-10 to 2023-12-08\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       2466 non-null   float64\n",
      " 1   High       2466 non-null   float64\n",
      " 2   Low        2466 non-null   float64\n",
      " 3   Close      2466 non-null   float64\n",
      " 4   Adj Close  2466 non-null   float64\n",
      " 5   Volume     2466 non-null   float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 135.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open         2\n",
       "High         2\n",
       "Low          2\n",
       "Close        2\n",
       "Adj Close    2\n",
       "Volume       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking for missing vaules\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking for duplicate record\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_duplicates(dataset):\n",
    "    if dataset.duplicated().sum()>0:\n",
    "        dataset.drop_duplicates(inplace=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=handle_duplicates(df)\n",
    "\n",
    "## rechecking \n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr=df.corr(numeric_only=True)\n",
    "sns.heatmap(corr,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fg, ax =plt.subplots(1,2,figsize=(20,7))\n",
    "ax[0].plot(df['Open'],label='Open',color='green')\n",
    "ax[0].set_xlabel('Date',size=15)\n",
    "ax[0].set_ylabel('Price',size=15)\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(df['Close'],label='Close',color='red')\n",
    "ax[1].set_xlabel('Date',size=15)\n",
    "ax[1].set_ylabel('Price',size=15)\n",
    "ax[1].legend()\n",
    "\n",
    "fg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"border: 3px solid #f0ad4e; background-color: #fcf8e3; padding: 10px;\">\n",
    "<p>\n",
    "    <font color = black><b>Observations :</b></font>\n",
    "</p>\n",
    "<font color = black>\n",
    "1.The heatmap plot provides a visual representation of the correlation between different features in the dataset.There is a strong correlation between the features [Open,Close,high,Low,Adj Close]because all the representing the Stock Price for the Day/Date.\n",
    "\n",
    "2.There is no missing values or duplicate records in the dataset.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"border: 3px solid #f0ad4e; background-color: #\t#355E3B; padding: 10px;\">\n",
    "<font color = black><b>Feature Selection:</b></font>\n",
    "<font color = black>\n",
    "    I'm Going to make use of only <b>\"Open\"</b> and <b>\"Close\"</b> columns because im trying to predict the opening price of the next day of market(whether the price is up or down)\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-10</th>\n",
       "      <td>118.099998</td>\n",
       "      <td>123.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-11</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>117.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-12</th>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-13</th>\n",
       "      <td>115.949997</td>\n",
       "      <td>113.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-16</th>\n",
       "      <td>113.400002</td>\n",
       "      <td>114.650002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open       Close\n",
       "Date                              \n",
       "2013-12-10  118.099998  123.699997\n",
       "2013-12-11  123.000000  117.550003\n",
       "2013-12-12  117.000000  117.250000\n",
       "2013-12-13  115.949997  113.500000\n",
       "2013-12-16  113.400002  114.650002"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature/columns Selection\n",
    "data=df[['Open','Close']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[583], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m scaler\u001b[38;5;241m=\u001b[39mMinMaxScaler()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "scaler=MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data=data.copy()\n",
    "scaled_data[data.columns]=scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-10</th>\n",
       "      <td>0.016250</td>\n",
       "      <td>0.019861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-11</th>\n",
       "      <td>0.020173</td>\n",
       "      <td>0.014896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-12</th>\n",
       "      <td>0.015370</td>\n",
       "      <td>0.014654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-13</th>\n",
       "      <td>0.014529</td>\n",
       "      <td>0.011626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-16</th>\n",
       "      <td>0.012488</td>\n",
       "      <td>0.012555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-04</th>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.596440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-05</th>\n",
       "      <td>0.595661</td>\n",
       "      <td>0.592120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-06</th>\n",
       "      <td>0.593340</td>\n",
       "      <td>0.602253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>0.598583</td>\n",
       "      <td>0.619207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>0.619757</td>\n",
       "      <td>0.610649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2466 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open     Close\n",
       "Date                          \n",
       "2013-12-10  0.016250  0.019861\n",
       "2013-12-11  0.020173  0.014896\n",
       "2013-12-12  0.015370  0.014654\n",
       "2013-12-13  0.014529  0.011626\n",
       "2013-12-16  0.012488  0.012555\n",
       "...              ...       ...\n",
       "2023-12-04  0.597342  0.596440\n",
       "2023-12-05  0.595661  0.592120\n",
       "2023-12-06  0.593340  0.602253\n",
       "2023-12-07  0.598583  0.619207\n",
       "2023-12-08  0.619757  0.610649\n",
       "\n",
       "[2466 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2466, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training data (1726, 2)\n",
      "Length of Testing data (370, 2)\n",
      "Length of Validation data (370, 2)\n"
     ]
    }
   ],
   "source": [
    "## splitting the dataset into 70% , 15% and 15%\n",
    "training_size=int(len(scaled_data)*0.70)\n",
    "test_size=int(len(scaled_data.iloc[training_size:])*0.50)+training_size\n",
    "\n",
    "train_data,test_data,val_data=scaled_data.iloc[:training_size,:],scaled_data.iloc[training_size:test_size,:],scaled_data.iloc[test_size:,:]\n",
    "print(\"Length of Training data\",train_data.shape)\n",
    "print(\"Length of Testing data\",test_data.shape)\n",
    "print(\"Length of Validation data\",val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the sequence of features and labels for training the model\n",
    "def create_data(dataset,n=1):\n",
    "    features=[]\n",
    "    targets=[]\n",
    "    start_idx=0\n",
    "    for stop_idx in range(n,len(dataset)):\n",
    "        features.append(dataset.iloc[start_idx:stop_idx])\n",
    "        targets.append(dataset.iloc[stop_idx])\n",
    "        start_idx +=1\n",
    "    return (np.array(features),np.array(targets))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=create_data(train_data,50)\n",
    "X_test,y_test=create_data(test_data,50)\n",
    "X_val,y_val=create_data(val_data,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train and y_train (1676, 50, 2) (1676, 2)\n",
      "Shape of X_test and y_test (320, 50, 2) (320, 2)\n",
      "shape of X_val and y_val (320, 50, 2) (320, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train and y_train\",X_train.shape,y_train.shape)\n",
    "print(\"Shape of X_test and y_test\",X_test.shape,y_test.shape)\n",
    "print(\"shape of X_val and y_val\",X_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm=Sequential()\n",
    "# lstm.add(LSTM(units=50,return_sequences=True,activation='relu',\n",
    "#               input_shape=(X_train.shape[1],X_train.shape[-1])))\n",
    "# lstm.add(Dropout(0.2))\n",
    "# lstm.add(LSTM(units=50))\n",
    "# lstm.add(Dense(units=2))\n",
    "# lstm.compile(optimizer='adam',loss='mean_squared_error',metrics=['mean_squared_error'])\n",
    "# lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm.fit(X_train,y_train,epochs=100,batch_size=32,validation_data=(X_val,y_val),verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM - Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Building the model\n",
    "# lstm_b = Sequential()\n",
    "\n",
    "# # Adding a Bidirectional LSTM layer\n",
    "# lstm_b.add(Bidirectional(LSTM(64, return_sequences=True, activation='relu'), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# lstm_b.add(Dropout(0.2))\n",
    "\n",
    "# # Adding another Bidirectional LSTM layer\n",
    "# lstm_b.add(Bidirectional(LSTM(64, activation='relu')))\n",
    "# lstm_b.add(Dropout(0.2))\n",
    "\n",
    "# # Adding a Dense layer with appropriate activation for classification\n",
    "# lstm_b.add(Dense(32, activation='relu'))\n",
    "# lstm_b.add(Dropout(0.2))\n",
    "\n",
    "# # Output layer with appropriate activation\n",
    "# lstm_b.add(Dense(2))\n",
    "# # Compile the model\n",
    "# lstm_b.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), \n",
    "#                loss='mean_absolute_error', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the summary to check the architecture\n",
    "# lstm_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history=lstm_b.fit(X_train,y_train,epochs=75,batch_size=16,validation_data=(X_val,y_val),verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "<div class=\"alert alert-block alert-warning\" style=\"border: 3px solid #f0ad4e; background-color: #fcf8e3; padding: 10px;\">\n",
    "<p>\n",
    "    <font color = black><b>Evaluation Metrics</b></font>\n",
    "</p>\n",
    "<font color = black>\n",
    "1.We can calculate the Percentage Accuracy for our regression model using the formula.\n",
    "\n",
    "2.Percentage Accuracy = $(100 \\times (1 - \\frac{\\text{MAE}}{\\text{Mean of the Actual Values}})$\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_evaluate(model_type,X_train,X_test,y_train,y_test,metrics=mean_absolute_error):\n",
    "#     if model_type=='lstm':\n",
    "#         train_y_pred=lstm.predict(X_train)\n",
    "#         test_y_pred=lstm.predict(X_test)\n",
    "#     elif model_type=='lstm_b':\n",
    "#         train_y_pred=lstm_b.predict(X_train)\n",
    "#         test_y_pred=lstm_b.predict(X_test)\n",
    "#     elif model_type=='best_model':\n",
    "#         train_y_pred=best_model.predict(X_train)\n",
    "#         test_y_pred=best_model.predict(X_test)\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid model type. Please choose 'lstm', 'lstm_b', or 'best_model'.\")\n",
    "    \n",
    "#     train_loss=metrics(y_train,train_y_pred)\n",
    "#     test_loss=metrics(y_test,test_y_pred)\n",
    "    \n",
    "#     print(\"Accuracy of Training Data\",100*(1-(train_loss/np.mean(y_train))))\n",
    "#     print(\"Accuarcy of Testing Data\",100*(1-(test_loss/np.mean(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 19ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "Accuracy of Training Data 95.63691573746955\n",
      "Accuarcy of Testing Data 92.22894082646846\n"
     ]
    }
   ],
   "source": [
    "# model_evaluate(model_type='lstm_b',metrics=mean_absolute_error,\n",
    "#                X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_error_graph(history):\n",
    "#     err= history.history['mean_squared_error']\n",
    "#     val_err = history.history['val_mean_squared_error']\n",
    "    \n",
    "#     loss = history.history['loss']\n",
    "#     val_loss = history.history['val_loss']\n",
    "    \n",
    "#     epochs_range = range(100)\n",
    "    \n",
    "#     plt.figure(figsize=(15,6))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(epochs_range, err, label='Training mean_absolute_error')\n",
    "#     plt.plot(epochs_range, val_err, label='Validation mean_absolute_error')\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.title('Training and Validation mean_absolute_error')\n",
    "    \n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(epochs_range, loss, label='Training Loss')\n",
    "#     plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "#     plt.legend(loc='upper right')\n",
    "#     plt.title('Training and Validation Loss')\n",
    "#     plt.show()\n",
    "# # plot_error_graph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"border: 3px solid #f0ad4e; background-color: #fcf8e3; padding: 10px;\">\n",
    "<font color = black><b>Observations:</b></font>\n",
    "<font color = black>\n",
    "    Comparing the Performance of each model based on <b>mean_absolute_error</b> Bidirectional_LSTM has given results better performance than LSTM. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# # Define the model-building function for Keras Tuner\n",
    "# def build_model(hp):\n",
    "#     model = keras.Sequential()\n",
    "\n",
    "#     # Adding a Bidirectional LSTM layer with return_sequences=True for stacking multiple layers\n",
    "#     model.add(layers.Bidirectional(\n",
    "#         layers.LSTM(\n",
    "#             units=hp.Int('units_1', min_value=32, max_value=128, step=32),\n",
    "#             activation='relu',\n",
    "#             return_sequences=True),\n",
    "#         input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "#     model.add(layers.Dropout(hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "#     # Adding another Bidirectional LSTM layer\n",
    "#     model.add(layers.Bidirectional(\n",
    "#         layers.LSTM(\n",
    "#             units=hp.Int('units_2', min_value=32, max_value=128, step=32),\n",
    "#             activation='relu')),\n",
    "#     )\n",
    "#     model.add(layers.Dropout(hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "#     # Adding a Dense output layer with linear activation for regression\n",
    "#     model.add(layers.Dense(2, activation='linear'))\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "#                   loss='mean_absolute_error',metrics=['mean_absolute_error'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# # Instantiate the tuner and perform random search\n",
    "# tuner = RandomSearch(\n",
    "#     build_model,\n",
    "#     objective='val_loss',\n",
    "#     max_trials=5, \n",
    "#     executions_per_trial=1,)\n",
    "\n",
    "# stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# # Search for the best hyperparameters\n",
    "# tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val),callbacks=[stop_early])\n",
    "\n",
    "# # # Get the best model\n",
    "# best_model = tuner.get_best_models(num_models=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "# best_hps.get('units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Summary of the best model\n",
    "# best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history=best_model.fit(X_train,y_train,epochs=50,batch_size=32,validation_data=(X_val,y_val),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_evaluate(model_type='best_model',\n",
    "#                metrics=mean_absolute_error,\n",
    "#                X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=best_model.predict(X_test)\n",
    "# r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result=pd.concat([data.iloc[-444:][['Open',\"Close\"]],pd.DataFrame(lstm_prediction,columns=['Open_predicted','Close_predicted'],\n",
    "#                                                 index=data.iloc[-444:].index)], axis=1)\n",
    "# result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result[['Close','Close_predicted']].plot(figsize=(10,6))\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.xlabel('Date',size=15)\n",
    "# plt.ylabel('Stock Price',size=15)\n",
    "# plt.title('Actual vs Predicted for Close Price',size=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result[['Open','Open_predicted']].plot(figsize=(10,6))\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.xlabel('Date',size=15)\n",
    "# plt.ylabel('Stock Price',size=15)\n",
    "# plt.title('Actual vs Predicted for open price',size=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(self, data_url):\n",
    "        self.data_url = data_url\n",
    "\n",
    "    ## Reading data\n",
    "    def read_data(self):\n",
    "        self.data = pd.read_csv(self.data_url)\n",
    "        self.data['Date']=pd.to_datetime(self.data['Date'])\n",
    "        self.data.set_index('Date',inplace=True)\n",
    "        print(\"shape of the dataset\", self.data.shape)\n",
    "        return self.data\n",
    "    ## Handling missing values\n",
    "    def handle_missing_data(self):\n",
    "        if (self.data.isna().sum().any())>0:\n",
    "            percent=(self.data.isnull().sum()/self.data.shape[0])*100\n",
    "            if (percent.any()<15) | (percent.any()>75):\n",
    "                self.data.dropna(inplace=True)\n",
    "            else:\n",
    "                self.data.fillna(method='bfill',inplace=True)\n",
    "        print(self.data.isnull().sum())\n",
    "\n",
    "    ## remove duplicate records\n",
    "    def handle_duplicate(self):\n",
    "        if self.data.duplicated().sum()>0:\n",
    "            self.data.drop_duplicates(inplace=True)\n",
    "        print(self.data.duplicated().sum())\n",
    "    \n",
    "    ## feature selection\n",
    "    def feature_selection(self,col_names):\n",
    "        '''Pass the list of columns in order to select as features'''\n",
    "        self.features=self.data[col_names]\n",
    "        \n",
    "        print(\"Features selected\")\n",
    "        print(self.features.head())\n",
    "\n",
    "    def feature_transformation(self,type):\n",
    "        '''Prints the top 5 scaled data after performing feature transformation'''\n",
    "        \n",
    "        if type==MinMaxScaler:\n",
    "            print(\"Performing MinMaxScaling\")\n",
    "            self.scaled_data=self.features.copy()\n",
    "            self.scaler=MinMaxScaler()\n",
    "            self.scaled_data[self.features.columns]=self.scaler.fit_transform(self.features)\n",
    "            print(self.scaled_data.head())\n",
    "        elif type==StandardScaler:\n",
    "            print(\"StandardScaling\")\n",
    "            self.scaler=StandardScaler()\n",
    "            self.scaled_data[self.features.columns]=self.scaler.fit_transform(self.features)\n",
    "            print(self.scaled_data.head())\n",
    "        else:\n",
    "            raise ValueError(\"Invalid scaling type. Please choose 'MinMaxScaler' or 'StandardScaler'.\")\n",
    "        return self.scaled_data,self.scaler\n",
    "\n",
    "\n",
    "    def data_split(self,data):\n",
    "        '''Should be performed after feature scaling.\n",
    "        Function is used to split the timeseries data\n",
    "        Returns train,test, validation data splitted in 70% , 15% ,15% '''\n",
    "        train_size=int(len(data)*0.70)\n",
    "        test_size=int(len(data.iloc[train_size:])*0.50)+train_size\n",
    "        \n",
    "        self.train_data=data.iloc[:train_size,:]\n",
    "        self.test_data=data.iloc[train_size:test_size,:]\n",
    "        self.val_data=data.iloc[test_size:,:]\n",
    "        \n",
    "        print(\"Length of Training data\",self.train_data.shape)\n",
    "        print(\"Length of Testing data\",self.test_data.shape)\n",
    "        print(\"Length of Validation data\",self.val_data.shape)\n",
    "        \n",
    "        return self.train_data,self.test_data,self.val_data\n",
    "\n",
    "\n",
    "    def create_labels(self,dataset,time_steps=1):\n",
    "        ''' Function returns the features and targets generated out of data\n",
    "        based on the n_steps values - 'n' rows are labeled as features and n+1 is labeled as target\n",
    "        '''\n",
    "        features=[]\n",
    "        targets=[]\n",
    "        start_idx=0\n",
    "        for stop_idx in range(time_steps,len(dataset)):\n",
    "            features.append(dataset.iloc[start_idx:stop_idx])\n",
    "            targets.append(dataset.iloc[stop_idx])\n",
    "            start_idx +=1\n",
    "        X=np.array(features)\n",
    "        y=np.array(targets)\n",
    "        print(f\"Shape of dataset is features {X.shape} and targets {y.shape}\")\n",
    "        return X,y\n",
    "\n",
    "\n",
    "    def create_rnn_model(self,model_type,time_steps,features):\n",
    "        ''' Returns the prepared model. '''\n",
    "        self.model = Sequential()\n",
    "        if model_type == 'lstm':\n",
    "            print(\"-------------Preparing LSTM Model----------------\")\n",
    "            self.model.add(LSTM(units=50,return_sequences=True,activation='relu',\n",
    "                           input_shape=(time_steps,features)))\n",
    "            self.model.add(Dropout(0.2))\n",
    "            self.model.add(LSTM(units=50))\n",
    "            \n",
    "        elif model_type == 'bidirectional_lstm':\n",
    "            print(\"-------------Preparing bidirectional_lSTM Model----------------\")\n",
    "            # Adding a Bidirectional LSTM layer\n",
    "            self.model.add(Bidirectional(LSTM(64, return_sequences=True, activation='relu'), input_shape=(time_steps,features)))\n",
    "            self.model.add(Dropout(0.2))\n",
    "\n",
    "            # Adding another Bidirectional LSTM layer\n",
    "            self.model.add(Bidirectional(LSTM(64, activation='relu')))\n",
    "            self.model.add(Dropout(0.2))\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model type. Please choose 'lstm', 'bidirectional_lstm'.\")\n",
    "\n",
    "        # Adding a Dense layer with appropriate activation for classification\n",
    "        self.model.add(Dense(32, activation='relu'))\n",
    "        self.model.add(Dropout(0.2))\n",
    "        \n",
    "        #Output layer\n",
    "        self.model.add(Dense(features))\n",
    "    \n",
    "        #Compile the model\n",
    "        self.model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), \n",
    "               loss='mean_absolute_error')\n",
    "\n",
    "        ##creating a instance variable for model_type.\n",
    "        self.type=model_type\n",
    "        print(f\"========================Summary of {self.type}==========================\")\n",
    "        print(self.model.summary())\n",
    "        return self.model\n",
    "\n",
    "\n",
    "    def model_train(self,X,y,epochs,batch,val_data):\n",
    "        \n",
    "        print(f\"===============Training the {self.type} Model====================\")\n",
    "        self.history=self.model.fit(X,y,epochs=epochs,batch_size=batch,validation_data=val_data,verbose=2)\n",
    "        return self.history\n",
    "            \n",
    "\n",
    "    def model_evaluate(self,X_train,X_test,y_train,y_test,metrics=mean_absolute_error):\n",
    "\n",
    "        print(f\"Evaluating the Performance of {self.type} Model\")\n",
    "        train_y_pred=self.model.predict(X_train)\n",
    "        test_y_pred=self.model.predict(X_test)\n",
    "        ## checking for metrics passed\n",
    "        if metrics==mean_absolute_error:\n",
    "            print(\"Metrics used is\",metrics)\n",
    "            train_loss=metrics(y_train,train_y_pred)\n",
    "            test_loss=metrics(y_test,test_y_pred)\n",
    "            \n",
    "            print(\"Accuracy of Training Data\",100*(1-(train_loss/np.mean(y_train))))\n",
    "            print(\"Accuarcy of Testing Data\",100*(1-(test_loss/np.mean(y_test))))\n",
    "        \n",
    "    def save_model(self,stockname,feature_name):\n",
    "\n",
    "        '''Function accepts strings and filename is designed as per the strings passed and \n",
    "        model saved using the same filename format'''\n",
    "        filename=f\"{stockname}_{self.type}_{feature_name}.h5\"\n",
    "        print(f\"Saving the {self.type} Model\")\n",
    "        self.model.save(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "voltas_data_url = 'https://raw.githubusercontent.com/Kamalesh1512/datasets/main/VOLTAS.NS.csv'\n",
    "nifty50_data_url='https://raw.githubusercontent.com/Kamalesh1512/datasets/main/Nifty50_NSE.csv'\n",
    "dmart_data_url='https://raw.githubusercontent.com/Kamalesh1512/datasets/main/DMART.NS.csv'\n",
    "reliance_data_url='https://raw.githubusercontent.com/Kamalesh1512/datasets/main/RELIANCE.NS.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Train a Model for a Provided Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data,features_names,stock_name,model):\n",
    "    stocks=Pipeline(data)\n",
    "    # reading dataset\n",
    "    df=stocks.read_data()\n",
    "    \n",
    "    #handling missing data\n",
    "    stocks.handle_missing_data()\n",
    "    \n",
    "    #handling duplicate data\n",
    "    stocks.handle_duplicate()\n",
    "\n",
    "    # a list of features are passed - feature selection\n",
    "    stocks.feature_selection(features_names)\n",
    "    # Feature transformation using MinMaxScaler.\n",
    "    scaled_df,scaler=stocks.feature_transformation(type=MinMaxScaler)\n",
    "\n",
    "    # data split into train,test,val.\n",
    "    train,test,val=stocks.data_split(data=scaled_df)\n",
    "\n",
    "    ## create_data sequences - features and targets\n",
    "    X_train,y_train=stocks.create_labels(dataset=train,time_steps=50)\n",
    "    X_test,y_test=stocks.create_labels(dataset=test,time_steps=50)\n",
    "    X_val,y_val=stocks.create_labels(dataset=val,time_steps=50)\n",
    "\n",
    "    if model=='lstm':\n",
    "        lstm=stocks.create_rnn_model(model_type=model,time_steps=50,features=len(features_names))\n",
    "        ### train \n",
    "        history=stocks.model_train(X=X_train,y=y_train,epochs=100,batch=32,val_data=(X_val,y_val))\n",
    "        ## model Evaluate\n",
    "        stocks.model_evaluate(X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test)\n",
    "        ## model save\n",
    "        stocks.save_model(stockname=stock_name,feature_name=features_names[0])\n",
    "    elif model=='bidirectional_lstm':\n",
    "        bidirectional=stocks.create_rnn_model(model_type=model,time_steps=50,features=len(features_names))\n",
    "        ### train \n",
    "        history=stocks.model_train(X=X_train,y=y_train,epochs=100,batch=32,val_data=(X_val,y_val))\n",
    "        ## model Evaluate\n",
    "        stocks.model_evaluate(X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test)\n",
    "        ## model save\n",
    "        stocks.save_model(stockname=stock_name,feature_name=features_names[0])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset (2468, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                  Open\n",
      "Date                  \n",
      "2013-12-10  118.099998\n",
      "2013-12-11  123.000000\n",
      "2013-12-12  117.000000\n",
      "2013-12-13  115.949997\n",
      "2013-12-16  113.400002\n",
      "Performing MinMaxScaling\n",
      "                Open\n",
      "Date                \n",
      "2013-12-10  0.016250\n",
      "2013-12-11  0.020173\n",
      "2013-12-12  0.015370\n",
      "2013-12-13  0.014529\n",
      "2013-12-16  0.012488\n",
      "Length of Training data (1726, 1)\n",
      "Length of Testing data (370, 1)\n",
      "Length of Validation data (370, 1)\n",
      "Shape of dataset is features (1676, 50, 1) and targets (1676, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "-------------Preparing LSTM Model----------------\n",
      "========================Summary of lstm==========================\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_26 (LSTM)              (None, 50, 50)            10400     \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 50, 50)            0         \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 32)                1632      \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32265 (126.04 KB)\n",
      "Trainable params: 32265 (126.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the lstm Model====================\n",
      "Epoch 1/100\n",
      "53/53 - 11s - loss: 0.2247 - val_loss: 0.3831 - 11s/epoch - 204ms/step\n",
      "Epoch 2/100\n",
      "53/53 - 2s - loss: 0.0848 - val_loss: 0.1097 - 2s/epoch - 43ms/step\n",
      "Epoch 3/100\n",
      "53/53 - 2s - loss: 0.0506 - val_loss: 0.0224 - 2s/epoch - 46ms/step\n",
      "Epoch 4/100\n",
      "53/53 - 2s - loss: 0.0407 - val_loss: 0.0248 - 2s/epoch - 45ms/step\n",
      "Epoch 5/100\n",
      "53/53 - 3s - loss: 0.0384 - val_loss: 0.0231 - 3s/epoch - 54ms/step\n",
      "Epoch 6/100\n",
      "53/53 - 3s - loss: 0.0378 - val_loss: 0.0275 - 3s/epoch - 52ms/step\n",
      "Epoch 7/100\n",
      "53/53 - 3s - loss: 0.0371 - val_loss: 0.0386 - 3s/epoch - 52ms/step\n",
      "Epoch 8/100\n",
      "53/53 - 3s - loss: 0.0365 - val_loss: 0.0331 - 3s/epoch - 54ms/step\n",
      "Epoch 9/100\n",
      "53/53 - 3s - loss: 0.0359 - val_loss: 0.0214 - 3s/epoch - 53ms/step\n",
      "Epoch 10/100\n",
      "53/53 - 3s - loss: 0.0352 - val_loss: 0.0208 - 3s/epoch - 50ms/step\n",
      "Epoch 11/100\n",
      "53/53 - 3s - loss: 0.0343 - val_loss: 0.0312 - 3s/epoch - 50ms/step\n",
      "Epoch 12/100\n",
      "53/53 - 3s - loss: 0.0348 - val_loss: 0.0272 - 3s/epoch - 52ms/step\n",
      "Epoch 13/100\n",
      "53/53 - 3s - loss: 0.0355 - val_loss: 0.0238 - 3s/epoch - 51ms/step\n",
      "Epoch 14/100\n",
      "53/53 - 3s - loss: 0.0343 - val_loss: 0.0199 - 3s/epoch - 51ms/step\n",
      "Epoch 15/100\n",
      "53/53 - 3s - loss: 0.0332 - val_loss: 0.0196 - 3s/epoch - 51ms/step\n",
      "Epoch 16/100\n",
      "53/53 - 3s - loss: 0.0331 - val_loss: 0.0194 - 3s/epoch - 52ms/step\n",
      "Epoch 17/100\n",
      "53/53 - 3s - loss: 0.0323 - val_loss: 0.0228 - 3s/epoch - 49ms/step\n",
      "Epoch 18/100\n",
      "53/53 - 3s - loss: 0.0320 - val_loss: 0.0204 - 3s/epoch - 50ms/step\n",
      "Epoch 19/100\n",
      "53/53 - 3s - loss: 0.0317 - val_loss: 0.0224 - 3s/epoch - 51ms/step\n",
      "Epoch 20/100\n",
      "53/53 - 3s - loss: 0.0327 - val_loss: 0.0196 - 3s/epoch - 51ms/step\n",
      "Epoch 21/100\n",
      "53/53 - 3s - loss: 0.0320 - val_loss: 0.0187 - 3s/epoch - 50ms/step\n",
      "Epoch 22/100\n",
      "53/53 - 3s - loss: 0.0310 - val_loss: 0.0185 - 3s/epoch - 55ms/step\n",
      "Epoch 23/100\n",
      "53/53 - 3s - loss: 0.0313 - val_loss: 0.0198 - 3s/epoch - 51ms/step\n",
      "Epoch 24/100\n",
      "53/53 - 3s - loss: 0.0305 - val_loss: 0.0199 - 3s/epoch - 56ms/step\n",
      "Epoch 25/100\n",
      "53/53 - 3s - loss: 0.0316 - val_loss: 0.0179 - 3s/epoch - 52ms/step\n",
      "Epoch 26/100\n",
      "53/53 - 3s - loss: 0.0311 - val_loss: 0.0176 - 3s/epoch - 53ms/step\n",
      "Epoch 27/100\n",
      "53/53 - 3s - loss: 0.0311 - val_loss: 0.0175 - 3s/epoch - 51ms/step\n",
      "Epoch 28/100\n",
      "53/53 - 3s - loss: 0.0298 - val_loss: 0.0183 - 3s/epoch - 51ms/step\n",
      "Epoch 29/100\n",
      "53/53 - 3s - loss: 0.0296 - val_loss: 0.0195 - 3s/epoch - 53ms/step\n",
      "Epoch 30/100\n",
      "53/53 - 3s - loss: 0.0311 - val_loss: 0.0182 - 3s/epoch - 52ms/step\n",
      "Epoch 31/100\n",
      "53/53 - 3s - loss: 0.0299 - val_loss: 0.0226 - 3s/epoch - 51ms/step\n",
      "Epoch 32/100\n",
      "53/53 - 3s - loss: 0.0294 - val_loss: 0.0203 - 3s/epoch - 54ms/step\n",
      "Epoch 33/100\n",
      "53/53 - 3s - loss: 0.0297 - val_loss: 0.0167 - 3s/epoch - 55ms/step\n",
      "Epoch 34/100\n",
      "53/53 - 3s - loss: 0.0286 - val_loss: 0.0166 - 3s/epoch - 48ms/step\n",
      "Epoch 35/100\n",
      "53/53 - 3s - loss: 0.0289 - val_loss: 0.0165 - 3s/epoch - 51ms/step\n",
      "Epoch 36/100\n",
      "53/53 - 3s - loss: 0.0291 - val_loss: 0.0166 - 3s/epoch - 52ms/step\n",
      "Epoch 37/100\n",
      "53/53 - 3s - loss: 0.0284 - val_loss: 0.0193 - 3s/epoch - 53ms/step\n",
      "Epoch 38/100\n",
      "53/53 - 3s - loss: 0.0274 - val_loss: 0.0271 - 3s/epoch - 50ms/step\n",
      "Epoch 39/100\n",
      "53/53 - 3s - loss: 0.0279 - val_loss: 0.0178 - 3s/epoch - 52ms/step\n",
      "Epoch 40/100\n",
      "53/53 - 3s - loss: 0.0286 - val_loss: 0.0158 - 3s/epoch - 58ms/step\n",
      "Epoch 41/100\n",
      "53/53 - 3s - loss: 0.0287 - val_loss: 0.0262 - 3s/epoch - 50ms/step\n",
      "Epoch 42/100\n",
      "53/53 - 3s - loss: 0.0276 - val_loss: 0.0201 - 3s/epoch - 55ms/step\n",
      "Epoch 43/100\n",
      "53/53 - 3s - loss: 0.0267 - val_loss: 0.0164 - 3s/epoch - 54ms/step\n",
      "Epoch 44/100\n",
      "53/53 - 3s - loss: 0.0272 - val_loss: 0.0227 - 3s/epoch - 54ms/step\n",
      "Epoch 45/100\n",
      "53/53 - 3s - loss: 0.0284 - val_loss: 0.0331 - 3s/epoch - 52ms/step\n",
      "Epoch 46/100\n",
      "53/53 - 3s - loss: 0.0281 - val_loss: 0.0167 - 3s/epoch - 53ms/step\n",
      "Epoch 47/100\n",
      "53/53 - 3s - loss: 0.0258 - val_loss: 0.0236 - 3s/epoch - 55ms/step\n",
      "Epoch 48/100\n",
      "53/53 - 3s - loss: 0.0261 - val_loss: 0.0152 - 3s/epoch - 52ms/step\n",
      "Epoch 49/100\n",
      "53/53 - 3s - loss: 0.0259 - val_loss: 0.0164 - 3s/epoch - 53ms/step\n",
      "Epoch 50/100\n",
      "53/53 - 3s - loss: 0.0271 - val_loss: 0.0245 - 3s/epoch - 52ms/step\n",
      "Epoch 51/100\n",
      "53/53 - 3s - loss: 0.0247 - val_loss: 0.0286 - 3s/epoch - 52ms/step\n",
      "Epoch 52/100\n",
      "53/53 - 3s - loss: 0.0262 - val_loss: 0.0311 - 3s/epoch - 57ms/step\n",
      "Epoch 53/100\n",
      "53/53 - 3s - loss: 0.0257 - val_loss: 0.0164 - 3s/epoch - 54ms/step\n",
      "Epoch 54/100\n",
      "53/53 - 3s - loss: 0.0265 - val_loss: 0.0155 - 3s/epoch - 52ms/step\n",
      "Epoch 55/100\n",
      "53/53 - 3s - loss: 0.0254 - val_loss: 0.0249 - 3s/epoch - 49ms/step\n",
      "Epoch 56/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0192 - 3s/epoch - 53ms/step\n",
      "Epoch 57/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0201 - 3s/epoch - 52ms/step\n",
      "Epoch 58/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0337 - 3s/epoch - 53ms/step\n",
      "Epoch 59/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0150 - 3s/epoch - 55ms/step\n",
      "Epoch 60/100\n",
      "53/53 - 3s - loss: 0.0252 - val_loss: 0.0175 - 3s/epoch - 52ms/step\n",
      "Epoch 61/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0356 - 3s/epoch - 51ms/step\n",
      "Epoch 62/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.0362 - 3s/epoch - 52ms/step\n",
      "Epoch 63/100\n",
      "53/53 - 3s - loss: 0.0243 - val_loss: 0.0265 - 3s/epoch - 53ms/step\n",
      "Epoch 64/100\n",
      "53/53 - 3s - loss: 0.0242 - val_loss: 0.0210 - 3s/epoch - 51ms/step\n",
      "Epoch 65/100\n",
      "53/53 - 3s - loss: 0.0246 - val_loss: 0.0249 - 3s/epoch - 52ms/step\n",
      "Epoch 66/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.0180 - 3s/epoch - 51ms/step\n",
      "Epoch 67/100\n",
      "53/53 - 3s - loss: 0.0239 - val_loss: 0.0396 - 3s/epoch - 52ms/step\n",
      "Epoch 68/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.0185 - 3s/epoch - 50ms/step\n",
      "Epoch 69/100\n",
      "53/53 - 3s - loss: 0.0237 - val_loss: 0.0220 - 3s/epoch - 57ms/step\n",
      "Epoch 70/100\n",
      "53/53 - 3s - loss: 0.0235 - val_loss: 0.0294 - 3s/epoch - 54ms/step\n",
      "Epoch 71/100\n",
      "53/53 - 3s - loss: 0.0234 - val_loss: 0.0238 - 3s/epoch - 49ms/step\n",
      "Epoch 72/100\n",
      "53/53 - 3s - loss: 0.0237 - val_loss: 0.0204 - 3s/epoch - 50ms/step\n",
      "Epoch 73/100\n",
      "53/53 - 3s - loss: 0.0236 - val_loss: 0.0181 - 3s/epoch - 55ms/step\n",
      "Epoch 74/100\n",
      "53/53 - 3s - loss: 0.0232 - val_loss: 0.0239 - 3s/epoch - 53ms/step\n",
      "Epoch 75/100\n",
      "53/53 - 3s - loss: 0.0228 - val_loss: 0.0207 - 3s/epoch - 50ms/step\n",
      "Epoch 76/100\n",
      "53/53 - 3s - loss: 0.0231 - val_loss: 0.0166 - 3s/epoch - 50ms/step\n",
      "Epoch 77/100\n",
      "53/53 - 3s - loss: 0.0225 - val_loss: 0.0270 - 3s/epoch - 51ms/step\n",
      "Epoch 78/100\n",
      "53/53 - 3s - loss: 0.0237 - val_loss: 0.0274 - 3s/epoch - 56ms/step\n",
      "Epoch 79/100\n",
      "53/53 - 3s - loss: 0.0232 - val_loss: 0.0195 - 3s/epoch - 50ms/step\n",
      "Epoch 80/100\n",
      "53/53 - 3s - loss: 0.0237 - val_loss: 0.0328 - 3s/epoch - 53ms/step\n",
      "Epoch 81/100\n",
      "53/53 - 3s - loss: 0.0232 - val_loss: 0.0243 - 3s/epoch - 50ms/step\n",
      "Epoch 82/100\n",
      "53/53 - 3s - loss: 0.0218 - val_loss: 0.0364 - 3s/epoch - 53ms/step\n",
      "Epoch 83/100\n",
      "53/53 - 3s - loss: 0.0233 - val_loss: 0.0325 - 3s/epoch - 57ms/step\n",
      "Epoch 84/100\n",
      "53/53 - 3s - loss: 0.0228 - val_loss: 0.0223 - 3s/epoch - 57ms/step\n",
      "Epoch 85/100\n",
      "53/53 - 3s - loss: 0.0220 - val_loss: 0.0210 - 3s/epoch - 47ms/step\n",
      "Epoch 86/100\n",
      "53/53 - 3s - loss: 0.0219 - val_loss: 0.0183 - 3s/epoch - 49ms/step\n",
      "Epoch 87/100\n",
      "53/53 - 3s - loss: 0.0223 - val_loss: 0.0239 - 3s/epoch - 55ms/step\n",
      "Epoch 88/100\n",
      "53/53 - 3s - loss: 0.0217 - val_loss: 0.0249 - 3s/epoch - 50ms/step\n",
      "Epoch 89/100\n",
      "53/53 - 3s - loss: 0.0215 - val_loss: 0.0252 - 3s/epoch - 52ms/step\n",
      "Epoch 90/100\n",
      "53/53 - 3s - loss: 0.0218 - val_loss: 0.0217 - 3s/epoch - 53ms/step\n",
      "Epoch 91/100\n",
      "53/53 - 3s - loss: 0.0216 - val_loss: 0.0181 - 3s/epoch - 53ms/step\n",
      "Epoch 92/100\n",
      "53/53 - 3s - loss: 0.0219 - val_loss: 0.0239 - 3s/epoch - 53ms/step\n",
      "Epoch 93/100\n",
      "53/53 - 3s - loss: 0.0220 - val_loss: 0.0204 - 3s/epoch - 53ms/step\n",
      "Epoch 94/100\n",
      "53/53 - 3s - loss: 0.0214 - val_loss: 0.0435 - 3s/epoch - 55ms/step\n",
      "Epoch 95/100\n",
      "53/53 - 3s - loss: 0.0216 - val_loss: 0.0297 - 3s/epoch - 51ms/step\n",
      "Epoch 96/100\n",
      "53/53 - 3s - loss: 0.0210 - val_loss: 0.0243 - 3s/epoch - 50ms/step\n",
      "Epoch 97/100\n",
      "53/53 - 3s - loss: 0.0210 - val_loss: 0.0207 - 3s/epoch - 53ms/step\n",
      "Epoch 98/100\n",
      "53/53 - 3s - loss: 0.0213 - val_loss: 0.0204 - 3s/epoch - 52ms/step\n",
      "Epoch 99/100\n",
      "53/53 - 3s - loss: 0.0208 - val_loss: 0.0142 - 3s/epoch - 53ms/step\n",
      "Epoch 100/100\n",
      "53/53 - 3s - loss: 0.0216 - val_loss: 0.0204 - 3s/epoch - 52ms/step\n",
      "Evaluating the Performance of lstm Model\n",
      "53/53 [==============================] - 2s 16ms/step\n",
      "10/10 [==============================] - 0s 17ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 96.15648340056642\n",
      "Accuarcy of Testing Data 92.80404203800542\n",
      "Saving the lstm Model\n"
     ]
    }
   ],
   "source": [
    "## Building lstm model\n",
    "build_model(data=voltas_data_url,stock_name='Voltas',features_names=['Open'],model='lstm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset (2468, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                  Open\n",
      "Date                  \n",
      "2013-12-10  118.099998\n",
      "2013-12-11  123.000000\n",
      "2013-12-12  117.000000\n",
      "2013-12-13  115.949997\n",
      "2013-12-16  113.400002\n",
      "Performing MinMaxScaling\n",
      "                Open\n",
      "Date                \n",
      "2013-12-10  0.016250\n",
      "2013-12-11  0.020173\n",
      "2013-12-12  0.015370\n",
      "2013-12-13  0.014529\n",
      "2013-12-16  0.012488\n",
      "Length of Training data (1726, 1)\n",
      "Length of Testing data (370, 1)\n",
      "Length of Validation data (370, 1)\n",
      "Shape of dataset is features (1676, 50, 1) and targets (1676, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "-------------Preparing bidirectional_lSTM Model----------------\n",
      "========================Summary of bidirectional_lstm==========================\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_10 (Bidirect  (None, 50, 128)           33792     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 50, 128)           0         \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirect  (None, 128)               98816     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136769 (534.25 KB)\n",
      "Trainable params: 136769 (534.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the bidirectional_lstm Model====================\n",
      "Epoch 1/100\n",
      "53/53 - 11s - loss: 0.2148 - val_loss: 0.2853 - 11s/epoch - 206ms/step\n",
      "Epoch 2/100\n",
      "53/53 - 3s - loss: 0.0708 - val_loss: 0.0415 - 3s/epoch - 56ms/step\n",
      "Epoch 3/100\n",
      "53/53 - 3s - loss: 0.0505 - val_loss: 0.0317 - 3s/epoch - 55ms/step\n",
      "Epoch 4/100\n",
      "53/53 - 3s - loss: 0.0460 - val_loss: 0.0323 - 3s/epoch - 59ms/step\n",
      "Epoch 5/100\n",
      "53/53 - 3s - loss: 0.0418 - val_loss: 0.0252 - 3s/epoch - 57ms/step\n",
      "Epoch 6/100\n",
      "53/53 - 3s - loss: 0.0418 - val_loss: 0.0363 - 3s/epoch - 55ms/step\n",
      "Epoch 7/100\n",
      "53/53 - 3s - loss: 0.0397 - val_loss: 0.0374 - 3s/epoch - 59ms/step\n",
      "Epoch 8/100\n",
      "53/53 - 3s - loss: 0.0390 - val_loss: 0.0260 - 3s/epoch - 55ms/step\n",
      "Epoch 9/100\n",
      "53/53 - 3s - loss: 0.0393 - val_loss: 0.0234 - 3s/epoch - 62ms/step\n",
      "Epoch 10/100\n",
      "53/53 - 4s - loss: 0.0391 - val_loss: 0.0360 - 4s/epoch - 67ms/step\n",
      "Epoch 11/100\n",
      "53/53 - 3s - loss: 0.0367 - val_loss: 0.0208 - 3s/epoch - 64ms/step\n",
      "Epoch 12/100\n",
      "53/53 - 3s - loss: 0.0373 - val_loss: 0.0206 - 3s/epoch - 64ms/step\n",
      "Epoch 13/100\n",
      "53/53 - 3s - loss: 0.0364 - val_loss: 0.0265 - 3s/epoch - 63ms/step\n",
      "Epoch 14/100\n",
      "53/53 - 3s - loss: 0.0354 - val_loss: 0.0262 - 3s/epoch - 65ms/step\n",
      "Epoch 15/100\n",
      "53/53 - 4s - loss: 0.0343 - val_loss: 0.0200 - 4s/epoch - 66ms/step\n",
      "Epoch 16/100\n",
      "53/53 - 3s - loss: 0.0349 - val_loss: 0.0183 - 3s/epoch - 62ms/step\n",
      "Epoch 17/100\n",
      "53/53 - 4s - loss: 0.0345 - val_loss: 0.0184 - 4s/epoch - 70ms/step\n",
      "Epoch 18/100\n",
      "53/53 - 4s - loss: 0.0348 - val_loss: 0.0225 - 4s/epoch - 67ms/step\n",
      "Epoch 19/100\n",
      "53/53 - 4s - loss: 0.0336 - val_loss: 0.0176 - 4s/epoch - 68ms/step\n",
      "Epoch 20/100\n",
      "53/53 - 3s - loss: 0.0332 - val_loss: 0.0188 - 3s/epoch - 66ms/step\n",
      "Epoch 21/100\n",
      "53/53 - 3s - loss: 0.0319 - val_loss: 0.0250 - 3s/epoch - 64ms/step\n",
      "Epoch 22/100\n",
      "53/53 - 3s - loss: 0.0338 - val_loss: 0.0168 - 3s/epoch - 62ms/step\n",
      "Epoch 23/100\n",
      "53/53 - 3s - loss: 0.0335 - val_loss: 0.0278 - 3s/epoch - 65ms/step\n",
      "Epoch 24/100\n",
      "53/53 - 3s - loss: 0.0335 - val_loss: 0.0166 - 3s/epoch - 62ms/step\n",
      "Epoch 25/100\n",
      "53/53 - 3s - loss: 0.0308 - val_loss: 0.0166 - 3s/epoch - 64ms/step\n",
      "Epoch 26/100\n",
      "53/53 - 3s - loss: 0.0321 - val_loss: 0.0168 - 3s/epoch - 62ms/step\n",
      "Epoch 27/100\n",
      "53/53 - 3s - loss: 0.0312 - val_loss: 0.0204 - 3s/epoch - 64ms/step\n",
      "Epoch 28/100\n",
      "53/53 - 3s - loss: 0.0309 - val_loss: 0.0196 - 3s/epoch - 62ms/step\n",
      "Epoch 29/100\n",
      "53/53 - 3s - loss: 0.0317 - val_loss: 0.0194 - 3s/epoch - 64ms/step\n",
      "Epoch 30/100\n",
      "53/53 - 3s - loss: 0.0298 - val_loss: 0.0236 - 3s/epoch - 64ms/step\n",
      "Epoch 31/100\n",
      "53/53 - 4s - loss: 0.0301 - val_loss: 0.0159 - 4s/epoch - 67ms/step\n",
      "Epoch 32/100\n",
      "53/53 - 3s - loss: 0.0306 - val_loss: 0.0210 - 3s/epoch - 62ms/step\n",
      "Epoch 33/100\n",
      "53/53 - 3s - loss: 0.0295 - val_loss: 0.0177 - 3s/epoch - 65ms/step\n",
      "Epoch 34/100\n",
      "53/53 - 3s - loss: 0.0292 - val_loss: 0.0278 - 3s/epoch - 65ms/step\n",
      "Epoch 35/100\n",
      "53/53 - 4s - loss: 0.0293 - val_loss: 0.0169 - 4s/epoch - 66ms/step\n",
      "Epoch 36/100\n",
      "53/53 - 3s - loss: 0.0292 - val_loss: 0.0184 - 3s/epoch - 63ms/step\n",
      "Epoch 37/100\n",
      "53/53 - 3s - loss: 0.0288 - val_loss: 0.0150 - 3s/epoch - 64ms/step\n",
      "Epoch 38/100\n",
      "53/53 - 3s - loss: 0.0284 - val_loss: 0.0200 - 3s/epoch - 64ms/step\n",
      "Epoch 39/100\n",
      "53/53 - 3s - loss: 0.0276 - val_loss: 0.0167 - 3s/epoch - 65ms/step\n",
      "Epoch 40/100\n",
      "53/53 - 3s - loss: 0.0287 - val_loss: 0.0175 - 3s/epoch - 65ms/step\n",
      "Epoch 41/100\n",
      "53/53 - 3s - loss: 0.0281 - val_loss: 0.0139 - 3s/epoch - 63ms/step\n",
      "Epoch 42/100\n",
      "53/53 - 3s - loss: 0.0270 - val_loss: 0.0161 - 3s/epoch - 64ms/step\n",
      "Epoch 43/100\n",
      "53/53 - 4s - loss: 0.0285 - val_loss: 0.0241 - 4s/epoch - 67ms/step\n",
      "Epoch 44/100\n",
      "53/53 - 3s - loss: 0.0278 - val_loss: 0.0354 - 3s/epoch - 64ms/step\n",
      "Epoch 45/100\n",
      "53/53 - 3s - loss: 0.0267 - val_loss: 0.0181 - 3s/epoch - 65ms/step\n",
      "Epoch 46/100\n",
      "53/53 - 3s - loss: 0.0272 - val_loss: 0.0174 - 3s/epoch - 64ms/step\n",
      "Epoch 47/100\n",
      "53/53 - 3s - loss: 0.0274 - val_loss: 0.0209 - 3s/epoch - 63ms/step\n",
      "Epoch 48/100\n",
      "53/53 - 3s - loss: 0.0274 - val_loss: 0.0229 - 3s/epoch - 64ms/step\n",
      "Epoch 49/100\n",
      "53/53 - 3s - loss: 0.0264 - val_loss: 0.0188 - 3s/epoch - 64ms/step\n",
      "Epoch 50/100\n",
      "53/53 - 3s - loss: 0.0279 - val_loss: 0.0284 - 3s/epoch - 64ms/step\n",
      "Epoch 51/100\n",
      "53/53 - 3s - loss: 0.0259 - val_loss: 0.0199 - 3s/epoch - 65ms/step\n",
      "Epoch 52/100\n",
      "53/53 - 3s - loss: 0.0263 - val_loss: 0.0307 - 3s/epoch - 64ms/step\n",
      "Epoch 53/100\n",
      "53/53 - 4s - loss: 0.0262 - val_loss: 0.0169 - 4s/epoch - 68ms/step\n",
      "Epoch 54/100\n",
      "53/53 - 4s - loss: 0.0271 - val_loss: 0.0176 - 4s/epoch - 69ms/step\n",
      "Epoch 55/100\n",
      "53/53 - 4s - loss: 0.0270 - val_loss: 0.0288 - 4s/epoch - 81ms/step\n",
      "Epoch 56/100\n",
      "53/53 - 4s - loss: 0.0256 - val_loss: 0.0137 - 4s/epoch - 68ms/step\n",
      "Epoch 57/100\n",
      "53/53 - 3s - loss: 0.0256 - val_loss: 0.0254 - 3s/epoch - 66ms/step\n",
      "Epoch 58/100\n",
      "53/53 - 3s - loss: 0.0252 - val_loss: 0.0374 - 3s/epoch - 63ms/step\n",
      "Epoch 59/100\n",
      "53/53 - 4s - loss: 0.0258 - val_loss: 0.0170 - 4s/epoch - 67ms/step\n",
      "Epoch 60/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0217 - 3s/epoch - 66ms/step\n",
      "Epoch 61/100\n",
      "53/53 - 4s - loss: 0.0256 - val_loss: 0.0189 - 4s/epoch - 67ms/step\n",
      "Epoch 62/100\n",
      "53/53 - 3s - loss: 0.0257 - val_loss: 0.0163 - 3s/epoch - 64ms/step\n",
      "Epoch 63/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0202 - 3s/epoch - 64ms/step\n",
      "Epoch 64/100\n",
      "53/53 - 3s - loss: 0.0255 - val_loss: 0.0241 - 3s/epoch - 63ms/step\n",
      "Epoch 65/100\n",
      "53/53 - 4s - loss: 0.0242 - val_loss: 0.0259 - 4s/epoch - 66ms/step\n",
      "Epoch 66/100\n",
      "53/53 - 3s - loss: 0.0242 - val_loss: 0.0177 - 3s/epoch - 65ms/step\n",
      "Epoch 67/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0193 - 3s/epoch - 62ms/step\n",
      "Epoch 68/100\n",
      "53/53 - 3s - loss: 0.0242 - val_loss: 0.0170 - 3s/epoch - 65ms/step\n",
      "Epoch 69/100\n",
      "53/53 - 3s - loss: 0.0236 - val_loss: 0.0131 - 3s/epoch - 63ms/step\n",
      "Epoch 70/100\n",
      "53/53 - 4s - loss: 0.0249 - val_loss: 0.0234 - 4s/epoch - 67ms/step\n",
      "Epoch 71/100\n",
      "53/53 - 3s - loss: 0.0234 - val_loss: 0.0240 - 3s/epoch - 64ms/step\n",
      "Epoch 72/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.0321 - 3s/epoch - 65ms/step\n",
      "Epoch 73/100\n",
      "53/53 - 3s - loss: 0.0228 - val_loss: 0.0173 - 3s/epoch - 63ms/step\n",
      "Epoch 74/100\n",
      "53/53 - 3s - loss: 0.0243 - val_loss: 0.0188 - 3s/epoch - 65ms/step\n",
      "Epoch 75/100\n",
      "53/53 - 3s - loss: 0.0230 - val_loss: 0.0315 - 3s/epoch - 65ms/step\n",
      "Epoch 76/100\n",
      "53/53 - 3s - loss: 0.0231 - val_loss: 0.0365 - 3s/epoch - 63ms/step\n",
      "Epoch 77/100\n",
      "53/53 - 4s - loss: 0.0237 - val_loss: 0.0214 - 4s/epoch - 66ms/step\n",
      "Epoch 78/100\n",
      "53/53 - 4s - loss: 0.0234 - val_loss: 0.0187 - 4s/epoch - 71ms/step\n",
      "Epoch 79/100\n",
      "53/53 - 3s - loss: 0.0226 - val_loss: 0.0244 - 3s/epoch - 64ms/step\n",
      "Epoch 80/100\n",
      "53/53 - 3s - loss: 0.0222 - val_loss: 0.0161 - 3s/epoch - 63ms/step\n",
      "Epoch 81/100\n",
      "53/53 - 3s - loss: 0.0242 - val_loss: 0.0198 - 3s/epoch - 65ms/step\n",
      "Epoch 82/100\n",
      "53/53 - 3s - loss: 0.0239 - val_loss: 0.0256 - 3s/epoch - 65ms/step\n",
      "Epoch 83/100\n",
      "53/53 - 3s - loss: 0.0234 - val_loss: 0.0260 - 3s/epoch - 66ms/step\n",
      "Epoch 84/100\n",
      "53/53 - 3s - loss: 0.0234 - val_loss: 0.0317 - 3s/epoch - 64ms/step\n",
      "Epoch 85/100\n",
      "53/53 - 3s - loss: 0.0228 - val_loss: 0.0200 - 3s/epoch - 64ms/step\n",
      "Epoch 86/100\n",
      "53/53 - 3s - loss: 0.0233 - val_loss: 0.0219 - 3s/epoch - 63ms/step\n",
      "Epoch 87/100\n",
      "53/53 - 3s - loss: 0.0227 - val_loss: 0.0254 - 3s/epoch - 65ms/step\n",
      "Epoch 88/100\n",
      "53/53 - 4s - loss: 0.0227 - val_loss: 0.0183 - 4s/epoch - 66ms/step\n",
      "Epoch 89/100\n",
      "53/53 - 3s - loss: 0.0221 - val_loss: 0.0273 - 3s/epoch - 64ms/step\n",
      "Epoch 90/100\n",
      "53/53 - 3s - loss: 0.0228 - val_loss: 0.0127 - 3s/epoch - 64ms/step\n",
      "Epoch 91/100\n",
      "53/53 - 3s - loss: 0.0218 - val_loss: 0.0245 - 3s/epoch - 63ms/step\n",
      "Epoch 92/100\n",
      "53/53 - 3s - loss: 0.0226 - val_loss: 0.0290 - 3s/epoch - 64ms/step\n",
      "Epoch 93/100\n",
      "53/53 - 3s - loss: 0.0220 - val_loss: 0.0182 - 3s/epoch - 65ms/step\n",
      "Epoch 94/100\n",
      "53/53 - 3s - loss: 0.0222 - val_loss: 0.0282 - 3s/epoch - 63ms/step\n",
      "Epoch 95/100\n",
      "53/53 - 3s - loss: 0.0221 - val_loss: 0.0178 - 3s/epoch - 65ms/step\n",
      "Epoch 96/100\n",
      "53/53 - 3s - loss: 0.0220 - val_loss: 0.0149 - 3s/epoch - 66ms/step\n",
      "Epoch 97/100\n",
      "53/53 - 3s - loss: 0.0212 - val_loss: 0.0312 - 3s/epoch - 64ms/step\n",
      "Epoch 98/100\n",
      "53/53 - 3s - loss: 0.0214 - val_loss: 0.0214 - 3s/epoch - 64ms/step\n",
      "Epoch 99/100\n",
      "53/53 - 3s - loss: 0.0211 - val_loss: 0.0166 - 3s/epoch - 65ms/step\n",
      "Epoch 100/100\n",
      "53/53 - 3s - loss: 0.0224 - val_loss: 0.0351 - 3s/epoch - 64ms/step\n",
      "Evaluating the Performance of bidirectional_lstm Model\n",
      "53/53 [==============================] - 2s 21ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 94.85950292613907\n",
      "Accuarcy of Testing Data 93.97855867612853\n",
      "Saving the bidirectional_lstm Model\n"
     ]
    }
   ],
   "source": [
    "## Building bidirectional_lstm model\n",
    "build_model(data=voltas_data_url,stock_name='Voltas',features_names=['Open'],model='bidirectional_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset (2468, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                 Close\n",
      "Date                  \n",
      "2013-12-10  123.699997\n",
      "2013-12-11  117.550003\n",
      "2013-12-12  117.250000\n",
      "2013-12-13  113.500000\n",
      "2013-12-16  114.650002\n",
      "Performing MinMaxScaling\n",
      "               Close\n",
      "Date                \n",
      "2013-12-10  0.019861\n",
      "2013-12-11  0.014896\n",
      "2013-12-12  0.014654\n",
      "2013-12-13  0.011626\n",
      "2013-12-16  0.012555\n",
      "Length of Training data (1726, 1)\n",
      "Length of Testing data (370, 1)\n",
      "Length of Validation data (370, 1)\n",
      "Shape of dataset is features (1676, 50, 1) and targets (1676, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "-------------Preparing LSTM Model----------------\n",
      "========================Summary of lstm==========================\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_32 (LSTM)              (None, 50, 50)            10400     \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 50, 50)            0         \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 32)                1632      \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32265 (126.04 KB)\n",
      "Trainable params: 32265 (126.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the lstm Model====================\n",
      "Epoch 1/100\n",
      "53/53 - 8s - loss: 0.2463 - val_loss: 0.4642 - 8s/epoch - 153ms/step\n",
      "Epoch 2/100\n",
      "53/53 - 3s - loss: 0.1093 - val_loss: 0.1589 - 3s/epoch - 50ms/step\n",
      "Epoch 3/100\n",
      "53/53 - 3s - loss: 0.0547 - val_loss: 0.0239 - 3s/epoch - 48ms/step\n",
      "Epoch 4/100\n",
      "53/53 - 2s - loss: 0.0452 - val_loss: 0.0250 - 2s/epoch - 45ms/step\n",
      "Epoch 5/100\n",
      "53/53 - 3s - loss: 0.0433 - val_loss: 0.0315 - 3s/epoch - 47ms/step\n",
      "Epoch 6/100\n",
      "53/53 - 2s - loss: 0.0429 - val_loss: 0.0325 - 2s/epoch - 46ms/step\n",
      "Epoch 7/100\n",
      "53/53 - 3s - loss: 0.0424 - val_loss: 0.0280 - 3s/epoch - 53ms/step\n",
      "Epoch 8/100\n",
      "53/53 - 3s - loss: 0.0430 - val_loss: 0.0243 - 3s/epoch - 52ms/step\n",
      "Epoch 9/100\n",
      "53/53 - 3s - loss: 0.0397 - val_loss: 0.0306 - 3s/epoch - 48ms/step\n",
      "Epoch 10/100\n",
      "53/53 - 3s - loss: 0.0413 - val_loss: 0.0363 - 3s/epoch - 50ms/step\n",
      "Epoch 11/100\n",
      "53/53 - 3s - loss: 0.0404 - val_loss: 0.0291 - 3s/epoch - 55ms/step\n",
      "Epoch 12/100\n",
      "53/53 - 3s - loss: 0.0409 - val_loss: 0.0276 - 3s/epoch - 53ms/step\n",
      "Epoch 13/100\n",
      "53/53 - 3s - loss: 0.0408 - val_loss: 0.0387 - 3s/epoch - 51ms/step\n",
      "Epoch 14/100\n",
      "53/53 - 3s - loss: 0.0374 - val_loss: 0.0640 - 3s/epoch - 52ms/step\n",
      "Epoch 15/100\n",
      "53/53 - 3s - loss: 0.0388 - val_loss: 0.0500 - 3s/epoch - 54ms/step\n",
      "Epoch 16/100\n",
      "53/53 - 3s - loss: 0.0389 - val_loss: 0.0292 - 3s/epoch - 53ms/step\n",
      "Epoch 17/100\n",
      "53/53 - 3s - loss: 0.0400 - val_loss: 0.0330 - 3s/epoch - 51ms/step\n",
      "Epoch 18/100\n",
      "53/53 - 3s - loss: 0.0380 - val_loss: 0.0446 - 3s/epoch - 49ms/step\n",
      "Epoch 19/100\n",
      "53/53 - 3s - loss: 0.0369 - val_loss: 0.0441 - 3s/epoch - 53ms/step\n",
      "Epoch 20/100\n",
      "53/53 - 3s - loss: 0.0374 - val_loss: 0.0528 - 3s/epoch - 53ms/step\n",
      "Epoch 21/100\n",
      "53/53 - 3s - loss: 0.0366 - val_loss: 0.0220 - 3s/epoch - 57ms/step\n",
      "Epoch 22/100\n",
      "53/53 - 3s - loss: 0.0373 - val_loss: 0.0493 - 3s/epoch - 50ms/step\n",
      "Epoch 23/100\n",
      "53/53 - 3s - loss: 0.0380 - val_loss: 0.0484 - 3s/epoch - 51ms/step\n",
      "Epoch 24/100\n",
      "53/53 - 3s - loss: 0.0367 - val_loss: 0.0335 - 3s/epoch - 52ms/step\n",
      "Epoch 25/100\n",
      "53/53 - 3s - loss: 0.0353 - val_loss: 0.0398 - 3s/epoch - 52ms/step\n",
      "Epoch 26/100\n",
      "53/53 - 3s - loss: 0.0366 - val_loss: 0.0349 - 3s/epoch - 56ms/step\n",
      "Epoch 27/100\n",
      "53/53 - 3s - loss: 0.0350 - val_loss: 0.0356 - 3s/epoch - 55ms/step\n",
      "Epoch 28/100\n",
      "53/53 - 3s - loss: 0.0346 - val_loss: 0.0338 - 3s/epoch - 55ms/step\n",
      "Epoch 29/100\n",
      "53/53 - 3s - loss: 0.0342 - val_loss: 0.0456 - 3s/epoch - 49ms/step\n",
      "Epoch 30/100\n",
      "53/53 - 3s - loss: 0.0333 - val_loss: 0.0410 - 3s/epoch - 53ms/step\n",
      "Epoch 31/100\n",
      "53/53 - 3s - loss: 0.0336 - val_loss: 0.0264 - 3s/epoch - 50ms/step\n",
      "Epoch 32/100\n",
      "53/53 - 3s - loss: 0.0338 - val_loss: 0.0326 - 3s/epoch - 53ms/step\n",
      "Epoch 33/100\n",
      "53/53 - 3s - loss: 0.0337 - val_loss: 0.0296 - 3s/epoch - 50ms/step\n",
      "Epoch 34/100\n",
      "53/53 - 3s - loss: 0.0342 - val_loss: 0.0444 - 3s/epoch - 53ms/step\n",
      "Epoch 35/100\n",
      "53/53 - 3s - loss: 0.0331 - val_loss: 0.0340 - 3s/epoch - 50ms/step\n",
      "Epoch 36/100\n",
      "53/53 - 3s - loss: 0.0327 - val_loss: 0.0363 - 3s/epoch - 49ms/step\n",
      "Epoch 37/100\n",
      "53/53 - 3s - loss: 0.0329 - val_loss: 0.0399 - 3s/epoch - 52ms/step\n",
      "Epoch 38/100\n",
      "53/53 - 3s - loss: 0.0322 - val_loss: 0.0384 - 3s/epoch - 52ms/step\n",
      "Epoch 39/100\n",
      "53/53 - 3s - loss: 0.0328 - val_loss: 0.0304 - 3s/epoch - 51ms/step\n",
      "Epoch 40/100\n",
      "53/53 - 3s - loss: 0.0322 - val_loss: 0.0331 - 3s/epoch - 55ms/step\n",
      "Epoch 41/100\n",
      "53/53 - 3s - loss: 0.0316 - val_loss: 0.0365 - 3s/epoch - 52ms/step\n",
      "Epoch 42/100\n",
      "53/53 - 3s - loss: 0.0317 - val_loss: 0.0279 - 3s/epoch - 54ms/step\n",
      "Epoch 43/100\n",
      "53/53 - 3s - loss: 0.0316 - val_loss: 0.0366 - 3s/epoch - 54ms/step\n",
      "Epoch 44/100\n",
      "53/53 - 3s - loss: 0.0307 - val_loss: 0.0269 - 3s/epoch - 56ms/step\n",
      "Epoch 45/100\n",
      "53/53 - 2s - loss: 0.0303 - val_loss: 0.0437 - 2s/epoch - 47ms/step\n",
      "Epoch 46/100\n",
      "53/53 - 3s - loss: 0.0310 - val_loss: 0.0387 - 3s/epoch - 54ms/step\n",
      "Epoch 47/100\n",
      "53/53 - 3s - loss: 0.0300 - val_loss: 0.0437 - 3s/epoch - 52ms/step\n",
      "Epoch 48/100\n",
      "53/53 - 3s - loss: 0.0307 - val_loss: 0.0500 - 3s/epoch - 53ms/step\n",
      "Epoch 49/100\n",
      "53/53 - 3s - loss: 0.0309 - val_loss: 0.0442 - 3s/epoch - 51ms/step\n",
      "Epoch 50/100\n",
      "53/53 - 3s - loss: 0.0307 - val_loss: 0.0337 - 3s/epoch - 52ms/step\n",
      "Epoch 51/100\n",
      "53/53 - 3s - loss: 0.0288 - val_loss: 0.0242 - 3s/epoch - 52ms/step\n",
      "Epoch 52/100\n",
      "53/53 - 3s - loss: 0.0300 - val_loss: 0.0393 - 3s/epoch - 54ms/step\n",
      "Epoch 53/100\n",
      "53/53 - 3s - loss: 0.0289 - val_loss: 0.0338 - 3s/epoch - 49ms/step\n",
      "Epoch 54/100\n",
      "53/53 - 3s - loss: 0.0297 - val_loss: 0.0539 - 3s/epoch - 51ms/step\n",
      "Epoch 55/100\n",
      "53/53 - 3s - loss: 0.0289 - val_loss: 0.0467 - 3s/epoch - 53ms/step\n",
      "Epoch 56/100\n",
      "53/53 - 3s - loss: 0.0280 - val_loss: 0.0258 - 3s/epoch - 54ms/step\n",
      "Epoch 57/100\n",
      "53/53 - 3s - loss: 0.0284 - val_loss: 0.0419 - 3s/epoch - 54ms/step\n",
      "Epoch 58/100\n",
      "53/53 - 3s - loss: 0.0293 - val_loss: 0.0403 - 3s/epoch - 53ms/step\n",
      "Epoch 59/100\n",
      "53/53 - 3s - loss: 0.0290 - val_loss: 0.0338 - 3s/epoch - 54ms/step\n",
      "Epoch 60/100\n",
      "53/53 - 3s - loss: 0.0274 - val_loss: 0.0278 - 3s/epoch - 52ms/step\n",
      "Epoch 61/100\n",
      "53/53 - 3s - loss: 0.0273 - val_loss: 0.0311 - 3s/epoch - 56ms/step\n",
      "Epoch 62/100\n",
      "53/53 - 3s - loss: 0.0276 - val_loss: 0.0347 - 3s/epoch - 54ms/step\n",
      "Epoch 63/100\n",
      "53/53 - 3s - loss: 0.0279 - val_loss: 0.0413 - 3s/epoch - 56ms/step\n",
      "Epoch 64/100\n",
      "53/53 - 3s - loss: 0.0272 - val_loss: 0.0240 - 3s/epoch - 54ms/step\n",
      "Epoch 65/100\n",
      "53/53 - 3s - loss: 0.0279 - val_loss: 0.0188 - 3s/epoch - 51ms/step\n",
      "Epoch 66/100\n",
      "53/53 - 3s - loss: 0.0268 - val_loss: 0.0434 - 3s/epoch - 52ms/step\n",
      "Epoch 67/100\n",
      "53/53 - 3s - loss: 0.0260 - val_loss: 0.0562 - 3s/epoch - 54ms/step\n",
      "Epoch 68/100\n",
      "53/53 - 3s - loss: 0.0260 - val_loss: 0.0290 - 3s/epoch - 55ms/step\n",
      "Epoch 69/100\n",
      "53/53 - 3s - loss: 0.0266 - val_loss: 0.0312 - 3s/epoch - 51ms/step\n",
      "Epoch 70/100\n",
      "53/53 - 3s - loss: 0.0262 - val_loss: 0.0450 - 3s/epoch - 50ms/step\n",
      "Epoch 71/100\n",
      "53/53 - 3s - loss: 0.0274 - val_loss: 0.0347 - 3s/epoch - 51ms/step\n",
      "Epoch 72/100\n",
      "53/53 - 3s - loss: 0.0258 - val_loss: 0.0522 - 3s/epoch - 53ms/step\n",
      "Epoch 73/100\n",
      "53/53 - 3s - loss: 0.0271 - val_loss: 0.0295 - 3s/epoch - 51ms/step\n",
      "Epoch 74/100\n",
      "53/53 - 3s - loss: 0.0262 - val_loss: 0.0450 - 3s/epoch - 52ms/step\n",
      "Epoch 75/100\n",
      "53/53 - 3s - loss: 0.0258 - val_loss: 0.0239 - 3s/epoch - 51ms/step\n",
      "Epoch 76/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0300 - 3s/epoch - 54ms/step\n",
      "Epoch 77/100\n",
      "53/53 - 3s - loss: 0.0256 - val_loss: 0.0266 - 3s/epoch - 51ms/step\n",
      "Epoch 78/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0251 - 3s/epoch - 52ms/step\n",
      "Epoch 79/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0428 - 3s/epoch - 52ms/step\n",
      "Epoch 80/100\n",
      "53/53 - 3s - loss: 0.0248 - val_loss: 0.0230 - 3s/epoch - 54ms/step\n",
      "Epoch 81/100\n",
      "53/53 - 3s - loss: 0.0255 - val_loss: 0.0271 - 3s/epoch - 53ms/step\n",
      "Epoch 82/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0423 - 3s/epoch - 52ms/step\n",
      "Epoch 83/100\n",
      "53/53 - 3s - loss: 0.0245 - val_loss: 0.0229 - 3s/epoch - 49ms/step\n",
      "Epoch 84/100\n",
      "53/53 - 3s - loss: 0.0254 - val_loss: 0.0249 - 3s/epoch - 53ms/step\n",
      "Epoch 85/100\n",
      "53/53 - 3s - loss: 0.0245 - val_loss: 0.0293 - 3s/epoch - 54ms/step\n",
      "Epoch 86/100\n",
      "53/53 - 3s - loss: 0.0239 - val_loss: 0.0382 - 3s/epoch - 50ms/step\n",
      "Epoch 87/100\n",
      "53/53 - 3s - loss: 0.0246 - val_loss: 0.0420 - 3s/epoch - 51ms/step\n",
      "Epoch 88/100\n",
      "53/53 - 3s - loss: 0.0242 - val_loss: 0.0313 - 3s/epoch - 52ms/step\n",
      "Epoch 89/100\n",
      "53/53 - 3s - loss: 0.0239 - val_loss: 0.0423 - 3s/epoch - 55ms/step\n",
      "Epoch 90/100\n",
      "53/53 - 3s - loss: 0.0247 - val_loss: 0.0366 - 3s/epoch - 51ms/step\n",
      "Epoch 91/100\n",
      "53/53 - 3s - loss: 0.0233 - val_loss: 0.0365 - 3s/epoch - 54ms/step\n",
      "Epoch 92/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0285 - 3s/epoch - 52ms/step\n",
      "Epoch 93/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0410 - 3s/epoch - 56ms/step\n",
      "Epoch 94/100\n",
      "53/53 - 3s - loss: 0.0235 - val_loss: 0.0282 - 3s/epoch - 54ms/step\n",
      "Epoch 95/100\n",
      "53/53 - 3s - loss: 0.0239 - val_loss: 0.0355 - 3s/epoch - 54ms/step\n",
      "Epoch 96/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.0340 - 3s/epoch - 53ms/step\n",
      "Epoch 97/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0218 - 3s/epoch - 48ms/step\n",
      "Epoch 98/100\n",
      "53/53 - 3s - loss: 0.0229 - val_loss: 0.0264 - 3s/epoch - 53ms/step\n",
      "Epoch 99/100\n",
      "53/53 - 3s - loss: 0.0234 - val_loss: 0.0230 - 3s/epoch - 51ms/step\n",
      "Epoch 100/100\n",
      "53/53 - 3s - loss: 0.0229 - val_loss: 0.0346 - 3s/epoch - 53ms/step\n",
      "Evaluating the Performance of lstm Model\n",
      "53/53 [==============================] - 2s 17ms/step\n",
      "10/10 [==============================] - 0s 16ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 95.69393202508067\n",
      "Accuarcy of Testing Data 87.48233202819225\n",
      "Saving the lstm Model\n"
     ]
    }
   ],
   "source": [
    "## Building lstm model\n",
    "build_model(data=voltas_data_url,stock_name='Voltas',features_names=['Close'],model='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset (2468, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                 Close\n",
      "Date                  \n",
      "2013-12-10  123.699997\n",
      "2013-12-11  117.550003\n",
      "2013-12-12  117.250000\n",
      "2013-12-13  113.500000\n",
      "2013-12-16  114.650002\n",
      "Performing MinMaxScaling\n",
      "               Close\n",
      "Date                \n",
      "2013-12-10  0.019861\n",
      "2013-12-11  0.014896\n",
      "2013-12-12  0.014654\n",
      "2013-12-13  0.011626\n",
      "2013-12-16  0.012555\n",
      "Length of Training data (1726, 1)\n",
      "Length of Testing data (370, 1)\n",
      "Length of Validation data (370, 1)\n",
      "Shape of dataset is features (1676, 50, 1) and targets (1676, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "-------------Preparing bidirectional_lSTM Model----------------\n",
      "========================Summary of bidirectional_lstm==========================\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_14 (Bidirect  (None, 50, 128)           33792     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 50, 128)           0         \n",
      "                                                                 \n",
      " bidirectional_15 (Bidirect  (None, 128)               98816     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136769 (534.25 KB)\n",
      "Trainable params: 136769 (534.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the bidirectional_lstm Model====================\n",
      "Epoch 1/100\n",
      "53/53 - 11s - loss: 0.2116 - val_loss: 0.2874 - 11s/epoch - 205ms/step\n",
      "Epoch 2/100\n",
      "53/53 - 3s - loss: 0.0723 - val_loss: 0.0838 - 3s/epoch - 55ms/step\n",
      "Epoch 3/100\n",
      "53/53 - 3s - loss: 0.0530 - val_loss: 0.0388 - 3s/epoch - 54ms/step\n",
      "Epoch 4/100\n",
      "53/53 - 3s - loss: 0.0465 - val_loss: 0.0290 - 3s/epoch - 53ms/step\n",
      "Epoch 5/100\n",
      "53/53 - 3s - loss: 0.0439 - val_loss: 0.0331 - 3s/epoch - 55ms/step\n",
      "Epoch 6/100\n",
      "53/53 - 3s - loss: 0.0445 - val_loss: 0.0258 - 3s/epoch - 63ms/step\n",
      "Epoch 7/100\n",
      "53/53 - 3s - loss: 0.0429 - val_loss: 0.0335 - 3s/epoch - 66ms/step\n",
      "Epoch 8/100\n",
      "53/53 - 3s - loss: 0.0413 - val_loss: 0.0242 - 3s/epoch - 66ms/step\n",
      "Epoch 9/100\n",
      "53/53 - 3s - loss: 0.0395 - val_loss: 0.0283 - 3s/epoch - 64ms/step\n",
      "Epoch 10/100\n",
      "53/53 - 4s - loss: 0.0399 - val_loss: 0.0209 - 4s/epoch - 72ms/step\n",
      "Epoch 11/100\n",
      "53/53 - 3s - loss: 0.0412 - val_loss: 0.0244 - 3s/epoch - 66ms/step\n",
      "Epoch 12/100\n",
      "53/53 - 3s - loss: 0.0392 - val_loss: 0.0201 - 3s/epoch - 65ms/step\n",
      "Epoch 13/100\n",
      "53/53 - 3s - loss: 0.0378 - val_loss: 0.0198 - 3s/epoch - 63ms/step\n",
      "Epoch 14/100\n",
      "53/53 - 3s - loss: 0.0376 - val_loss: 0.0241 - 3s/epoch - 64ms/step\n",
      "Epoch 15/100\n",
      "53/53 - 3s - loss: 0.0370 - val_loss: 0.0192 - 3s/epoch - 64ms/step\n",
      "Epoch 16/100\n",
      "53/53 - 3s - loss: 0.0368 - val_loss: 0.0190 - 3s/epoch - 66ms/step\n",
      "Epoch 17/100\n",
      "53/53 - 3s - loss: 0.0374 - val_loss: 0.0295 - 3s/epoch - 62ms/step\n",
      "Epoch 18/100\n",
      "53/53 - 3s - loss: 0.0356 - val_loss: 0.0214 - 3s/epoch - 65ms/step\n",
      "Epoch 19/100\n",
      "53/53 - 3s - loss: 0.0348 - val_loss: 0.0225 - 3s/epoch - 63ms/step\n",
      "Epoch 20/100\n",
      "53/53 - 3s - loss: 0.0344 - val_loss: 0.0222 - 3s/epoch - 64ms/step\n",
      "Epoch 21/100\n",
      "53/53 - 3s - loss: 0.0348 - val_loss: 0.0203 - 3s/epoch - 63ms/step\n",
      "Epoch 22/100\n",
      "53/53 - 3s - loss: 0.0339 - val_loss: 0.0184 - 3s/epoch - 65ms/step\n",
      "Epoch 23/100\n",
      "53/53 - 3s - loss: 0.0342 - val_loss: 0.0176 - 3s/epoch - 64ms/step\n",
      "Epoch 24/100\n",
      "53/53 - 3s - loss: 0.0345 - val_loss: 0.0185 - 3s/epoch - 65ms/step\n",
      "Epoch 25/100\n",
      "53/53 - 3s - loss: 0.0326 - val_loss: 0.0173 - 3s/epoch - 65ms/step\n",
      "Epoch 26/100\n",
      "53/53 - 3s - loss: 0.0334 - val_loss: 0.0168 - 3s/epoch - 65ms/step\n",
      "Epoch 27/100\n",
      "53/53 - 3s - loss: 0.0328 - val_loss: 0.0270 - 3s/epoch - 64ms/step\n",
      "Epoch 28/100\n",
      "53/53 - 3s - loss: 0.0316 - val_loss: 0.0167 - 3s/epoch - 65ms/step\n",
      "Epoch 29/100\n",
      "53/53 - 3s - loss: 0.0316 - val_loss: 0.0208 - 3s/epoch - 64ms/step\n",
      "Epoch 30/100\n",
      "53/53 - 3s - loss: 0.0323 - val_loss: 0.0208 - 3s/epoch - 64ms/step\n",
      "Epoch 31/100\n",
      "53/53 - 3s - loss: 0.0320 - val_loss: 0.0173 - 3s/epoch - 63ms/step\n",
      "Epoch 32/100\n",
      "53/53 - 3s - loss: 0.0323 - val_loss: 0.0352 - 3s/epoch - 65ms/step\n",
      "Epoch 33/100\n",
      "53/53 - 3s - loss: 0.0315 - val_loss: 0.0288 - 3s/epoch - 64ms/step\n",
      "Epoch 34/100\n",
      "53/53 - 3s - loss: 0.0316 - val_loss: 0.0204 - 3s/epoch - 65ms/step\n",
      "Epoch 35/100\n",
      "53/53 - 3s - loss: 0.0293 - val_loss: 0.0258 - 3s/epoch - 64ms/step\n",
      "Epoch 36/100\n",
      "53/53 - 3s - loss: 0.0313 - val_loss: 0.0257 - 3s/epoch - 64ms/step\n",
      "Epoch 37/100\n",
      "53/53 - 4s - loss: 0.0299 - val_loss: 0.0199 - 4s/epoch - 67ms/step\n",
      "Epoch 38/100\n",
      "53/53 - 3s - loss: 0.0301 - val_loss: 0.0250 - 3s/epoch - 65ms/step\n",
      "Epoch 39/100\n",
      "53/53 - 3s - loss: 0.0312 - val_loss: 0.0188 - 3s/epoch - 64ms/step\n",
      "Epoch 40/100\n",
      "53/53 - 3s - loss: 0.0296 - val_loss: 0.0226 - 3s/epoch - 63ms/step\n",
      "Epoch 41/100\n",
      "53/53 - 3s - loss: 0.0300 - val_loss: 0.0224 - 3s/epoch - 64ms/step\n",
      "Epoch 42/100\n",
      "53/53 - 3s - loss: 0.0294 - val_loss: 0.0146 - 3s/epoch - 64ms/step\n",
      "Epoch 43/100\n",
      "53/53 - 4s - loss: 0.0282 - val_loss: 0.0188 - 4s/epoch - 68ms/step\n",
      "Epoch 44/100\n",
      "53/53 - 3s - loss: 0.0299 - val_loss: 0.0312 - 3s/epoch - 63ms/step\n",
      "Epoch 45/100\n",
      "53/53 - 3s - loss: 0.0279 - val_loss: 0.0254 - 3s/epoch - 63ms/step\n",
      "Epoch 46/100\n",
      "53/53 - 3s - loss: 0.0284 - val_loss: 0.0180 - 3s/epoch - 63ms/step\n",
      "Epoch 47/100\n",
      "53/53 - 3s - loss: 0.0289 - val_loss: 0.0148 - 3s/epoch - 64ms/step\n",
      "Epoch 48/100\n",
      "53/53 - 3s - loss: 0.0289 - val_loss: 0.0207 - 3s/epoch - 64ms/step\n",
      "Epoch 49/100\n",
      "53/53 - 3s - loss: 0.0275 - val_loss: 0.0208 - 3s/epoch - 65ms/step\n",
      "Epoch 50/100\n",
      "53/53 - 3s - loss: 0.0281 - val_loss: 0.0148 - 3s/epoch - 63ms/step\n",
      "Epoch 51/100\n",
      "53/53 - 3s - loss: 0.0282 - val_loss: 0.0190 - 3s/epoch - 64ms/step\n",
      "Epoch 52/100\n",
      "53/53 - 3s - loss: 0.0278 - val_loss: 0.0277 - 3s/epoch - 65ms/step\n",
      "Epoch 53/100\n",
      "53/53 - 3s - loss: 0.0265 - val_loss: 0.0154 - 3s/epoch - 64ms/step\n",
      "Epoch 54/100\n",
      "53/53 - 3s - loss: 0.0272 - val_loss: 0.0209 - 3s/epoch - 64ms/step\n",
      "Epoch 55/100\n",
      "53/53 - 3s - loss: 0.0275 - val_loss: 0.0264 - 3s/epoch - 66ms/step\n",
      "Epoch 56/100\n",
      "53/53 - 4s - loss: 0.0282 - val_loss: 0.0236 - 4s/epoch - 68ms/step\n",
      "Epoch 57/100\n",
      "53/53 - 4s - loss: 0.0278 - val_loss: 0.0329 - 4s/epoch - 66ms/step\n",
      "Epoch 58/100\n",
      "53/53 - 3s - loss: 0.0267 - val_loss: 0.0199 - 3s/epoch - 66ms/step\n",
      "Epoch 59/100\n",
      "53/53 - 3s - loss: 0.0258 - val_loss: 0.0144 - 3s/epoch - 64ms/step\n",
      "Epoch 60/100\n",
      "53/53 - 4s - loss: 0.0271 - val_loss: 0.0387 - 4s/epoch - 67ms/step\n",
      "Epoch 61/100\n",
      "53/53 - 3s - loss: 0.0270 - val_loss: 0.0343 - 3s/epoch - 63ms/step\n",
      "Epoch 62/100\n",
      "53/53 - 3s - loss: 0.0265 - val_loss: 0.0233 - 3s/epoch - 65ms/step\n",
      "Epoch 63/100\n",
      "53/53 - 3s - loss: 0.0263 - val_loss: 0.0427 - 3s/epoch - 64ms/step\n",
      "Epoch 64/100\n",
      "53/53 - 3s - loss: 0.0260 - val_loss: 0.0169 - 3s/epoch - 63ms/step\n",
      "Epoch 65/100\n",
      "53/53 - 3s - loss: 0.0275 - val_loss: 0.0198 - 3s/epoch - 65ms/step\n",
      "Epoch 66/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0159 - 3s/epoch - 63ms/step\n",
      "Epoch 67/100\n",
      "53/53 - 4s - loss: 0.0253 - val_loss: 0.0143 - 4s/epoch - 67ms/step\n",
      "Epoch 68/100\n",
      "53/53 - 3s - loss: 0.0264 - val_loss: 0.0137 - 3s/epoch - 66ms/step\n",
      "Epoch 69/100\n",
      "53/53 - 3s - loss: 0.0256 - val_loss: 0.0352 - 3s/epoch - 65ms/step\n",
      "Epoch 70/100\n",
      "53/53 - 3s - loss: 0.0255 - val_loss: 0.0188 - 3s/epoch - 63ms/step\n",
      "Epoch 71/100\n",
      "53/53 - 3s - loss: 0.0237 - val_loss: 0.0234 - 3s/epoch - 65ms/step\n",
      "Epoch 72/100\n",
      "53/53 - 4s - loss: 0.0253 - val_loss: 0.0386 - 4s/epoch - 70ms/step\n",
      "Epoch 73/100\n",
      "53/53 - 4s - loss: 0.0243 - val_loss: 0.0315 - 4s/epoch - 67ms/step\n",
      "Epoch 74/100\n",
      "53/53 - 3s - loss: 0.0242 - val_loss: 0.0174 - 3s/epoch - 65ms/step\n",
      "Epoch 75/100\n",
      "53/53 - 4s - loss: 0.0249 - val_loss: 0.0354 - 4s/epoch - 70ms/step\n",
      "Epoch 76/100\n",
      "53/53 - 4s - loss: 0.0245 - val_loss: 0.0179 - 4s/epoch - 72ms/step\n",
      "Epoch 77/100\n",
      "53/53 - 4s - loss: 0.0248 - val_loss: 0.0297 - 4s/epoch - 76ms/step\n",
      "Epoch 78/100\n",
      "53/53 - 4s - loss: 0.0240 - val_loss: 0.0173 - 4s/epoch - 71ms/step\n",
      "Epoch 79/100\n",
      "53/53 - 4s - loss: 0.0253 - val_loss: 0.0177 - 4s/epoch - 77ms/step\n",
      "Epoch 80/100\n",
      "53/53 - 4s - loss: 0.0235 - val_loss: 0.0287 - 4s/epoch - 76ms/step\n",
      "Epoch 81/100\n",
      "53/53 - 4s - loss: 0.0243 - val_loss: 0.0337 - 4s/epoch - 66ms/step\n",
      "Epoch 82/100\n",
      "53/53 - 4s - loss: 0.0236 - val_loss: 0.0263 - 4s/epoch - 66ms/step\n",
      "Epoch 83/100\n",
      "53/53 - 3s - loss: 0.0234 - val_loss: 0.0287 - 3s/epoch - 65ms/step\n",
      "Epoch 84/100\n",
      "53/53 - 3s - loss: 0.0229 - val_loss: 0.0230 - 3s/epoch - 66ms/step\n",
      "Epoch 85/100\n",
      "53/53 - 4s - loss: 0.0241 - val_loss: 0.0270 - 4s/epoch - 75ms/step\n",
      "Epoch 86/100\n",
      "53/53 - 4s - loss: 0.0234 - val_loss: 0.0397 - 4s/epoch - 66ms/step\n",
      "Epoch 87/100\n",
      "53/53 - 4s - loss: 0.0242 - val_loss: 0.0247 - 4s/epoch - 66ms/step\n",
      "Epoch 88/100\n",
      "53/53 - 4s - loss: 0.0234 - val_loss: 0.0187 - 4s/epoch - 67ms/step\n",
      "Epoch 89/100\n",
      "53/53 - 3s - loss: 0.0244 - val_loss: 0.0293 - 3s/epoch - 64ms/step\n",
      "Epoch 90/100\n",
      "53/53 - 4s - loss: 0.0230 - val_loss: 0.0494 - 4s/epoch - 67ms/step\n",
      "Epoch 91/100\n",
      "53/53 - 3s - loss: 0.0225 - val_loss: 0.0341 - 3s/epoch - 65ms/step\n",
      "Epoch 92/100\n",
      "53/53 - 3s - loss: 0.0232 - val_loss: 0.0200 - 3s/epoch - 66ms/step\n",
      "Epoch 93/100\n",
      "53/53 - 3s - loss: 0.0229 - val_loss: 0.0288 - 3s/epoch - 66ms/step\n",
      "Epoch 94/100\n",
      "53/53 - 4s - loss: 0.0228 - val_loss: 0.0326 - 4s/epoch - 69ms/step\n",
      "Epoch 95/100\n",
      "53/53 - 4s - loss: 0.0227 - val_loss: 0.0301 - 4s/epoch - 72ms/step\n",
      "Epoch 96/100\n",
      "53/53 - 4s - loss: 0.0222 - val_loss: 0.0241 - 4s/epoch - 72ms/step\n",
      "Epoch 97/100\n",
      "53/53 - 3s - loss: 0.0231 - val_loss: 0.0327 - 3s/epoch - 66ms/step\n",
      "Epoch 98/100\n",
      "53/53 - 4s - loss: 0.0229 - val_loss: 0.0208 - 4s/epoch - 68ms/step\n",
      "Epoch 99/100\n",
      "53/53 - 4s - loss: 0.0233 - val_loss: 0.0140 - 4s/epoch - 67ms/step\n",
      "Epoch 100/100\n",
      "53/53 - 3s - loss: 0.0227 - val_loss: 0.0126 - 3s/epoch - 65ms/step\n",
      "Evaluating the Performance of bidirectional_lstm Model\n",
      "53/53 [==============================] - 2s 19ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 96.4227252423666\n",
      "Accuarcy of Testing Data 96.25128935610711\n",
      "Saving the bidirectional_lstm Model\n"
     ]
    }
   ],
   "source": [
    "## Building bidirectional_lstm model\n",
    "build_model(data=voltas_data_url,stock_name='Voltas',features_names=['Close'],model='bidirectional_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset (1661, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                  Open\n",
      "Date                  \n",
      "2017-03-22  641.549988\n",
      "2017-03-23  637.900024\n",
      "2017-03-24  635.450012\n",
      "2017-03-27  615.000000\n",
      "2017-03-28  617.200012\n",
      "Performing MinMaxScaling\n",
      "                Open\n",
      "Date                \n",
      "2017-03-22  0.005327\n",
      "2017-03-23  0.004595\n",
      "2017-03-24  0.004103\n",
      "2017-03-27  0.000000\n",
      "2017-03-28  0.000441\n",
      "Length of Training data (1162, 1)\n",
      "Length of Testing data (249, 1)\n",
      "Length of Validation data (250, 1)\n",
      "Shape of dataset is features (1112, 50, 1) and targets (1112, 1)\n",
      "Shape of dataset is features (199, 50, 1) and targets (199, 1)\n",
      "Shape of dataset is features (200, 50, 1) and targets (200, 1)\n",
      "-------------Preparing LSTM Model----------------\n",
      "========================Summary of lstm==========================\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_36 (LSTM)              (None, 50, 50)            10400     \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 50, 50)            0         \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 32)                1632      \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32265 (126.04 KB)\n",
      "Trainable params: 32265 (126.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the lstm Model====================\n",
      "Epoch 1/100\n",
      "35/35 - 8s - loss: 0.2140 - val_loss: 0.3939 - 8s/epoch - 215ms/step\n",
      "Epoch 2/100\n",
      "35/35 - 2s - loss: 0.1044 - val_loss: 0.0864 - 2s/epoch - 50ms/step\n",
      "Epoch 3/100\n",
      "35/35 - 2s - loss: 0.0601 - val_loss: 0.0806 - 2s/epoch - 52ms/step\n",
      "Epoch 4/100\n",
      "35/35 - 2s - loss: 0.0483 - val_loss: 0.0278 - 2s/epoch - 51ms/step\n",
      "Epoch 5/100\n",
      "35/35 - 2s - loss: 0.0429 - val_loss: 0.0213 - 2s/epoch - 54ms/step\n",
      "Epoch 6/100\n",
      "35/35 - 2s - loss: 0.0424 - val_loss: 0.0281 - 2s/epoch - 50ms/step\n",
      "Epoch 7/100\n",
      "35/35 - 2s - loss: 0.0394 - val_loss: 0.0257 - 2s/epoch - 51ms/step\n",
      "Epoch 8/100\n",
      "35/35 - 2s - loss: 0.0388 - val_loss: 0.0245 - 2s/epoch - 52ms/step\n",
      "Epoch 9/100\n",
      "35/35 - 2s - loss: 0.0395 - val_loss: 0.0207 - 2s/epoch - 52ms/step\n",
      "Epoch 10/100\n",
      "35/35 - 2s - loss: 0.0365 - val_loss: 0.0205 - 2s/epoch - 52ms/step\n",
      "Epoch 11/100\n",
      "35/35 - 2s - loss: 0.0368 - val_loss: 0.0227 - 2s/epoch - 50ms/step\n",
      "Epoch 12/100\n",
      "35/35 - 2s - loss: 0.0348 - val_loss: 0.0245 - 2s/epoch - 45ms/step\n",
      "Epoch 13/100\n",
      "35/35 - 2s - loss: 0.0361 - val_loss: 0.0253 - 2s/epoch - 51ms/step\n",
      "Epoch 14/100\n",
      "35/35 - 2s - loss: 0.0363 - val_loss: 0.0201 - 2s/epoch - 52ms/step\n",
      "Epoch 15/100\n",
      "35/35 - 2s - loss: 0.0348 - val_loss: 0.0206 - 2s/epoch - 46ms/step\n",
      "Epoch 16/100\n",
      "35/35 - 2s - loss: 0.0357 - val_loss: 0.0213 - 2s/epoch - 52ms/step\n",
      "Epoch 17/100\n",
      "35/35 - 2s - loss: 0.0355 - val_loss: 0.0198 - 2s/epoch - 55ms/step\n",
      "Epoch 18/100\n",
      "35/35 - 2s - loss: 0.0345 - val_loss: 0.0261 - 2s/epoch - 55ms/step\n",
      "Epoch 19/100\n",
      "35/35 - 2s - loss: 0.0358 - val_loss: 0.0197 - 2s/epoch - 52ms/step\n",
      "Epoch 20/100\n",
      "35/35 - 2s - loss: 0.0347 - val_loss: 0.0214 - 2s/epoch - 52ms/step\n",
      "Epoch 21/100\n",
      "35/35 - 2s - loss: 0.0346 - val_loss: 0.0235 - 2s/epoch - 52ms/step\n",
      "Epoch 22/100\n",
      "35/35 - 2s - loss: 0.0350 - val_loss: 0.0369 - 2s/epoch - 52ms/step\n",
      "Epoch 23/100\n",
      "35/35 - 2s - loss: 0.0337 - val_loss: 0.0199 - 2s/epoch - 52ms/step\n",
      "Epoch 24/100\n",
      "35/35 - 2s - loss: 0.0361 - val_loss: 0.0259 - 2s/epoch - 55ms/step\n",
      "Epoch 25/100\n",
      "35/35 - 2s - loss: 0.0330 - val_loss: 0.0194 - 2s/epoch - 52ms/step\n",
      "Epoch 26/100\n",
      "35/35 - 2s - loss: 0.0337 - val_loss: 0.0225 - 2s/epoch - 55ms/step\n",
      "Epoch 27/100\n",
      "35/35 - 2s - loss: 0.0326 - val_loss: 0.0191 - 2s/epoch - 57ms/step\n",
      "Epoch 28/100\n",
      "35/35 - 2s - loss: 0.0335 - val_loss: 0.0204 - 2s/epoch - 55ms/step\n",
      "Epoch 29/100\n",
      "35/35 - 2s - loss: 0.0347 - val_loss: 0.0323 - 2s/epoch - 52ms/step\n",
      "Epoch 30/100\n",
      "35/35 - 2s - loss: 0.0328 - val_loss: 0.0189 - 2s/epoch - 48ms/step\n",
      "Epoch 31/100\n",
      "35/35 - 2s - loss: 0.0322 - val_loss: 0.0189 - 2s/epoch - 53ms/step\n",
      "Epoch 32/100\n",
      "35/35 - 2s - loss: 0.0322 - val_loss: 0.0217 - 2s/epoch - 55ms/step\n",
      "Epoch 33/100\n",
      "35/35 - 2s - loss: 0.0338 - val_loss: 0.0214 - 2s/epoch - 51ms/step\n",
      "Epoch 34/100\n",
      "35/35 - 2s - loss: 0.0331 - val_loss: 0.0213 - 2s/epoch - 53ms/step\n",
      "Epoch 35/100\n",
      "35/35 - 2s - loss: 0.0319 - val_loss: 0.0188 - 2s/epoch - 51ms/step\n",
      "Epoch 36/100\n",
      "35/35 - 2s - loss: 0.0333 - val_loss: 0.0215 - 2s/epoch - 50ms/step\n",
      "Epoch 37/100\n",
      "35/35 - 2s - loss: 0.0310 - val_loss: 0.0197 - 2s/epoch - 55ms/step\n",
      "Epoch 38/100\n",
      "35/35 - 2s - loss: 0.0315 - val_loss: 0.0189 - 2s/epoch - 51ms/step\n",
      "Epoch 39/100\n",
      "35/35 - 2s - loss: 0.0319 - val_loss: 0.0216 - 2s/epoch - 55ms/step\n",
      "Epoch 40/100\n",
      "35/35 - 2s - loss: 0.0306 - val_loss: 0.0228 - 2s/epoch - 50ms/step\n",
      "Epoch 41/100\n",
      "35/35 - 2s - loss: 0.0305 - val_loss: 0.0213 - 2s/epoch - 44ms/step\n",
      "Epoch 42/100\n",
      "35/35 - 2s - loss: 0.0305 - val_loss: 0.0186 - 2s/epoch - 57ms/step\n",
      "Epoch 43/100\n",
      "35/35 - 2s - loss: 0.0302 - val_loss: 0.0298 - 2s/epoch - 56ms/step\n",
      "Epoch 44/100\n",
      "35/35 - 2s - loss: 0.0307 - val_loss: 0.0214 - 2s/epoch - 48ms/step\n",
      "Epoch 45/100\n",
      "35/35 - 2s - loss: 0.0302 - val_loss: 0.0264 - 2s/epoch - 50ms/step\n",
      "Epoch 46/100\n",
      "35/35 - 2s - loss: 0.0304 - val_loss: 0.0221 - 2s/epoch - 49ms/step\n",
      "Epoch 47/100\n",
      "35/35 - 2s - loss: 0.0301 - val_loss: 0.0205 - 2s/epoch - 55ms/step\n",
      "Epoch 48/100\n",
      "35/35 - 2s - loss: 0.0309 - val_loss: 0.0198 - 2s/epoch - 56ms/step\n",
      "Epoch 49/100\n",
      "35/35 - 2s - loss: 0.0302 - val_loss: 0.0182 - 2s/epoch - 49ms/step\n",
      "Epoch 50/100\n",
      "35/35 - 2s - loss: 0.0301 - val_loss: 0.0193 - 2s/epoch - 55ms/step\n",
      "Epoch 51/100\n",
      "35/35 - 2s - loss: 0.0293 - val_loss: 0.0195 - 2s/epoch - 54ms/step\n",
      "Epoch 52/100\n",
      "35/35 - 2s - loss: 0.0299 - val_loss: 0.0189 - 2s/epoch - 52ms/step\n",
      "Epoch 53/100\n",
      "35/35 - 2s - loss: 0.0301 - val_loss: 0.0200 - 2s/epoch - 55ms/step\n",
      "Epoch 54/100\n",
      "35/35 - 2s - loss: 0.0299 - val_loss: 0.0204 - 2s/epoch - 67ms/step\n",
      "Epoch 55/100\n",
      "35/35 - 2s - loss: 0.0281 - val_loss: 0.0180 - 2s/epoch - 57ms/step\n",
      "Epoch 56/100\n",
      "35/35 - 2s - loss: 0.0292 - val_loss: 0.0180 - 2s/epoch - 53ms/step\n",
      "Epoch 57/100\n",
      "35/35 - 2s - loss: 0.0300 - val_loss: 0.0181 - 2s/epoch - 50ms/step\n",
      "Epoch 58/100\n",
      "35/35 - 2s - loss: 0.0302 - val_loss: 0.0226 - 2s/epoch - 55ms/step\n",
      "Epoch 59/100\n",
      "35/35 - 2s - loss: 0.0299 - val_loss: 0.0246 - 2s/epoch - 54ms/step\n",
      "Epoch 60/100\n",
      "35/35 - 2s - loss: 0.0289 - val_loss: 0.0287 - 2s/epoch - 54ms/step\n",
      "Epoch 61/100\n",
      "35/35 - 2s - loss: 0.0296 - val_loss: 0.0178 - 2s/epoch - 58ms/step\n",
      "Epoch 62/100\n",
      "35/35 - 2s - loss: 0.0299 - val_loss: 0.0195 - 2s/epoch - 57ms/step\n",
      "Epoch 63/100\n",
      "35/35 - 2s - loss: 0.0287 - val_loss: 0.0178 - 2s/epoch - 57ms/step\n",
      "Epoch 64/100\n",
      "35/35 - 2s - loss: 0.0284 - val_loss: 0.0177 - 2s/epoch - 56ms/step\n",
      "Epoch 65/100\n",
      "35/35 - 2s - loss: 0.0277 - val_loss: 0.0176 - 2s/epoch - 53ms/step\n",
      "Epoch 66/100\n",
      "35/35 - 2s - loss: 0.0289 - val_loss: 0.0237 - 2s/epoch - 57ms/step\n",
      "Epoch 67/100\n",
      "35/35 - 2s - loss: 0.0272 - val_loss: 0.0176 - 2s/epoch - 54ms/step\n",
      "Epoch 68/100\n",
      "35/35 - 2s - loss: 0.0270 - val_loss: 0.0234 - 2s/epoch - 56ms/step\n",
      "Epoch 69/100\n",
      "35/35 - 2s - loss: 0.0280 - val_loss: 0.0175 - 2s/epoch - 54ms/step\n",
      "Epoch 70/100\n",
      "35/35 - 2s - loss: 0.0280 - val_loss: 0.0175 - 2s/epoch - 53ms/step\n",
      "Epoch 71/100\n",
      "35/35 - 2s - loss: 0.0270 - val_loss: 0.0177 - 2s/epoch - 51ms/step\n",
      "Epoch 72/100\n",
      "35/35 - 2s - loss: 0.0271 - val_loss: 0.0182 - 2s/epoch - 55ms/step\n",
      "Epoch 73/100\n",
      "35/35 - 2s - loss: 0.0280 - val_loss: 0.0178 - 2s/epoch - 48ms/step\n",
      "Epoch 74/100\n",
      "35/35 - 2s - loss: 0.0293 - val_loss: 0.0183 - 2s/epoch - 50ms/step\n",
      "Epoch 75/100\n",
      "35/35 - 2s - loss: 0.0287 - val_loss: 0.0173 - 2s/epoch - 53ms/step\n",
      "Epoch 76/100\n",
      "35/35 - 2s - loss: 0.0278 - val_loss: 0.0175 - 2s/epoch - 48ms/step\n",
      "Epoch 77/100\n",
      "35/35 - 2s - loss: 0.0266 - val_loss: 0.0174 - 2s/epoch - 52ms/step\n",
      "Epoch 78/100\n",
      "35/35 - 2s - loss: 0.0265 - val_loss: 0.0176 - 2s/epoch - 47ms/step\n",
      "Epoch 79/100\n",
      "35/35 - 2s - loss: 0.0265 - val_loss: 0.0215 - 2s/epoch - 57ms/step\n",
      "Epoch 80/100\n",
      "35/35 - 2s - loss: 0.0269 - val_loss: 0.0242 - 2s/epoch - 49ms/step\n",
      "Epoch 81/100\n",
      "35/35 - 2s - loss: 0.0268 - val_loss: 0.0183 - 2s/epoch - 45ms/step\n",
      "Epoch 82/100\n",
      "35/35 - 2s - loss: 0.0271 - val_loss: 0.0172 - 2s/epoch - 53ms/step\n",
      "Epoch 83/100\n",
      "35/35 - 2s - loss: 0.0268 - val_loss: 0.0171 - 2s/epoch - 56ms/step\n",
      "Epoch 84/100\n",
      "35/35 - 2s - loss: 0.0276 - val_loss: 0.0192 - 2s/epoch - 55ms/step\n",
      "Epoch 85/100\n",
      "35/35 - 2s - loss: 0.0269 - val_loss: 0.0192 - 2s/epoch - 58ms/step\n",
      "Epoch 86/100\n",
      "35/35 - 2s - loss: 0.0269 - val_loss: 0.0194 - 2s/epoch - 52ms/step\n",
      "Epoch 87/100\n",
      "35/35 - 2s - loss: 0.0281 - val_loss: 0.0171 - 2s/epoch - 50ms/step\n",
      "Epoch 88/100\n",
      "35/35 - 2s - loss: 0.0268 - val_loss: 0.0195 - 2s/epoch - 52ms/step\n",
      "Epoch 89/100\n",
      "35/35 - 2s - loss: 0.0263 - val_loss: 0.0189 - 2s/epoch - 50ms/step\n",
      "Epoch 90/100\n",
      "35/35 - 2s - loss: 0.0268 - val_loss: 0.0184 - 2s/epoch - 55ms/step\n",
      "Epoch 91/100\n",
      "35/35 - 2s - loss: 0.0259 - val_loss: 0.0176 - 2s/epoch - 55ms/step\n",
      "Epoch 92/100\n",
      "35/35 - 2s - loss: 0.0265 - val_loss: 0.0178 - 2s/epoch - 56ms/step\n",
      "Epoch 93/100\n",
      "35/35 - 2s - loss: 0.0263 - val_loss: 0.0168 - 2s/epoch - 50ms/step\n",
      "Epoch 94/100\n",
      "35/35 - 2s - loss: 0.0249 - val_loss: 0.0201 - 2s/epoch - 51ms/step\n",
      "Epoch 95/100\n",
      "35/35 - 2s - loss: 0.0261 - val_loss: 0.0233 - 2s/epoch - 53ms/step\n",
      "Epoch 96/100\n",
      "35/35 - 2s - loss: 0.0258 - val_loss: 0.0170 - 2s/epoch - 53ms/step\n",
      "Epoch 97/100\n",
      "35/35 - 2s - loss: 0.0249 - val_loss: 0.0169 - 2s/epoch - 54ms/step\n",
      "Epoch 98/100\n",
      "35/35 - 2s - loss: 0.0267 - val_loss: 0.0167 - 2s/epoch - 55ms/step\n",
      "Epoch 99/100\n",
      "35/35 - 2s - loss: 0.0268 - val_loss: 0.0221 - 2s/epoch - 55ms/step\n",
      "Epoch 100/100\n",
      "35/35 - 2s - loss: 0.0258 - val_loss: 0.0175 - 2s/epoch - 54ms/step\n",
      "Evaluating the Performance of lstm Model\n",
      "35/35 [==============================] - 1s 16ms/step\n",
      "7/7 [==============================] - 0s 15ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 95.28397825202075\n",
      "Accuarcy of Testing Data 96.32487845373407\n",
      "Saving the lstm Model\n",
      "shape of the dataset (1661, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                 Close\n",
      "Date                  \n",
      "2017-03-22  638.549988\n",
      "2017-03-23  634.849976\n",
      "2017-03-24  616.900024\n",
      "2017-03-27  614.400024\n",
      "2017-03-28  628.799988\n",
      "Performing MinMaxScaling\n",
      "               Close\n",
      "Date                \n",
      "2017-03-22  0.005128\n",
      "2017-03-23  0.004342\n",
      "2017-03-24  0.000531\n",
      "2017-03-27  0.000000\n",
      "2017-03-28  0.003058\n",
      "Length of Training data (1162, 1)\n",
      "Length of Testing data (249, 1)\n",
      "Length of Validation data (250, 1)\n",
      "Shape of dataset is features (1112, 50, 1) and targets (1112, 1)\n",
      "Shape of dataset is features (199, 50, 1) and targets (199, 1)\n",
      "Shape of dataset is features (200, 50, 1) and targets (200, 1)\n",
      "-------------Preparing LSTM Model----------------\n",
      "========================Summary of lstm==========================\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_38 (LSTM)              (None, 50, 50)            10400     \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 50, 50)            0         \n",
      "                                                                 \n",
      " lstm_39 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 32)                1632      \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32265 (126.04 KB)\n",
      "Trainable params: 32265 (126.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the lstm Model====================\n",
      "Epoch 1/100\n",
      "35/35 - 7s - loss: 0.2795 - val_loss: 0.5694 - 7s/epoch - 191ms/step\n",
      "Epoch 2/100\n",
      "35/35 - 2s - loss: 0.2021 - val_loss: 0.4048 - 2s/epoch - 46ms/step\n",
      "Epoch 3/100\n",
      "35/35 - 2s - loss: 0.1028 - val_loss: 0.1047 - 2s/epoch - 58ms/step\n",
      "Epoch 4/100\n",
      "35/35 - 2s - loss: 0.0681 - val_loss: 0.0853 - 2s/epoch - 55ms/step\n",
      "Epoch 5/100\n",
      "35/35 - 2s - loss: 0.0514 - val_loss: 0.0239 - 2s/epoch - 53ms/step\n",
      "Epoch 6/100\n",
      "35/35 - 2s - loss: 0.0451 - val_loss: 0.0237 - 2s/epoch - 57ms/step\n",
      "Epoch 7/100\n",
      "35/35 - 2s - loss: 0.0413 - val_loss: 0.0257 - 2s/epoch - 57ms/step\n",
      "Epoch 8/100\n",
      "35/35 - 2s - loss: 0.0414 - val_loss: 0.0254 - 2s/epoch - 57ms/step\n",
      "Epoch 9/100\n",
      "35/35 - 2s - loss: 0.0420 - val_loss: 0.0229 - 2s/epoch - 57ms/step\n",
      "Epoch 10/100\n",
      "35/35 - 2s - loss: 0.0426 - val_loss: 0.0272 - 2s/epoch - 57ms/step\n",
      "Epoch 11/100\n",
      "35/35 - 2s - loss: 0.0389 - val_loss: 0.0236 - 2s/epoch - 55ms/step\n",
      "Epoch 12/100\n",
      "35/35 - 2s - loss: 0.0378 - val_loss: 0.0227 - 2s/epoch - 51ms/step\n",
      "Epoch 13/100\n",
      "35/35 - 2s - loss: 0.0373 - val_loss: 0.0230 - 2s/epoch - 48ms/step\n",
      "Epoch 14/100\n",
      "35/35 - 2s - loss: 0.0389 - val_loss: 0.0260 - 2s/epoch - 53ms/step\n",
      "Epoch 15/100\n",
      "35/35 - 2s - loss: 0.0360 - val_loss: 0.0221 - 2s/epoch - 52ms/step\n",
      "Epoch 16/100\n",
      "35/35 - 2s - loss: 0.0373 - val_loss: 0.0221 - 2s/epoch - 55ms/step\n",
      "Epoch 17/100\n",
      "35/35 - 2s - loss: 0.0373 - val_loss: 0.0319 - 2s/epoch - 52ms/step\n",
      "Epoch 18/100\n",
      "35/35 - 2s - loss: 0.0369 - val_loss: 0.0301 - 2s/epoch - 44ms/step\n",
      "Epoch 19/100\n",
      "35/35 - 2s - loss: 0.0380 - val_loss: 0.0526 - 2s/epoch - 51ms/step\n",
      "Epoch 20/100\n",
      "35/35 - 2s - loss: 0.0375 - val_loss: 0.0218 - 2s/epoch - 57ms/step\n",
      "Epoch 21/100\n",
      "35/35 - 2s - loss: 0.0367 - val_loss: 0.0222 - 2s/epoch - 56ms/step\n",
      "Epoch 22/100\n",
      "35/35 - 2s - loss: 0.0369 - val_loss: 0.0216 - 2s/epoch - 57ms/step\n",
      "Epoch 23/100\n",
      "35/35 - 2s - loss: 0.0353 - val_loss: 0.0226 - 2s/epoch - 56ms/step\n",
      "Epoch 24/100\n",
      "35/35 - 2s - loss: 0.0363 - val_loss: 0.0241 - 2s/epoch - 50ms/step\n",
      "Epoch 25/100\n",
      "35/35 - 2s - loss: 0.0349 - val_loss: 0.0215 - 2s/epoch - 51ms/step\n",
      "Epoch 26/100\n",
      "35/35 - 2s - loss: 0.0337 - val_loss: 0.0223 - 2s/epoch - 49ms/step\n",
      "Epoch 27/100\n",
      "35/35 - 2s - loss: 0.0372 - val_loss: 0.0222 - 2s/epoch - 55ms/step\n",
      "Epoch 28/100\n",
      "35/35 - 2s - loss: 0.0355 - val_loss: 0.0212 - 2s/epoch - 51ms/step\n",
      "Epoch 29/100\n",
      "35/35 - 2s - loss: 0.0356 - val_loss: 0.0255 - 2s/epoch - 51ms/step\n",
      "Epoch 30/100\n",
      "35/35 - 2s - loss: 0.0348 - val_loss: 0.0213 - 2s/epoch - 58ms/step\n",
      "Epoch 31/100\n",
      "35/35 - 2s - loss: 0.0350 - val_loss: 0.0213 - 2s/epoch - 50ms/step\n",
      "Epoch 32/100\n",
      "35/35 - 2s - loss: 0.0353 - val_loss: 0.0210 - 2s/epoch - 49ms/step\n",
      "Epoch 33/100\n",
      "35/35 - 2s - loss: 0.0331 - val_loss: 0.0225 - 2s/epoch - 55ms/step\n",
      "Epoch 34/100\n",
      "35/35 - 2s - loss: 0.0339 - val_loss: 0.0255 - 2s/epoch - 53ms/step\n",
      "Epoch 35/100\n",
      "35/35 - 2s - loss: 0.0340 - val_loss: 0.0207 - 2s/epoch - 55ms/step\n",
      "Epoch 36/100\n",
      "35/35 - 2s - loss: 0.0349 - val_loss: 0.0219 - 2s/epoch - 54ms/step\n",
      "Epoch 37/100\n",
      "35/35 - 2s - loss: 0.0338 - val_loss: 0.0206 - 2s/epoch - 55ms/step\n",
      "Epoch 38/100\n",
      "35/35 - 2s - loss: 0.0361 - val_loss: 0.0261 - 2s/epoch - 48ms/step\n",
      "Epoch 39/100\n",
      "35/35 - 2s - loss: 0.0337 - val_loss: 0.0217 - 2s/epoch - 52ms/step\n",
      "Epoch 40/100\n",
      "35/35 - 2s - loss: 0.0344 - val_loss: 0.0228 - 2s/epoch - 52ms/step\n",
      "Epoch 41/100\n",
      "35/35 - 2s - loss: 0.0336 - val_loss: 0.0209 - 2s/epoch - 55ms/step\n",
      "Epoch 42/100\n",
      "35/35 - 2s - loss: 0.0344 - val_loss: 0.0205 - 2s/epoch - 56ms/step\n",
      "Epoch 43/100\n",
      "35/35 - 2s - loss: 0.0336 - val_loss: 0.0206 - 2s/epoch - 58ms/step\n",
      "Epoch 44/100\n",
      "35/35 - 2s - loss: 0.0342 - val_loss: 0.0212 - 2s/epoch - 56ms/step\n",
      "Epoch 45/100\n",
      "35/35 - 2s - loss: 0.0327 - val_loss: 0.0230 - 2s/epoch - 51ms/step\n",
      "Epoch 46/100\n",
      "35/35 - 2s - loss: 0.0340 - val_loss: 0.0209 - 2s/epoch - 49ms/step\n",
      "Epoch 47/100\n",
      "35/35 - 2s - loss: 0.0341 - val_loss: 0.0268 - 2s/epoch - 49ms/step\n",
      "Epoch 48/100\n",
      "35/35 - 2s - loss: 0.0324 - val_loss: 0.0232 - 2s/epoch - 53ms/step\n",
      "Epoch 49/100\n",
      "35/35 - 2s - loss: 0.0331 - val_loss: 0.0213 - 2s/epoch - 51ms/step\n",
      "Epoch 50/100\n",
      "35/35 - 2s - loss: 0.0319 - val_loss: 0.0203 - 2s/epoch - 55ms/step\n",
      "Epoch 51/100\n",
      "35/35 - 2s - loss: 0.0326 - val_loss: 0.0298 - 2s/epoch - 43ms/step\n",
      "Epoch 52/100\n",
      "35/35 - 2s - loss: 0.0317 - val_loss: 0.0198 - 2s/epoch - 56ms/step\n",
      "Epoch 53/100\n",
      "35/35 - 2s - loss: 0.0328 - val_loss: 0.0200 - 2s/epoch - 51ms/step\n",
      "Epoch 54/100\n",
      "35/35 - 2s - loss: 0.0320 - val_loss: 0.0272 - 2s/epoch - 49ms/step\n",
      "Epoch 55/100\n",
      "35/35 - 2s - loss: 0.0334 - val_loss: 0.0210 - 2s/epoch - 51ms/step\n",
      "Epoch 56/100\n",
      "35/35 - 2s - loss: 0.0322 - val_loss: 0.0234 - 2s/epoch - 53ms/step\n",
      "Epoch 57/100\n",
      "35/35 - 2s - loss: 0.0316 - val_loss: 0.0205 - 2s/epoch - 54ms/step\n",
      "Epoch 58/100\n",
      "35/35 - 2s - loss: 0.0323 - val_loss: 0.0199 - 2s/epoch - 50ms/step\n",
      "Epoch 59/100\n",
      "35/35 - 2s - loss: 0.0323 - val_loss: 0.0201 - 2s/epoch - 57ms/step\n",
      "Epoch 60/100\n",
      "35/35 - 2s - loss: 0.0316 - val_loss: 0.0238 - 2s/epoch - 53ms/step\n",
      "Epoch 61/100\n",
      "35/35 - 2s - loss: 0.0317 - val_loss: 0.0251 - 2s/epoch - 51ms/step\n",
      "Epoch 62/100\n",
      "35/35 - 2s - loss: 0.0320 - val_loss: 0.0217 - 2s/epoch - 53ms/step\n",
      "Epoch 63/100\n",
      "35/35 - 2s - loss: 0.0305 - val_loss: 0.0273 - 2s/epoch - 52ms/step\n",
      "Epoch 64/100\n",
      "35/35 - 2s - loss: 0.0326 - val_loss: 0.0197 - 2s/epoch - 54ms/step\n",
      "Epoch 65/100\n",
      "35/35 - 2s - loss: 0.0305 - val_loss: 0.0195 - 2s/epoch - 50ms/step\n",
      "Epoch 66/100\n",
      "35/35 - 2s - loss: 0.0302 - val_loss: 0.0238 - 2s/epoch - 53ms/step\n",
      "Epoch 67/100\n",
      "35/35 - 2s - loss: 0.0310 - val_loss: 0.0246 - 2s/epoch - 52ms/step\n",
      "Epoch 68/100\n",
      "35/35 - 2s - loss: 0.0302 - val_loss: 0.0193 - 2s/epoch - 52ms/step\n",
      "Epoch 69/100\n",
      "35/35 - 2s - loss: 0.0316 - val_loss: 0.0191 - 2s/epoch - 51ms/step\n",
      "Epoch 70/100\n",
      "35/35 - 2s - loss: 0.0304 - val_loss: 0.0232 - 2s/epoch - 53ms/step\n",
      "Epoch 71/100\n",
      "35/35 - 2s - loss: 0.0295 - val_loss: 0.0193 - 2s/epoch - 52ms/step\n",
      "Epoch 72/100\n",
      "35/35 - 2s - loss: 0.0308 - val_loss: 0.0211 - 2s/epoch - 55ms/step\n",
      "Epoch 73/100\n",
      "35/35 - 2s - loss: 0.0308 - val_loss: 0.0198 - 2s/epoch - 46ms/step\n",
      "Epoch 74/100\n",
      "35/35 - 2s - loss: 0.0286 - val_loss: 0.0256 - 2s/epoch - 49ms/step\n",
      "Epoch 75/100\n",
      "35/35 - 2s - loss: 0.0311 - val_loss: 0.0213 - 2s/epoch - 55ms/step\n",
      "Epoch 76/100\n",
      "35/35 - 2s - loss: 0.0305 - val_loss: 0.0248 - 2s/epoch - 53ms/step\n",
      "Epoch 77/100\n",
      "35/35 - 2s - loss: 0.0287 - val_loss: 0.0188 - 2s/epoch - 56ms/step\n",
      "Epoch 78/100\n",
      "35/35 - 2s - loss: 0.0300 - val_loss: 0.0200 - 2s/epoch - 57ms/step\n",
      "Epoch 79/100\n",
      "35/35 - 2s - loss: 0.0304 - val_loss: 0.0211 - 2s/epoch - 57ms/step\n",
      "Epoch 80/100\n",
      "35/35 - 2s - loss: 0.0297 - val_loss: 0.0200 - 2s/epoch - 54ms/step\n",
      "Epoch 81/100\n",
      "35/35 - 2s - loss: 0.0298 - val_loss: 0.0189 - 2s/epoch - 53ms/step\n",
      "Epoch 82/100\n",
      "35/35 - 2s - loss: 0.0285 - val_loss: 0.0191 - 2s/epoch - 52ms/step\n",
      "Epoch 83/100\n",
      "35/35 - 2s - loss: 0.0295 - val_loss: 0.0207 - 2s/epoch - 52ms/step\n",
      "Epoch 84/100\n",
      "35/35 - 2s - loss: 0.0292 - val_loss: 0.0191 - 2s/epoch - 52ms/step\n",
      "Epoch 85/100\n",
      "35/35 - 2s - loss: 0.0288 - val_loss: 0.0235 - 2s/epoch - 56ms/step\n",
      "Epoch 86/100\n",
      "35/35 - 2s - loss: 0.0291 - val_loss: 0.0217 - 2s/epoch - 53ms/step\n",
      "Epoch 87/100\n",
      "35/35 - 2s - loss: 0.0281 - val_loss: 0.0190 - 2s/epoch - 49ms/step\n",
      "Epoch 88/100\n",
      "35/35 - 2s - loss: 0.0282 - val_loss: 0.0196 - 2s/epoch - 53ms/step\n",
      "Epoch 89/100\n",
      "35/35 - 2s - loss: 0.0283 - val_loss: 0.0187 - 2s/epoch - 50ms/step\n",
      "Epoch 90/100\n",
      "35/35 - 2s - loss: 0.0286 - val_loss: 0.0245 - 2s/epoch - 52ms/step\n",
      "Epoch 91/100\n",
      "35/35 - 2s - loss: 0.0291 - val_loss: 0.0204 - 2s/epoch - 55ms/step\n",
      "Epoch 92/100\n",
      "35/35 - 2s - loss: 0.0268 - val_loss: 0.0188 - 2s/epoch - 55ms/step\n",
      "Epoch 93/100\n",
      "35/35 - 2s - loss: 0.0293 - val_loss: 0.0217 - 2s/epoch - 51ms/step\n",
      "Epoch 94/100\n",
      "35/35 - 2s - loss: 0.0294 - val_loss: 0.0184 - 2s/epoch - 46ms/step\n",
      "Epoch 95/100\n",
      "35/35 - 2s - loss: 0.0280 - val_loss: 0.0185 - 2s/epoch - 54ms/step\n",
      "Epoch 96/100\n",
      "35/35 - 2s - loss: 0.0285 - val_loss: 0.0213 - 2s/epoch - 52ms/step\n",
      "Epoch 97/100\n",
      "35/35 - 2s - loss: 0.0266 - val_loss: 0.0187 - 2s/epoch - 54ms/step\n",
      "Epoch 98/100\n",
      "35/35 - 2s - loss: 0.0270 - val_loss: 0.0183 - 2s/epoch - 57ms/step\n",
      "Epoch 99/100\n",
      "35/35 - 2s - loss: 0.0272 - val_loss: 0.0186 - 2s/epoch - 53ms/step\n",
      "Epoch 100/100\n",
      "35/35 - 2s - loss: 0.0279 - val_loss: 0.0209 - 2s/epoch - 49ms/step\n",
      "Evaluating the Performance of lstm Model\n",
      "35/35 [==============================] - 2s 15ms/step\n",
      "7/7 [==============================] - 0s 15ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 94.41403652824172\n",
      "Accuarcy of Testing Data 96.33718019916073\n",
      "Saving the lstm Model\n"
     ]
    }
   ],
   "source": [
    "## Building lstm model - open feature\n",
    "build_model(data=dmart_data_url,stock_name='Dmart',features_names=['Open'],model='lstm')\n",
    "## Building lstm model - close feature\n",
    "build_model(data=dmart_data_url,stock_name='Dmart',features_names=['Close'],model='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset (1661, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                  Open\n",
      "Date                  \n",
      "2017-03-22  641.549988\n",
      "2017-03-23  637.900024\n",
      "2017-03-24  635.450012\n",
      "2017-03-27  615.000000\n",
      "2017-03-28  617.200012\n",
      "Performing MinMaxScaling\n",
      "                Open\n",
      "Date                \n",
      "2017-03-22  0.005327\n",
      "2017-03-23  0.004595\n",
      "2017-03-24  0.004103\n",
      "2017-03-27  0.000000\n",
      "2017-03-28  0.000441\n",
      "Length of Training data (1162, 1)\n",
      "Length of Testing data (249, 1)\n",
      "Length of Validation data (250, 1)\n",
      "Shape of dataset is features (1112, 50, 1) and targets (1112, 1)\n",
      "Shape of dataset is features (199, 50, 1) and targets (199, 1)\n",
      "Shape of dataset is features (200, 50, 1) and targets (200, 1)\n",
      "-------------Preparing bidirectional_lSTM Model----------------\n",
      "========================Summary of bidirectional_lstm==========================\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_16 (Bidirect  (None, 50, 128)           33792     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 50, 128)           0         \n",
      "                                                                 \n",
      " bidirectional_17 (Bidirect  (None, 128)               98816     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136769 (534.25 KB)\n",
      "Trainable params: 136769 (534.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the bidirectional_lstm Model====================\n",
      "Epoch 1/100\n",
      "35/35 - 9s - loss: 0.2078 - val_loss: 0.3499 - 9s/epoch - 268ms/step\n",
      "Epoch 2/100\n",
      "35/35 - 2s - loss: 0.0856 - val_loss: 0.0463 - 2s/epoch - 53ms/step\n",
      "Epoch 3/100\n",
      "35/35 - 2s - loss: 0.0584 - val_loss: 0.0371 - 2s/epoch - 54ms/step\n",
      "Epoch 4/100\n",
      "35/35 - 2s - loss: 0.0522 - val_loss: 0.0299 - 2s/epoch - 52ms/step\n",
      "Epoch 5/100\n",
      "35/35 - 2s - loss: 0.0458 - val_loss: 0.0267 - 2s/epoch - 53ms/step\n",
      "Epoch 6/100\n",
      "35/35 - 2s - loss: 0.0443 - val_loss: 0.0255 - 2s/epoch - 53ms/step\n",
      "Epoch 7/100\n",
      "35/35 - 2s - loss: 0.0432 - val_loss: 0.0389 - 2s/epoch - 53ms/step\n",
      "Epoch 8/100\n",
      "35/35 - 2s - loss: 0.0405 - val_loss: 0.0543 - 2s/epoch - 52ms/step\n",
      "Epoch 9/100\n",
      "35/35 - 2s - loss: 0.0432 - val_loss: 0.0262 - 2s/epoch - 51ms/step\n",
      "Epoch 10/100\n",
      "35/35 - 2s - loss: 0.0415 - val_loss: 0.0279 - 2s/epoch - 53ms/step\n",
      "Epoch 11/100\n",
      "35/35 - 2s - loss: 0.0403 - val_loss: 0.0346 - 2s/epoch - 53ms/step\n",
      "Epoch 12/100\n",
      "35/35 - 2s - loss: 0.0382 - val_loss: 0.0466 - 2s/epoch - 57ms/step\n",
      "Epoch 13/100\n",
      "35/35 - 2s - loss: 0.0395 - val_loss: 0.0220 - 2s/epoch - 68ms/step\n",
      "Epoch 14/100\n",
      "35/35 - 2s - loss: 0.0388 - val_loss: 0.0228 - 2s/epoch - 65ms/step\n",
      "Epoch 15/100\n",
      "35/35 - 2s - loss: 0.0379 - val_loss: 0.0481 - 2s/epoch - 63ms/step\n",
      "Epoch 16/100\n",
      "35/35 - 2s - loss: 0.0386 - val_loss: 0.0343 - 2s/epoch - 64ms/step\n",
      "Epoch 17/100\n",
      "35/35 - 2s - loss: 0.0389 - val_loss: 0.0250 - 2s/epoch - 62ms/step\n",
      "Epoch 18/100\n",
      "35/35 - 2s - loss: 0.0379 - val_loss: 0.0322 - 2s/epoch - 62ms/step\n",
      "Epoch 19/100\n",
      "35/35 - 2s - loss: 0.0364 - val_loss: 0.0306 - 2s/epoch - 64ms/step\n",
      "Epoch 20/100\n",
      "35/35 - 2s - loss: 0.0349 - val_loss: 0.0330 - 2s/epoch - 62ms/step\n",
      "Epoch 21/100\n",
      "35/35 - 2s - loss: 0.0355 - val_loss: 0.0221 - 2s/epoch - 62ms/step\n",
      "Epoch 22/100\n",
      "35/35 - 2s - loss: 0.0355 - val_loss: 0.0308 - 2s/epoch - 64ms/step\n",
      "Epoch 23/100\n",
      "35/35 - 2s - loss: 0.0363 - val_loss: 0.0207 - 2s/epoch - 62ms/step\n",
      "Epoch 24/100\n",
      "35/35 - 2s - loss: 0.0357 - val_loss: 0.0232 - 2s/epoch - 62ms/step\n",
      "Epoch 25/100\n",
      "35/35 - 2s - loss: 0.0346 - val_loss: 0.0210 - 2s/epoch - 66ms/step\n",
      "Epoch 26/100\n",
      "35/35 - 2s - loss: 0.0374 - val_loss: 0.0264 - 2s/epoch - 62ms/step\n",
      "Epoch 27/100\n",
      "35/35 - 2s - loss: 0.0335 - val_loss: 0.0342 - 2s/epoch - 61ms/step\n",
      "Epoch 28/100\n",
      "35/35 - 2s - loss: 0.0361 - val_loss: 0.0190 - 2s/epoch - 65ms/step\n",
      "Epoch 29/100\n",
      "35/35 - 2s - loss: 0.0349 - val_loss: 0.0189 - 2s/epoch - 63ms/step\n",
      "Epoch 30/100\n",
      "35/35 - 2s - loss: 0.0333 - val_loss: 0.0208 - 2s/epoch - 61ms/step\n",
      "Epoch 31/100\n",
      "35/35 - 2s - loss: 0.0334 - val_loss: 0.0186 - 2s/epoch - 64ms/step\n",
      "Epoch 32/100\n",
      "35/35 - 2s - loss: 0.0332 - val_loss: 0.0350 - 2s/epoch - 62ms/step\n",
      "Epoch 33/100\n",
      "35/35 - 2s - loss: 0.0328 - val_loss: 0.0212 - 2s/epoch - 62ms/step\n",
      "Epoch 34/100\n",
      "35/35 - 2s - loss: 0.0329 - val_loss: 0.0278 - 2s/epoch - 63ms/step\n",
      "Epoch 35/100\n",
      "35/35 - 2s - loss: 0.0319 - val_loss: 0.0267 - 2s/epoch - 62ms/step\n",
      "Epoch 36/100\n",
      "35/35 - 2s - loss: 0.0318 - val_loss: 0.0182 - 2s/epoch - 61ms/step\n",
      "Epoch 37/100\n",
      "35/35 - 2s - loss: 0.0321 - val_loss: 0.0189 - 2s/epoch - 66ms/step\n",
      "Epoch 38/100\n",
      "35/35 - 2s - loss: 0.0320 - val_loss: 0.0251 - 2s/epoch - 64ms/step\n",
      "Epoch 39/100\n",
      "35/35 - 2s - loss: 0.0323 - val_loss: 0.0288 - 2s/epoch - 61ms/step\n",
      "Epoch 40/100\n",
      "35/35 - 2s - loss: 0.0302 - val_loss: 0.0178 - 2s/epoch - 64ms/step\n",
      "Epoch 41/100\n",
      "35/35 - 2s - loss: 0.0305 - val_loss: 0.0193 - 2s/epoch - 64ms/step\n",
      "Epoch 42/100\n",
      "35/35 - 2s - loss: 0.0307 - val_loss: 0.0189 - 2s/epoch - 63ms/step\n",
      "Epoch 43/100\n",
      "35/35 - 2s - loss: 0.0302 - val_loss: 0.0177 - 2s/epoch - 66ms/step\n",
      "Epoch 44/100\n",
      "35/35 - 2s - loss: 0.0307 - val_loss: 0.0181 - 2s/epoch - 63ms/step\n",
      "Epoch 45/100\n",
      "35/35 - 2s - loss: 0.0318 - val_loss: 0.0175 - 2s/epoch - 61ms/step\n",
      "Epoch 46/100\n",
      "35/35 - 2s - loss: 0.0305 - val_loss: 0.0195 - 2s/epoch - 64ms/step\n",
      "Epoch 47/100\n",
      "35/35 - 2s - loss: 0.0307 - val_loss: 0.0176 - 2s/epoch - 62ms/step\n",
      "Epoch 48/100\n",
      "35/35 - 2s - loss: 0.0312 - val_loss: 0.0195 - 2s/epoch - 61ms/step\n",
      "Epoch 49/100\n",
      "35/35 - 2s - loss: 0.0301 - val_loss: 0.0170 - 2s/epoch - 64ms/step\n",
      "Epoch 50/100\n",
      "35/35 - 2s - loss: 0.0295 - val_loss: 0.0276 - 2s/epoch - 62ms/step\n",
      "Epoch 51/100\n",
      "35/35 - 2s - loss: 0.0298 - val_loss: 0.0173 - 2s/epoch - 62ms/step\n",
      "Epoch 52/100\n",
      "35/35 - 2s - loss: 0.0316 - val_loss: 0.0183 - 2s/epoch - 65ms/step\n",
      "Epoch 53/100\n",
      "35/35 - 2s - loss: 0.0304 - val_loss: 0.0196 - 2s/epoch - 64ms/step\n",
      "Epoch 54/100\n",
      "35/35 - 2s - loss: 0.0294 - val_loss: 0.0172 - 2s/epoch - 62ms/step\n",
      "Epoch 55/100\n",
      "35/35 - 2s - loss: 0.0292 - val_loss: 0.0167 - 2s/epoch - 63ms/step\n",
      "Epoch 56/100\n",
      "35/35 - 2s - loss: 0.0288 - val_loss: 0.0255 - 2s/epoch - 64ms/step\n",
      "Epoch 57/100\n",
      "35/35 - 2s - loss: 0.0309 - val_loss: 0.0174 - 2s/epoch - 63ms/step\n",
      "Epoch 58/100\n",
      "35/35 - 2s - loss: 0.0285 - val_loss: 0.0165 - 2s/epoch - 64ms/step\n",
      "Epoch 59/100\n",
      "35/35 - 2s - loss: 0.0290 - val_loss: 0.0179 - 2s/epoch - 63ms/step\n",
      "Epoch 60/100\n",
      "35/35 - 2s - loss: 0.0294 - val_loss: 0.0182 - 2s/epoch - 64ms/step\n",
      "Epoch 61/100\n",
      "35/35 - 2s - loss: 0.0280 - val_loss: 0.0167 - 2s/epoch - 66ms/step\n",
      "Epoch 62/100\n",
      "35/35 - 2s - loss: 0.0274 - val_loss: 0.0186 - 2s/epoch - 62ms/step\n",
      "Epoch 63/100\n",
      "35/35 - 2s - loss: 0.0303 - val_loss: 0.0167 - 2s/epoch - 64ms/step\n",
      "Epoch 64/100\n",
      "35/35 - 2s - loss: 0.0274 - val_loss: 0.0164 - 2s/epoch - 64ms/step\n",
      "Epoch 65/100\n",
      "35/35 - 2s - loss: 0.0283 - val_loss: 0.0171 - 2s/epoch - 68ms/step\n",
      "Epoch 66/100\n",
      "35/35 - 2s - loss: 0.0275 - val_loss: 0.0213 - 2s/epoch - 62ms/step\n",
      "Epoch 67/100\n",
      "35/35 - 2s - loss: 0.0279 - val_loss: 0.0168 - 2s/epoch - 61ms/step\n",
      "Epoch 68/100\n",
      "35/35 - 2s - loss: 0.0293 - val_loss: 0.0196 - 2s/epoch - 65ms/step\n",
      "Epoch 69/100\n",
      "35/35 - 2s - loss: 0.0285 - val_loss: 0.0164 - 2s/epoch - 62ms/step\n",
      "Epoch 70/100\n",
      "35/35 - 2s - loss: 0.0285 - val_loss: 0.0161 - 2s/epoch - 64ms/step\n",
      "Epoch 71/100\n",
      "35/35 - 2s - loss: 0.0286 - val_loss: 0.0311 - 2s/epoch - 61ms/step\n",
      "Epoch 72/100\n",
      "35/35 - 2s - loss: 0.0286 - val_loss: 0.0174 - 2s/epoch - 64ms/step\n",
      "Epoch 73/100\n",
      "35/35 - 2s - loss: 0.0280 - val_loss: 0.0160 - 2s/epoch - 67ms/step\n",
      "Epoch 74/100\n",
      "35/35 - 2s - loss: 0.0285 - val_loss: 0.0178 - 2s/epoch - 64ms/step\n",
      "Epoch 75/100\n",
      "35/35 - 2s - loss: 0.0275 - val_loss: 0.0162 - 2s/epoch - 62ms/step\n",
      "Epoch 76/100\n",
      "35/35 - 2s - loss: 0.0278 - val_loss: 0.0250 - 2s/epoch - 64ms/step\n",
      "Epoch 77/100\n",
      "35/35 - 2s - loss: 0.0259 - val_loss: 0.0166 - 2s/epoch - 62ms/step\n",
      "Epoch 78/100\n",
      "35/35 - 2s - loss: 0.0273 - val_loss: 0.0322 - 2s/epoch - 65ms/step\n",
      "Epoch 79/100\n",
      "35/35 - 2s - loss: 0.0270 - val_loss: 0.0157 - 2s/epoch - 63ms/step\n",
      "Epoch 80/100\n",
      "35/35 - 2s - loss: 0.0257 - val_loss: 0.0160 - 2s/epoch - 65ms/step\n",
      "Epoch 81/100\n",
      "35/35 - 2s - loss: 0.0271 - val_loss: 0.0221 - 2s/epoch - 62ms/step\n",
      "Epoch 82/100\n",
      "35/35 - 2s - loss: 0.0265 - val_loss: 0.0179 - 2s/epoch - 62ms/step\n",
      "Epoch 83/100\n",
      "35/35 - 2s - loss: 0.0273 - val_loss: 0.0160 - 2s/epoch - 63ms/step\n",
      "Epoch 84/100\n",
      "35/35 - 2s - loss: 0.0277 - val_loss: 0.0157 - 2s/epoch - 62ms/step\n",
      "Epoch 85/100\n",
      "35/35 - 2s - loss: 0.0267 - val_loss: 0.0157 - 2s/epoch - 61ms/step\n",
      "Epoch 86/100\n",
      "35/35 - 2s - loss: 0.0252 - val_loss: 0.0163 - 2s/epoch - 64ms/step\n",
      "Epoch 87/100\n",
      "35/35 - 2s - loss: 0.0249 - val_loss: 0.0158 - 2s/epoch - 62ms/step\n",
      "Epoch 88/100\n",
      "35/35 - 2s - loss: 0.0273 - val_loss: 0.0181 - 2s/epoch - 63ms/step\n",
      "Epoch 89/100\n",
      "35/35 - 2s - loss: 0.0266 - val_loss: 0.0197 - 2s/epoch - 64ms/step\n",
      "Epoch 90/100\n",
      "35/35 - 2s - loss: 0.0247 - val_loss: 0.0180 - 2s/epoch - 61ms/step\n",
      "Epoch 91/100\n",
      "35/35 - 2s - loss: 0.0275 - val_loss: 0.0205 - 2s/epoch - 62ms/step\n",
      "Epoch 92/100\n",
      "35/35 - 2s - loss: 0.0251 - val_loss: 0.0158 - 2s/epoch - 64ms/step\n",
      "Epoch 93/100\n",
      "35/35 - 2s - loss: 0.0255 - val_loss: 0.0343 - 2s/epoch - 61ms/step\n",
      "Epoch 94/100\n",
      "35/35 - 2s - loss: 0.0267 - val_loss: 0.0159 - 2s/epoch - 62ms/step\n",
      "Epoch 95/100\n",
      "35/35 - 2s - loss: 0.0247 - val_loss: 0.0158 - 2s/epoch - 63ms/step\n",
      "Epoch 96/100\n",
      "35/35 - 2s - loss: 0.0254 - val_loss: 0.0158 - 2s/epoch - 64ms/step\n",
      "Epoch 97/100\n",
      "35/35 - 2s - loss: 0.0267 - val_loss: 0.0153 - 2s/epoch - 62ms/step\n",
      "Epoch 98/100\n",
      "35/35 - 2s - loss: 0.0247 - val_loss: 0.0170 - 2s/epoch - 64ms/step\n",
      "Epoch 99/100\n",
      "35/35 - 2s - loss: 0.0260 - val_loss: 0.0154 - 2s/epoch - 63ms/step\n",
      "Epoch 100/100\n",
      "35/35 - 2s - loss: 0.0261 - val_loss: 0.0158 - 2s/epoch - 61ms/step\n",
      "Evaluating the Performance of bidirectional_lstm Model\n",
      "35/35 [==============================] - 1s 19ms/step\n",
      "7/7 [==============================] - 0s 19ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 95.40987815745126\n",
      "Accuarcy of Testing Data 95.99592671587295\n",
      "Saving the bidirectional_lstm Model\n",
      "shape of the dataset (1661, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                 Close\n",
      "Date                  \n",
      "2017-03-22  638.549988\n",
      "2017-03-23  634.849976\n",
      "2017-03-24  616.900024\n",
      "2017-03-27  614.400024\n",
      "2017-03-28  628.799988\n",
      "Performing MinMaxScaling\n",
      "               Close\n",
      "Date                \n",
      "2017-03-22  0.005128\n",
      "2017-03-23  0.004342\n",
      "2017-03-24  0.000531\n",
      "2017-03-27  0.000000\n",
      "2017-03-28  0.003058\n",
      "Length of Training data (1162, 1)\n",
      "Length of Testing data (249, 1)\n",
      "Length of Validation data (250, 1)\n",
      "Shape of dataset is features (1112, 50, 1) and targets (1112, 1)\n",
      "Shape of dataset is features (199, 50, 1) and targets (199, 1)\n",
      "Shape of dataset is features (200, 50, 1) and targets (200, 1)\n",
      "-------------Preparing bidirectional_lSTM Model----------------\n",
      "========================Summary of bidirectional_lstm==========================\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_18 (Bidirect  (None, 50, 128)           33792     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 50, 128)           0         \n",
      "                                                                 \n",
      " bidirectional_19 (Bidirect  (None, 128)               98816     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136769 (534.25 KB)\n",
      "Trainable params: 136769 (534.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the bidirectional_lstm Model====================\n",
      "Epoch 1/100\n",
      "35/35 - 9s - loss: 0.2311 - val_loss: 0.3916 - 9s/epoch - 264ms/step\n",
      "Epoch 2/100\n",
      "35/35 - 2s - loss: 0.0984 - val_loss: 0.0533 - 2s/epoch - 58ms/step\n",
      "Epoch 3/100\n",
      "35/35 - 2s - loss: 0.0623 - val_loss: 0.0291 - 2s/epoch - 64ms/step\n",
      "Epoch 4/100\n",
      "35/35 - 2s - loss: 0.0528 - val_loss: 0.0708 - 2s/epoch - 63ms/step\n",
      "Epoch 5/100\n",
      "35/35 - 2s - loss: 0.0496 - val_loss: 0.0432 - 2s/epoch - 64ms/step\n",
      "Epoch 6/100\n",
      "35/35 - 2s - loss: 0.0451 - val_loss: 0.0362 - 2s/epoch - 62ms/step\n",
      "Epoch 7/100\n",
      "35/35 - 2s - loss: 0.0463 - val_loss: 0.0368 - 2s/epoch - 64ms/step\n",
      "Epoch 8/100\n",
      "35/35 - 2s - loss: 0.0433 - val_loss: 0.0298 - 2s/epoch - 67ms/step\n",
      "Epoch 9/100\n",
      "35/35 - 2s - loss: 0.0473 - val_loss: 0.0600 - 2s/epoch - 62ms/step\n",
      "Epoch 10/100\n",
      "35/35 - 2s - loss: 0.0458 - val_loss: 0.0318 - 2s/epoch - 63ms/step\n",
      "Epoch 11/100\n",
      "35/35 - 2s - loss: 0.0428 - val_loss: 0.0323 - 2s/epoch - 68ms/step\n",
      "Epoch 12/100\n",
      "35/35 - 2s - loss: 0.0411 - val_loss: 0.0321 - 2s/epoch - 66ms/step\n",
      "Epoch 13/100\n",
      "35/35 - 2s - loss: 0.0425 - val_loss: 0.0421 - 2s/epoch - 67ms/step\n",
      "Epoch 14/100\n",
      "35/35 - 2s - loss: 0.0420 - val_loss: 0.0310 - 2s/epoch - 67ms/step\n",
      "Epoch 15/100\n",
      "35/35 - 2s - loss: 0.0420 - val_loss: 0.0331 - 2s/epoch - 65ms/step\n",
      "Epoch 16/100\n",
      "35/35 - 2s - loss: 0.0391 - val_loss: 0.0383 - 2s/epoch - 67ms/step\n",
      "Epoch 17/100\n",
      "35/35 - 2s - loss: 0.0420 - val_loss: 0.0366 - 2s/epoch - 65ms/step\n",
      "Epoch 18/100\n",
      "35/35 - 2s - loss: 0.0409 - val_loss: 0.0418 - 2s/epoch - 66ms/step\n",
      "Epoch 19/100\n",
      "35/35 - 2s - loss: 0.0398 - val_loss: 0.0598 - 2s/epoch - 64ms/step\n",
      "Epoch 20/100\n",
      "35/35 - 2s - loss: 0.0403 - val_loss: 0.0307 - 2s/epoch - 67ms/step\n",
      "Epoch 21/100\n",
      "35/35 - 2s - loss: 0.0395 - val_loss: 0.0270 - 2s/epoch - 65ms/step\n",
      "Epoch 22/100\n",
      "35/35 - 2s - loss: 0.0358 - val_loss: 0.0320 - 2s/epoch - 65ms/step\n",
      "Epoch 23/100\n",
      "35/35 - 2s - loss: 0.0375 - val_loss: 0.0219 - 2s/epoch - 61ms/step\n",
      "Epoch 24/100\n",
      "35/35 - 2s - loss: 0.0383 - val_loss: 0.0317 - 2s/epoch - 63ms/step\n",
      "Epoch 25/100\n",
      "35/35 - 3s - loss: 0.0379 - val_loss: 0.0250 - 3s/epoch - 74ms/step\n",
      "Epoch 26/100\n",
      "35/35 - 2s - loss: 0.0369 - val_loss: 0.0217 - 2s/epoch - 68ms/step\n",
      "Epoch 27/100\n",
      "35/35 - 2s - loss: 0.0363 - val_loss: 0.0259 - 2s/epoch - 69ms/step\n",
      "Epoch 28/100\n",
      "35/35 - 2s - loss: 0.0392 - val_loss: 0.0227 - 2s/epoch - 69ms/step\n",
      "Epoch 29/100\n",
      "35/35 - 2s - loss: 0.0348 - val_loss: 0.0324 - 2s/epoch - 65ms/step\n",
      "Epoch 30/100\n",
      "35/35 - 2s - loss: 0.0362 - val_loss: 0.0356 - 2s/epoch - 65ms/step\n",
      "Epoch 31/100\n",
      "35/35 - 2s - loss: 0.0363 - val_loss: 0.0216 - 2s/epoch - 64ms/step\n",
      "Epoch 32/100\n",
      "35/35 - 2s - loss: 0.0361 - val_loss: 0.0315 - 2s/epoch - 63ms/step\n",
      "Epoch 33/100\n",
      "35/35 - 2s - loss: 0.0348 - val_loss: 0.0216 - 2s/epoch - 62ms/step\n",
      "Epoch 34/100\n",
      "35/35 - 2s - loss: 0.0353 - val_loss: 0.0240 - 2s/epoch - 66ms/step\n",
      "Epoch 35/100\n",
      "35/35 - 2s - loss: 0.0362 - val_loss: 0.0273 - 2s/epoch - 63ms/step\n",
      "Epoch 36/100\n",
      "35/35 - 2s - loss: 0.0352 - val_loss: 0.0207 - 2s/epoch - 68ms/step\n",
      "Epoch 37/100\n",
      "35/35 - 2s - loss: 0.0343 - val_loss: 0.0285 - 2s/epoch - 64ms/step\n",
      "Epoch 38/100\n",
      "35/35 - 2s - loss: 0.0338 - val_loss: 0.0266 - 2s/epoch - 68ms/step\n",
      "Epoch 39/100\n",
      "35/35 - 2s - loss: 0.0334 - val_loss: 0.0245 - 2s/epoch - 65ms/step\n",
      "Epoch 40/100\n",
      "35/35 - 2s - loss: 0.0342 - val_loss: 0.0200 - 2s/epoch - 65ms/step\n",
      "Epoch 41/100\n",
      "35/35 - 2s - loss: 0.0333 - val_loss: 0.0221 - 2s/epoch - 64ms/step\n",
      "Epoch 42/100\n",
      "35/35 - 2s - loss: 0.0337 - val_loss: 0.0197 - 2s/epoch - 66ms/step\n",
      "Epoch 43/100\n",
      "35/35 - 2s - loss: 0.0329 - val_loss: 0.0282 - 2s/epoch - 64ms/step\n",
      "Epoch 44/100\n",
      "35/35 - 2s - loss: 0.0324 - val_loss: 0.0294 - 2s/epoch - 67ms/step\n",
      "Epoch 45/100\n",
      "35/35 - 2s - loss: 0.0318 - val_loss: 0.0196 - 2s/epoch - 68ms/step\n",
      "Epoch 46/100\n",
      "35/35 - 3s - loss: 0.0326 - val_loss: 0.0277 - 3s/epoch - 77ms/step\n",
      "Epoch 47/100\n",
      "35/35 - 2s - loss: 0.0318 - val_loss: 0.0426 - 2s/epoch - 64ms/step\n",
      "Epoch 48/100\n",
      "35/35 - 2s - loss: 0.0355 - val_loss: 0.0199 - 2s/epoch - 61ms/step\n",
      "Epoch 49/100\n",
      "35/35 - 2s - loss: 0.0304 - val_loss: 0.0240 - 2s/epoch - 62ms/step\n",
      "Epoch 50/100\n",
      "35/35 - 2s - loss: 0.0312 - val_loss: 0.0234 - 2s/epoch - 64ms/step\n",
      "Epoch 51/100\n",
      "35/35 - 2s - loss: 0.0319 - val_loss: 0.0187 - 2s/epoch - 62ms/step\n",
      "Epoch 52/100\n",
      "35/35 - 2s - loss: 0.0307 - val_loss: 0.0190 - 2s/epoch - 64ms/step\n",
      "Epoch 53/100\n",
      "35/35 - 2s - loss: 0.0309 - val_loss: 0.0278 - 2s/epoch - 62ms/step\n",
      "Epoch 54/100\n",
      "35/35 - 2s - loss: 0.0314 - val_loss: 0.0182 - 2s/epoch - 64ms/step\n",
      "Epoch 55/100\n",
      "35/35 - 2s - loss: 0.0318 - val_loss: 0.0485 - 2s/epoch - 69ms/step\n",
      "Epoch 56/100\n",
      "35/35 - 2s - loss: 0.0300 - val_loss: 0.0197 - 2s/epoch - 67ms/step\n",
      "Epoch 57/100\n",
      "35/35 - 2s - loss: 0.0307 - val_loss: 0.0177 - 2s/epoch - 65ms/step\n",
      "Epoch 58/100\n",
      "35/35 - 2s - loss: 0.0306 - val_loss: 0.0191 - 2s/epoch - 64ms/step\n",
      "Epoch 59/100\n",
      "35/35 - 2s - loss: 0.0309 - val_loss: 0.0191 - 2s/epoch - 64ms/step\n",
      "Epoch 60/100\n",
      "35/35 - 2s - loss: 0.0291 - val_loss: 0.0182 - 2s/epoch - 63ms/step\n",
      "Epoch 61/100\n",
      "35/35 - 2s - loss: 0.0298 - val_loss: 0.0187 - 2s/epoch - 62ms/step\n",
      "Epoch 62/100\n",
      "35/35 - 2s - loss: 0.0317 - val_loss: 0.0262 - 2s/epoch - 64ms/step\n",
      "Epoch 63/100\n",
      "35/35 - 2s - loss: 0.0307 - val_loss: 0.0183 - 2s/epoch - 64ms/step\n",
      "Epoch 64/100\n",
      "35/35 - 2s - loss: 0.0304 - val_loss: 0.0177 - 2s/epoch - 64ms/step\n",
      "Epoch 65/100\n",
      "35/35 - 2s - loss: 0.0299 - val_loss: 0.0233 - 2s/epoch - 61ms/step\n",
      "Epoch 66/100\n",
      "35/35 - 2s - loss: 0.0303 - val_loss: 0.0176 - 2s/epoch - 65ms/step\n",
      "Epoch 67/100\n",
      "35/35 - 2s - loss: 0.0289 - val_loss: 0.0357 - 2s/epoch - 64ms/step\n",
      "Epoch 68/100\n",
      "35/35 - 2s - loss: 0.0304 - val_loss: 0.0232 - 2s/epoch - 64ms/step\n",
      "Epoch 69/100\n",
      "35/35 - 2s - loss: 0.0285 - val_loss: 0.0217 - 2s/epoch - 64ms/step\n",
      "Epoch 70/100\n",
      "35/35 - 2s - loss: 0.0299 - val_loss: 0.0172 - 2s/epoch - 62ms/step\n",
      "Epoch 71/100\n",
      "35/35 - 2s - loss: 0.0301 - val_loss: 0.0183 - 2s/epoch - 65ms/step\n",
      "Epoch 72/100\n",
      "35/35 - 2s - loss: 0.0294 - val_loss: 0.0180 - 2s/epoch - 65ms/step\n",
      "Epoch 73/100\n",
      "35/35 - 2s - loss: 0.0274 - val_loss: 0.0261 - 2s/epoch - 64ms/step\n",
      "Epoch 74/100\n",
      "35/35 - 2s - loss: 0.0292 - val_loss: 0.0180 - 2s/epoch - 63ms/step\n",
      "Epoch 75/100\n",
      "35/35 - 2s - loss: 0.0297 - val_loss: 0.0169 - 2s/epoch - 65ms/step\n",
      "Epoch 76/100\n",
      "35/35 - 2s - loss: 0.0285 - val_loss: 0.0317 - 2s/epoch - 66ms/step\n",
      "Epoch 77/100\n",
      "35/35 - 2s - loss: 0.0272 - val_loss: 0.0168 - 2s/epoch - 65ms/step\n",
      "Epoch 78/100\n",
      "35/35 - 2s - loss: 0.0292 - val_loss: 0.0176 - 2s/epoch - 65ms/step\n",
      "Epoch 79/100\n",
      "35/35 - 2s - loss: 0.0278 - val_loss: 0.0269 - 2s/epoch - 62ms/step\n",
      "Epoch 80/100\n",
      "35/35 - 2s - loss: 0.0296 - val_loss: 0.0234 - 2s/epoch - 66ms/step\n",
      "Epoch 81/100\n",
      "35/35 - 2s - loss: 0.0294 - val_loss: 0.0166 - 2s/epoch - 64ms/step\n",
      "Epoch 82/100\n",
      "35/35 - 2s - loss: 0.0280 - val_loss: 0.0179 - 2s/epoch - 66ms/step\n",
      "Epoch 83/100\n",
      "35/35 - 2s - loss: 0.0280 - val_loss: 0.0192 - 2s/epoch - 64ms/step\n",
      "Epoch 84/100\n",
      "35/35 - 2s - loss: 0.0276 - val_loss: 0.0279 - 2s/epoch - 65ms/step\n",
      "Epoch 85/100\n",
      "35/35 - 2s - loss: 0.0285 - val_loss: 0.0202 - 2s/epoch - 67ms/step\n",
      "Epoch 86/100\n",
      "35/35 - 2s - loss: 0.0274 - val_loss: 0.0169 - 2s/epoch - 66ms/step\n",
      "Epoch 87/100\n",
      "35/35 - 2s - loss: 0.0282 - val_loss: 0.0204 - 2s/epoch - 67ms/step\n",
      "Epoch 88/100\n",
      "35/35 - 2s - loss: 0.0278 - val_loss: 0.0166 - 2s/epoch - 65ms/step\n",
      "Epoch 89/100\n",
      "35/35 - 2s - loss: 0.0270 - val_loss: 0.0166 - 2s/epoch - 65ms/step\n",
      "Epoch 90/100\n",
      "35/35 - 2s - loss: 0.0266 - val_loss: 0.0164 - 2s/epoch - 63ms/step\n",
      "Epoch 91/100\n",
      "35/35 - 2s - loss: 0.0273 - val_loss: 0.0169 - 2s/epoch - 65ms/step\n",
      "Epoch 92/100\n",
      "35/35 - 2s - loss: 0.0269 - val_loss: 0.0163 - 2s/epoch - 65ms/step\n",
      "Epoch 93/100\n",
      "35/35 - 2s - loss: 0.0276 - val_loss: 0.0212 - 2s/epoch - 69ms/step\n",
      "Epoch 94/100\n",
      "35/35 - 2s - loss: 0.0273 - val_loss: 0.0168 - 2s/epoch - 68ms/step\n",
      "Epoch 95/100\n",
      "35/35 - 2s - loss: 0.0271 - val_loss: 0.0164 - 2s/epoch - 62ms/step\n",
      "Epoch 96/100\n",
      "35/35 - 2s - loss: 0.0274 - val_loss: 0.0173 - 2s/epoch - 65ms/step\n",
      "Epoch 97/100\n",
      "35/35 - 2s - loss: 0.0271 - val_loss: 0.0179 - 2s/epoch - 65ms/step\n",
      "Epoch 98/100\n",
      "35/35 - 2s - loss: 0.0271 - val_loss: 0.0166 - 2s/epoch - 65ms/step\n",
      "Epoch 99/100\n",
      "35/35 - 2s - loss: 0.0272 - val_loss: 0.0164 - 2s/epoch - 64ms/step\n",
      "Epoch 100/100\n",
      "35/35 - 2s - loss: 0.0264 - val_loss: 0.0164 - 2s/epoch - 62ms/step\n",
      "Evaluating the Performance of bidirectional_lstm Model\n",
      "35/35 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 0s 19ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 94.60633739323586\n",
      "Accuarcy of Testing Data 95.95303737840398\n",
      "Saving the bidirectional_lstm Model\n"
     ]
    }
   ],
   "source": [
    "## Building Bidirectional_lstm model - open feature\n",
    "build_model(data=dmart_data_url,stock_name='Dmart',features_names=['Open'],model='bidirectional_lstm')\n",
    "## Building Bidirectional_lstm model - close feature\n",
    "build_model(data=dmart_data_url,stock_name='Dmart',features_names=['Close'],model='bidirectional_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset (2467, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                   Open\n",
      "Date                   \n",
      "2013-12-13  6201.299805\n",
      "2013-12-16  6168.350098\n",
      "2013-12-17  6178.200195\n",
      "2013-12-18  6129.950195\n",
      "2013-12-19  6253.899902\n",
      "Performing MinMaxScaling\n",
      "                Open\n",
      "Date                \n",
      "2013-12-13  0.016834\n",
      "2013-12-16  0.014647\n",
      "2013-12-17  0.015301\n",
      "2013-12-18  0.012099\n",
      "2013-12-19  0.020324\n",
      "Length of Training data (1717, 1)\n",
      "Length of Testing data (368, 1)\n",
      "Length of Validation data (368, 1)\n",
      "Shape of dataset is features (1667, 50, 1) and targets (1667, 1)\n",
      "Shape of dataset is features (318, 50, 1) and targets (318, 1)\n",
      "Shape of dataset is features (318, 50, 1) and targets (318, 1)\n",
      "-------------Preparing LSTM Model----------------\n",
      "========================Summary of lstm==========================\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_44 (LSTM)              (None, 50, 50)            10400     \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 50, 50)            0         \n",
      "                                                                 \n",
      " lstm_45 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 32)                1632      \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32265 (126.04 KB)\n",
      "Trainable params: 32265 (126.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the lstm Model====================\n",
      "Epoch 1/100\n",
      "53/53 - 7s - loss: 0.2234 - val_loss: 0.7059 - 7s/epoch - 141ms/step\n",
      "Epoch 2/100\n",
      "53/53 - 3s - loss: 0.0960 - val_loss: 0.3074 - 3s/epoch - 52ms/step\n",
      "Epoch 3/100\n",
      "53/53 - 3s - loss: 0.0556 - val_loss: 0.1476 - 3s/epoch - 58ms/step\n",
      "Epoch 4/100\n",
      "53/53 - 3s - loss: 0.0464 - val_loss: 0.0862 - 3s/epoch - 58ms/step\n",
      "Epoch 5/100\n",
      "53/53 - 3s - loss: 0.0447 - val_loss: 0.0967 - 3s/epoch - 56ms/step\n",
      "Epoch 6/100\n",
      "53/53 - 3s - loss: 0.0433 - val_loss: 0.0863 - 3s/epoch - 56ms/step\n",
      "Epoch 7/100\n",
      "53/53 - 3s - loss: 0.0431 - val_loss: 0.0612 - 3s/epoch - 57ms/step\n",
      "Epoch 8/100\n",
      "53/53 - 3s - loss: 0.0403 - val_loss: 0.0650 - 3s/epoch - 57ms/step\n",
      "Epoch 9/100\n",
      "53/53 - 3s - loss: 0.0392 - val_loss: 0.0575 - 3s/epoch - 55ms/step\n",
      "Epoch 10/100\n",
      "53/53 - 3s - loss: 0.0378 - val_loss: 0.0866 - 3s/epoch - 54ms/step\n",
      "Epoch 11/100\n",
      "53/53 - 3s - loss: 0.0365 - val_loss: 0.1059 - 3s/epoch - 59ms/step\n",
      "Epoch 12/100\n",
      "53/53 - 3s - loss: 0.0357 - val_loss: 0.1083 - 3s/epoch - 50ms/step\n",
      "Epoch 13/100\n",
      "53/53 - 3s - loss: 0.0374 - val_loss: 0.0999 - 3s/epoch - 53ms/step\n",
      "Epoch 14/100\n",
      "53/53 - 3s - loss: 0.0356 - val_loss: 0.1050 - 3s/epoch - 51ms/step\n",
      "Epoch 15/100\n",
      "53/53 - 3s - loss: 0.0341 - val_loss: 0.1217 - 3s/epoch - 56ms/step\n",
      "Epoch 16/100\n",
      "53/53 - 3s - loss: 0.0338 - val_loss: 0.0860 - 3s/epoch - 57ms/step\n",
      "Epoch 17/100\n",
      "53/53 - 3s - loss: 0.0334 - val_loss: 0.0794 - 3s/epoch - 54ms/step\n",
      "Epoch 18/100\n",
      "53/53 - 3s - loss: 0.0338 - val_loss: 0.1146 - 3s/epoch - 58ms/step\n",
      "Epoch 19/100\n",
      "53/53 - 3s - loss: 0.0323 - val_loss: 0.1201 - 3s/epoch - 57ms/step\n",
      "Epoch 20/100\n",
      "53/53 - 3s - loss: 0.0333 - val_loss: 0.1008 - 3s/epoch - 53ms/step\n",
      "Epoch 21/100\n",
      "53/53 - 3s - loss: 0.0324 - val_loss: 0.0879 - 3s/epoch - 56ms/step\n",
      "Epoch 22/100\n",
      "53/53 - 3s - loss: 0.0323 - val_loss: 0.1086 - 3s/epoch - 55ms/step\n",
      "Epoch 23/100\n",
      "53/53 - 3s - loss: 0.0315 - val_loss: 0.0888 - 3s/epoch - 55ms/step\n",
      "Epoch 24/100\n",
      "53/53 - 3s - loss: 0.0315 - val_loss: 0.0999 - 3s/epoch - 51ms/step\n",
      "Epoch 25/100\n",
      "53/53 - 3s - loss: 0.0310 - val_loss: 0.1186 - 3s/epoch - 58ms/step\n",
      "Epoch 26/100\n",
      "53/53 - 3s - loss: 0.0318 - val_loss: 0.1071 - 3s/epoch - 52ms/step\n",
      "Epoch 27/100\n",
      "53/53 - 3s - loss: 0.0294 - val_loss: 0.1046 - 3s/epoch - 55ms/step\n",
      "Epoch 28/100\n",
      "53/53 - 3s - loss: 0.0297 - val_loss: 0.1141 - 3s/epoch - 55ms/step\n",
      "Epoch 29/100\n",
      "53/53 - 3s - loss: 0.0297 - val_loss: 0.1208 - 3s/epoch - 56ms/step\n",
      "Epoch 30/100\n",
      "53/53 - 3s - loss: 0.0302 - val_loss: 0.1205 - 3s/epoch - 53ms/step\n",
      "Epoch 31/100\n",
      "53/53 - 3s - loss: 0.0295 - val_loss: 0.0941 - 3s/epoch - 56ms/step\n",
      "Epoch 32/100\n",
      "53/53 - 3s - loss: 0.0288 - val_loss: 0.1249 - 3s/epoch - 54ms/step\n",
      "Epoch 33/100\n",
      "53/53 - 3s - loss: 0.0290 - val_loss: 0.1059 - 3s/epoch - 51ms/step\n",
      "Epoch 34/100\n",
      "53/53 - 3s - loss: 0.0292 - val_loss: 0.0793 - 3s/epoch - 51ms/step\n",
      "Epoch 35/100\n",
      "53/53 - 3s - loss: 0.0294 - val_loss: 0.0787 - 3s/epoch - 51ms/step\n",
      "Epoch 36/100\n",
      "53/53 - 3s - loss: 0.0279 - val_loss: 0.1181 - 3s/epoch - 51ms/step\n",
      "Epoch 37/100\n",
      "53/53 - 3s - loss: 0.0280 - val_loss: 0.0917 - 3s/epoch - 53ms/step\n",
      "Epoch 38/100\n",
      "53/53 - 3s - loss: 0.0275 - val_loss: 0.1163 - 3s/epoch - 52ms/step\n",
      "Epoch 39/100\n",
      "53/53 - 3s - loss: 0.0282 - val_loss: 0.1166 - 3s/epoch - 57ms/step\n",
      "Epoch 40/100\n",
      "53/53 - 3s - loss: 0.0274 - val_loss: 0.1300 - 3s/epoch - 55ms/step\n",
      "Epoch 41/100\n",
      "53/53 - 3s - loss: 0.0280 - val_loss: 0.1510 - 3s/epoch - 55ms/step\n",
      "Epoch 42/100\n",
      "53/53 - 3s - loss: 0.0257 - val_loss: 0.1416 - 3s/epoch - 53ms/step\n",
      "Epoch 43/100\n",
      "53/53 - 3s - loss: 0.0265 - val_loss: 0.1401 - 3s/epoch - 51ms/step\n",
      "Epoch 44/100\n",
      "53/53 - 3s - loss: 0.0261 - val_loss: 0.1235 - 3s/epoch - 52ms/step\n",
      "Epoch 45/100\n",
      "53/53 - 3s - loss: 0.0266 - val_loss: 0.1289 - 3s/epoch - 54ms/step\n",
      "Epoch 46/100\n",
      "53/53 - 3s - loss: 0.0264 - val_loss: 0.1085 - 3s/epoch - 55ms/step\n",
      "Epoch 47/100\n",
      "53/53 - 3s - loss: 0.0256 - val_loss: 0.1466 - 3s/epoch - 53ms/step\n",
      "Epoch 48/100\n",
      "53/53 - 3s - loss: 0.0258 - val_loss: 0.1155 - 3s/epoch - 48ms/step\n",
      "Epoch 49/100\n",
      "53/53 - 3s - loss: 0.0248 - val_loss: 0.1189 - 3s/epoch - 58ms/step\n",
      "Epoch 50/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.1176 - 3s/epoch - 49ms/step\n",
      "Epoch 51/100\n",
      "53/53 - 3s - loss: 0.0249 - val_loss: 0.1183 - 3s/epoch - 56ms/step\n",
      "Epoch 52/100\n",
      "53/53 - 3s - loss: 0.0247 - val_loss: 0.1311 - 3s/epoch - 57ms/step\n",
      "Epoch 53/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.1207 - 3s/epoch - 57ms/step\n",
      "Epoch 54/100\n",
      "53/53 - 3s - loss: 0.0244 - val_loss: 0.1264 - 3s/epoch - 55ms/step\n",
      "Epoch 55/100\n",
      "53/53 - 3s - loss: 0.0249 - val_loss: 0.1264 - 3s/epoch - 57ms/step\n",
      "Epoch 56/100\n",
      "53/53 - 3s - loss: 0.0242 - val_loss: 0.1313 - 3s/epoch - 57ms/step\n",
      "Epoch 57/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.1260 - 3s/epoch - 51ms/step\n",
      "Epoch 58/100\n",
      "53/53 - 3s - loss: 0.0235 - val_loss: 0.1231 - 3s/epoch - 50ms/step\n",
      "Epoch 59/100\n",
      "53/53 - 3s - loss: 0.0232 - val_loss: 0.1358 - 3s/epoch - 52ms/step\n",
      "Epoch 60/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.1649 - 3s/epoch - 56ms/step\n",
      "Epoch 61/100\n",
      "53/53 - 3s - loss: 0.0243 - val_loss: 0.1251 - 3s/epoch - 55ms/step\n",
      "Epoch 62/100\n",
      "53/53 - 3s - loss: 0.0237 - val_loss: 0.1406 - 3s/epoch - 55ms/step\n",
      "Epoch 63/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.1357 - 3s/epoch - 54ms/step\n",
      "Epoch 64/100\n",
      "53/53 - 2s - loss: 0.0232 - val_loss: 0.1204 - 2s/epoch - 45ms/step\n",
      "Epoch 65/100\n",
      "53/53 - 3s - loss: 0.0229 - val_loss: 0.1382 - 3s/epoch - 54ms/step\n",
      "Epoch 66/100\n",
      "53/53 - 3s - loss: 0.0223 - val_loss: 0.1248 - 3s/epoch - 54ms/step\n",
      "Epoch 67/100\n",
      "53/53 - 3s - loss: 0.0220 - val_loss: 0.1641 - 3s/epoch - 53ms/step\n",
      "Epoch 68/100\n",
      "53/53 - 2s - loss: 0.0222 - val_loss: 0.1350 - 2s/epoch - 47ms/step\n",
      "Epoch 69/100\n",
      "53/53 - 3s - loss: 0.0217 - val_loss: 0.1433 - 3s/epoch - 52ms/step\n",
      "Epoch 70/100\n",
      "53/53 - 3s - loss: 0.0221 - val_loss: 0.1506 - 3s/epoch - 55ms/step\n",
      "Epoch 71/100\n",
      "53/53 - 3s - loss: 0.0223 - val_loss: 0.1516 - 3s/epoch - 53ms/step\n",
      "Epoch 72/100\n",
      "53/53 - 3s - loss: 0.0216 - val_loss: 0.1599 - 3s/epoch - 50ms/step\n",
      "Epoch 73/100\n",
      "53/53 - 3s - loss: 0.0223 - val_loss: 0.1186 - 3s/epoch - 55ms/step\n",
      "Epoch 74/100\n",
      "53/53 - 3s - loss: 0.0213 - val_loss: 0.1392 - 3s/epoch - 56ms/step\n",
      "Epoch 75/100\n",
      "53/53 - 3s - loss: 0.0212 - val_loss: 0.1376 - 3s/epoch - 58ms/step\n",
      "Epoch 76/100\n",
      "53/53 - 3s - loss: 0.0218 - val_loss: 0.1319 - 3s/epoch - 58ms/step\n",
      "Epoch 77/100\n",
      "53/53 - 3s - loss: 0.0204 - val_loss: 0.1119 - 3s/epoch - 53ms/step\n",
      "Epoch 78/100\n",
      "53/53 - 3s - loss: 0.0211 - val_loss: 0.1247 - 3s/epoch - 51ms/step\n",
      "Epoch 79/100\n",
      "53/53 - 3s - loss: 0.0207 - val_loss: 0.1490 - 3s/epoch - 48ms/step\n",
      "Epoch 80/100\n",
      "53/53 - 3s - loss: 0.0206 - val_loss: 0.1386 - 3s/epoch - 57ms/step\n",
      "Epoch 81/100\n",
      "53/53 - 3s - loss: 0.0205 - val_loss: 0.1515 - 3s/epoch - 49ms/step\n",
      "Epoch 82/100\n",
      "53/53 - 3s - loss: 0.0206 - val_loss: 0.1510 - 3s/epoch - 53ms/step\n",
      "Epoch 83/100\n",
      "53/53 - 3s - loss: 0.0209 - val_loss: 0.1538 - 3s/epoch - 54ms/step\n",
      "Epoch 84/100\n",
      "53/53 - 3s - loss: 0.0204 - val_loss: 0.1427 - 3s/epoch - 48ms/step\n",
      "Epoch 85/100\n",
      "53/53 - 3s - loss: 0.0208 - val_loss: 0.1620 - 3s/epoch - 57ms/step\n",
      "Epoch 86/100\n",
      "53/53 - 3s - loss: 0.0199 - val_loss: 0.1554 - 3s/epoch - 52ms/step\n",
      "Epoch 87/100\n",
      "53/53 - 3s - loss: 0.0201 - val_loss: 0.1525 - 3s/epoch - 56ms/step\n",
      "Epoch 88/100\n",
      "53/53 - 3s - loss: 0.0196 - val_loss: 0.1674 - 3s/epoch - 55ms/step\n",
      "Epoch 89/100\n",
      "53/53 - 3s - loss: 0.0194 - val_loss: 0.1631 - 3s/epoch - 51ms/step\n",
      "Epoch 90/100\n",
      "53/53 - 3s - loss: 0.0194 - val_loss: 0.1602 - 3s/epoch - 53ms/step\n",
      "Epoch 91/100\n",
      "53/53 - 3s - loss: 0.0201 - val_loss: 0.1564 - 3s/epoch - 57ms/step\n",
      "Epoch 92/100\n",
      "53/53 - 3s - loss: 0.0202 - val_loss: 0.1515 - 3s/epoch - 51ms/step\n",
      "Epoch 93/100\n",
      "53/53 - 3s - loss: 0.0198 - val_loss: 0.1368 - 3s/epoch - 48ms/step\n",
      "Epoch 94/100\n",
      "53/53 - 3s - loss: 0.0198 - val_loss: 0.1466 - 3s/epoch - 51ms/step\n",
      "Epoch 95/100\n",
      "53/53 - 3s - loss: 0.0201 - val_loss: 0.1595 - 3s/epoch - 58ms/step\n",
      "Epoch 96/100\n",
      "53/53 - 3s - loss: 0.0188 - val_loss: 0.1597 - 3s/epoch - 55ms/step\n",
      "Epoch 97/100\n",
      "53/53 - 3s - loss: 0.0192 - val_loss: 0.1375 - 3s/epoch - 51ms/step\n",
      "Epoch 98/100\n",
      "53/53 - 3s - loss: 0.0196 - val_loss: 0.1570 - 3s/epoch - 57ms/step\n",
      "Epoch 99/100\n",
      "53/53 - 3s - loss: 0.0191 - val_loss: 0.1403 - 3s/epoch - 52ms/step\n",
      "Epoch 100/100\n",
      "53/53 - 3s - loss: 0.0186 - val_loss: 0.1633 - 3s/epoch - 57ms/step\n",
      "Evaluating the Performance of lstm Model\n",
      "53/53 [==============================] - 2s 14ms/step\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 95.45105894306414\n",
      "Accuarcy of Testing Data 84.58497709100644\n",
      "Saving the lstm Model\n",
      "shape of the dataset (2467, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                  Close\n",
      "Date                   \n",
      "2013-12-13  6168.399902\n",
      "2013-12-16  6154.700195\n",
      "2013-12-17  6139.049805\n",
      "2013-12-18  6217.149902\n",
      "2013-12-19  6166.649902\n",
      "Performing MinMaxScaling\n",
      "               Close\n",
      "Date                \n",
      "2013-12-13  0.011169\n",
      "2013-12-16  0.010256\n",
      "2013-12-17  0.009212\n",
      "2013-12-18  0.014420\n",
      "2013-12-19  0.011053\n",
      "Length of Training data (1717, 1)\n",
      "Length of Testing data (368, 1)\n",
      "Length of Validation data (368, 1)\n",
      "Shape of dataset is features (1667, 50, 1) and targets (1667, 1)\n",
      "Shape of dataset is features (318, 50, 1) and targets (318, 1)\n",
      "Shape of dataset is features (318, 50, 1) and targets (318, 1)\n",
      "-------------Preparing LSTM Model----------------\n",
      "========================Summary of lstm==========================\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_46 (LSTM)              (None, 50, 50)            10400     \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 50, 50)            0         \n",
      "                                                                 \n",
      " lstm_47 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 32)                1632      \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32265 (126.04 KB)\n",
      "Trainable params: 32265 (126.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the lstm Model====================\n",
      "Epoch 1/100\n",
      "53/53 - 8s - loss: 0.2110 - val_loss: 0.7051 - 8s/epoch - 149ms/step\n",
      "Epoch 2/100\n",
      "53/53 - 3s - loss: 0.0985 - val_loss: 0.3420 - 3s/epoch - 48ms/step\n",
      "Epoch 3/100\n",
      "53/53 - 3s - loss: 0.0548 - val_loss: 0.1081 - 3s/epoch - 51ms/step\n",
      "Epoch 4/100\n",
      "53/53 - 3s - loss: 0.0414 - val_loss: 0.0244 - 3s/epoch - 53ms/step\n",
      "Epoch 5/100\n",
      "53/53 - 3s - loss: 0.0405 - val_loss: 0.0256 - 3s/epoch - 49ms/step\n",
      "Epoch 6/100\n",
      "53/53 - 3s - loss: 0.0400 - val_loss: 0.0257 - 3s/epoch - 53ms/step\n",
      "Epoch 7/100\n",
      "53/53 - 3s - loss: 0.0367 - val_loss: 0.0415 - 3s/epoch - 54ms/step\n",
      "Epoch 8/100\n",
      "53/53 - 3s - loss: 0.0390 - val_loss: 0.0776 - 3s/epoch - 54ms/step\n",
      "Epoch 9/100\n",
      "53/53 - 3s - loss: 0.0369 - val_loss: 0.0763 - 3s/epoch - 51ms/step\n",
      "Epoch 10/100\n",
      "53/53 - 3s - loss: 0.0370 - val_loss: 0.0417 - 3s/epoch - 53ms/step\n",
      "Epoch 11/100\n",
      "53/53 - 3s - loss: 0.0373 - val_loss: 0.0510 - 3s/epoch - 51ms/step\n",
      "Epoch 12/100\n",
      "53/53 - 3s - loss: 0.0369 - val_loss: 0.0574 - 3s/epoch - 53ms/step\n",
      "Epoch 13/100\n",
      "53/53 - 3s - loss: 0.0345 - val_loss: 0.0403 - 3s/epoch - 53ms/step\n",
      "Epoch 14/100\n",
      "53/53 - 3s - loss: 0.0348 - val_loss: 0.0485 - 3s/epoch - 51ms/step\n",
      "Epoch 15/100\n",
      "53/53 - 3s - loss: 0.0344 - val_loss: 0.0494 - 3s/epoch - 48ms/step\n",
      "Epoch 16/100\n",
      "53/53 - 3s - loss: 0.0341 - val_loss: 0.0506 - 3s/epoch - 55ms/step\n",
      "Epoch 17/100\n",
      "53/53 - 3s - loss: 0.0341 - val_loss: 0.0451 - 3s/epoch - 53ms/step\n",
      "Epoch 18/100\n",
      "53/53 - 3s - loss: 0.0337 - val_loss: 0.0499 - 3s/epoch - 53ms/step\n",
      "Epoch 19/100\n",
      "53/53 - 3s - loss: 0.0335 - val_loss: 0.0649 - 3s/epoch - 51ms/step\n",
      "Epoch 20/100\n",
      "53/53 - 3s - loss: 0.0324 - val_loss: 0.0707 - 3s/epoch - 53ms/step\n",
      "Epoch 21/100\n",
      "53/53 - 3s - loss: 0.0325 - val_loss: 0.0625 - 3s/epoch - 54ms/step\n",
      "Epoch 22/100\n",
      "53/53 - 3s - loss: 0.0305 - val_loss: 0.0677 - 3s/epoch - 54ms/step\n",
      "Epoch 23/100\n",
      "53/53 - 3s - loss: 0.0315 - val_loss: 0.0508 - 3s/epoch - 53ms/step\n",
      "Epoch 24/100\n",
      "53/53 - 3s - loss: 0.0311 - val_loss: 0.0575 - 3s/epoch - 49ms/step\n",
      "Epoch 25/100\n",
      "53/53 - 3s - loss: 0.0319 - val_loss: 0.0533 - 3s/epoch - 57ms/step\n",
      "Epoch 26/100\n",
      "53/53 - 3s - loss: 0.0307 - val_loss: 0.0387 - 3s/epoch - 50ms/step\n",
      "Epoch 27/100\n",
      "53/53 - 3s - loss: 0.0296 - val_loss: 0.0498 - 3s/epoch - 56ms/step\n",
      "Epoch 28/100\n",
      "53/53 - 3s - loss: 0.0299 - val_loss: 0.0555 - 3s/epoch - 54ms/step\n",
      "Epoch 29/100\n",
      "53/53 - 3s - loss: 0.0299 - val_loss: 0.0246 - 3s/epoch - 56ms/step\n",
      "Epoch 30/100\n",
      "53/53 - 3s - loss: 0.0301 - val_loss: 0.0715 - 3s/epoch - 53ms/step\n",
      "Epoch 31/100\n",
      "53/53 - 3s - loss: 0.0301 - val_loss: 0.0850 - 3s/epoch - 52ms/step\n",
      "Epoch 32/100\n",
      "53/53 - 3s - loss: 0.0291 - val_loss: 0.0497 - 3s/epoch - 54ms/step\n",
      "Epoch 33/100\n",
      "53/53 - 3s - loss: 0.0303 - val_loss: 0.0620 - 3s/epoch - 57ms/step\n",
      "Epoch 34/100\n",
      "53/53 - 3s - loss: 0.0281 - val_loss: 0.0627 - 3s/epoch - 54ms/step\n",
      "Epoch 35/100\n",
      "53/53 - 3s - loss: 0.0279 - val_loss: 0.0483 - 3s/epoch - 53ms/step\n",
      "Epoch 36/100\n",
      "53/53 - 3s - loss: 0.0280 - val_loss: 0.0296 - 3s/epoch - 55ms/step\n",
      "Epoch 37/100\n",
      "53/53 - 3s - loss: 0.0278 - val_loss: 0.0379 - 3s/epoch - 51ms/step\n",
      "Epoch 38/100\n",
      "53/53 - 3s - loss: 0.0289 - val_loss: 0.0438 - 3s/epoch - 51ms/step\n",
      "Epoch 39/100\n",
      "53/53 - 3s - loss: 0.0278 - val_loss: 0.0695 - 3s/epoch - 51ms/step\n",
      "Epoch 40/100\n",
      "53/53 - 3s - loss: 0.0279 - val_loss: 0.0674 - 3s/epoch - 56ms/step\n",
      "Epoch 41/100\n",
      "53/53 - 3s - loss: 0.0272 - val_loss: 0.0518 - 3s/epoch - 55ms/step\n",
      "Epoch 42/100\n",
      "53/53 - 3s - loss: 0.0268 - val_loss: 0.0562 - 3s/epoch - 56ms/step\n",
      "Epoch 43/100\n",
      "53/53 - 3s - loss: 0.0264 - val_loss: 0.0282 - 3s/epoch - 56ms/step\n",
      "Epoch 44/100\n",
      "53/53 - 3s - loss: 0.0271 - val_loss: 0.0423 - 3s/epoch - 51ms/step\n",
      "Epoch 45/100\n",
      "53/53 - 3s - loss: 0.0263 - val_loss: 0.0503 - 3s/epoch - 51ms/step\n",
      "Epoch 46/100\n",
      "53/53 - 3s - loss: 0.0259 - val_loss: 0.0261 - 3s/epoch - 50ms/step\n",
      "Epoch 47/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0396 - 3s/epoch - 55ms/step\n",
      "Epoch 48/100\n",
      "53/53 - 3s - loss: 0.0255 - val_loss: 0.0599 - 3s/epoch - 55ms/step\n",
      "Epoch 49/100\n",
      "53/53 - 2s - loss: 0.0252 - val_loss: 0.0698 - 2s/epoch - 44ms/step\n",
      "Epoch 50/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0506 - 3s/epoch - 57ms/step\n",
      "Epoch 51/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0261 - 3s/epoch - 55ms/step\n",
      "Epoch 52/100\n",
      "53/53 - 3s - loss: 0.0259 - val_loss: 0.0589 - 3s/epoch - 52ms/step\n",
      "Epoch 53/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0482 - 3s/epoch - 52ms/step\n",
      "Epoch 54/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.0369 - 3s/epoch - 52ms/step\n",
      "Epoch 55/100\n",
      "53/53 - 3s - loss: 0.0242 - val_loss: 0.0333 - 3s/epoch - 53ms/step\n",
      "Epoch 56/100\n",
      "53/53 - 3s - loss: 0.0242 - val_loss: 0.0238 - 3s/epoch - 54ms/step\n",
      "Epoch 57/100\n",
      "53/53 - 3s - loss: 0.0244 - val_loss: 0.0512 - 3s/epoch - 55ms/step\n",
      "Epoch 58/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.0713 - 3s/epoch - 52ms/step\n",
      "Epoch 59/100\n",
      "53/53 - 3s - loss: 0.0230 - val_loss: 0.0337 - 3s/epoch - 56ms/step\n",
      "Epoch 60/100\n",
      "53/53 - 3s - loss: 0.0236 - val_loss: 0.0589 - 3s/epoch - 53ms/step\n",
      "Epoch 61/100\n",
      "53/53 - 3s - loss: 0.0235 - val_loss: 0.0464 - 3s/epoch - 50ms/step\n",
      "Epoch 62/100\n",
      "53/53 - 3s - loss: 0.0233 - val_loss: 0.0748 - 3s/epoch - 55ms/step\n",
      "Epoch 63/100\n",
      "53/53 - 3s - loss: 0.0231 - val_loss: 0.0599 - 3s/epoch - 54ms/step\n",
      "Epoch 64/100\n",
      "53/53 - 3s - loss: 0.0222 - val_loss: 0.0356 - 3s/epoch - 56ms/step\n",
      "Epoch 65/100\n",
      "53/53 - 3s - loss: 0.0233 - val_loss: 0.0332 - 3s/epoch - 58ms/step\n",
      "Epoch 66/100\n",
      "53/53 - 3s - loss: 0.0221 - val_loss: 0.0436 - 3s/epoch - 58ms/step\n",
      "Epoch 67/100\n",
      "53/53 - 3s - loss: 0.0227 - val_loss: 0.0507 - 3s/epoch - 56ms/step\n",
      "Epoch 68/100\n",
      "53/53 - 3s - loss: 0.0224 - val_loss: 0.0353 - 3s/epoch - 57ms/step\n",
      "Epoch 69/100\n",
      "53/53 - 3s - loss: 0.0218 - val_loss: 0.0417 - 3s/epoch - 51ms/step\n",
      "Epoch 70/100\n",
      "53/53 - 2s - loss: 0.0223 - val_loss: 0.0610 - 2s/epoch - 46ms/step\n",
      "Epoch 71/100\n",
      "53/53 - 3s - loss: 0.0216 - val_loss: 0.0646 - 3s/epoch - 56ms/step\n",
      "Epoch 72/100\n",
      "53/53 - 3s - loss: 0.0216 - val_loss: 0.0392 - 3s/epoch - 56ms/step\n",
      "Epoch 73/100\n",
      "53/53 - 3s - loss: 0.0215 - val_loss: 0.0401 - 3s/epoch - 52ms/step\n",
      "Epoch 74/100\n",
      "53/53 - 3s - loss: 0.0216 - val_loss: 0.0278 - 3s/epoch - 60ms/step\n",
      "Epoch 75/100\n",
      "53/53 - 3s - loss: 0.0207 - val_loss: 0.0488 - 3s/epoch - 57ms/step\n",
      "Epoch 76/100\n",
      "53/53 - 3s - loss: 0.0214 - val_loss: 0.0315 - 3s/epoch - 50ms/step\n",
      "Epoch 77/100\n",
      "53/53 - 3s - loss: 0.0211 - val_loss: 0.0678 - 3s/epoch - 51ms/step\n",
      "Epoch 78/100\n",
      "53/53 - 3s - loss: 0.0212 - val_loss: 0.0344 - 3s/epoch - 51ms/step\n",
      "Epoch 79/100\n",
      "53/53 - 3s - loss: 0.0203 - val_loss: 0.1298 - 3s/epoch - 51ms/step\n",
      "Epoch 80/100\n",
      "53/53 - 3s - loss: 0.0220 - val_loss: 0.0793 - 3s/epoch - 49ms/step\n",
      "Epoch 81/100\n",
      "53/53 - 3s - loss: 0.0203 - val_loss: 0.0718 - 3s/epoch - 53ms/step\n",
      "Epoch 82/100\n",
      "53/53 - 3s - loss: 0.0210 - val_loss: 0.0643 - 3s/epoch - 55ms/step\n",
      "Epoch 83/100\n",
      "53/53 - 3s - loss: 0.0201 - val_loss: 0.0807 - 3s/epoch - 57ms/step\n",
      "Epoch 84/100\n",
      "53/53 - 3s - loss: 0.0214 - val_loss: 0.0705 - 3s/epoch - 55ms/step\n",
      "Epoch 85/100\n",
      "53/53 - 3s - loss: 0.0204 - val_loss: 0.0915 - 3s/epoch - 56ms/step\n",
      "Epoch 86/100\n",
      "53/53 - 3s - loss: 0.0203 - val_loss: 0.0654 - 3s/epoch - 57ms/step\n",
      "Epoch 87/100\n",
      "53/53 - 3s - loss: 0.0206 - val_loss: 0.0820 - 3s/epoch - 56ms/step\n",
      "Epoch 88/100\n",
      "53/53 - 3s - loss: 0.0198 - val_loss: 0.0751 - 3s/epoch - 55ms/step\n",
      "Epoch 89/100\n",
      "53/53 - 3s - loss: 0.0201 - val_loss: 0.0631 - 3s/epoch - 50ms/step\n",
      "Epoch 90/100\n",
      "53/53 - 3s - loss: 0.0190 - val_loss: 0.0751 - 3s/epoch - 51ms/step\n",
      "Epoch 91/100\n",
      "53/53 - 3s - loss: 0.0200 - val_loss: 0.0860 - 3s/epoch - 54ms/step\n",
      "Epoch 92/100\n",
      "53/53 - 3s - loss: 0.0194 - val_loss: 0.0886 - 3s/epoch - 55ms/step\n",
      "Epoch 93/100\n",
      "53/53 - 3s - loss: 0.0194 - val_loss: 0.0735 - 3s/epoch - 54ms/step\n",
      "Epoch 94/100\n",
      "53/53 - 3s - loss: 0.0188 - val_loss: 0.0860 - 3s/epoch - 52ms/step\n",
      "Epoch 95/100\n",
      "53/53 - 3s - loss: 0.0193 - val_loss: 0.0702 - 3s/epoch - 54ms/step\n",
      "Epoch 96/100\n",
      "53/53 - 3s - loss: 0.0191 - val_loss: 0.0840 - 3s/epoch - 51ms/step\n",
      "Epoch 97/100\n",
      "53/53 - 3s - loss: 0.0190 - val_loss: 0.0755 - 3s/epoch - 55ms/step\n",
      "Epoch 98/100\n",
      "53/53 - 3s - loss: 0.0194 - val_loss: 0.0773 - 3s/epoch - 54ms/step\n",
      "Epoch 99/100\n",
      "53/53 - 3s - loss: 0.0188 - val_loss: 0.0499 - 3s/epoch - 55ms/step\n",
      "Epoch 100/100\n",
      "53/53 - 3s - loss: 0.0187 - val_loss: 0.0700 - 3s/epoch - 55ms/step\n",
      "Evaluating the Performance of lstm Model\n",
      "53/53 [==============================] - 2s 15ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 95.42246183983507\n",
      "Accuarcy of Testing Data 93.35805612709953\n",
      "Saving the lstm Model\n"
     ]
    }
   ],
   "source": [
    "## Building lstm model - open feature\n",
    "build_model(data=nifty50_data_url,stock_name='Nifyt50',features_names=['Open'],model='lstm')\n",
    "## Building lstm model - close feature\n",
    "build_model(data=nifty50_data_url,stock_name='Nifty50',features_names=['Close'],model='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset (2467, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                   Open\n",
      "Date                   \n",
      "2013-12-13  6201.299805\n",
      "2013-12-16  6168.350098\n",
      "2013-12-17  6178.200195\n",
      "2013-12-18  6129.950195\n",
      "2013-12-19  6253.899902\n",
      "Performing MinMaxScaling\n",
      "                Open\n",
      "Date                \n",
      "2013-12-13  0.016834\n",
      "2013-12-16  0.014647\n",
      "2013-12-17  0.015301\n",
      "2013-12-18  0.012099\n",
      "2013-12-19  0.020324\n",
      "Length of Training data (1717, 1)\n",
      "Length of Testing data (368, 1)\n",
      "Length of Validation data (368, 1)\n",
      "Shape of dataset is features (1667, 50, 1) and targets (1667, 1)\n",
      "Shape of dataset is features (318, 50, 1) and targets (318, 1)\n",
      "Shape of dataset is features (318, 50, 1) and targets (318, 1)\n",
      "-------------Preparing bidirectional_lSTM Model----------------\n",
      "========================Summary of bidirectional_lstm==========================\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_20 (Bidirect  (None, 50, 128)           33792     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 50, 128)           0         \n",
      "                                                                 \n",
      " bidirectional_21 (Bidirect  (None, 128)               98816     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136769 (534.25 KB)\n",
      "Trainable params: 136769 (534.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the bidirectional_lstm Model====================\n",
      "Epoch 1/100\n",
      "53/53 - 11s - loss: 0.1587 - val_loss: 0.3526 - 11s/epoch - 198ms/step\n",
      "Epoch 2/100\n",
      "53/53 - 3s - loss: 0.0575 - val_loss: 0.1469 - 3s/epoch - 62ms/step\n",
      "Epoch 3/100\n",
      "53/53 - 4s - loss: 0.0448 - val_loss: 0.0403 - 4s/epoch - 68ms/step\n",
      "Epoch 4/100\n",
      "53/53 - 3s - loss: 0.0393 - val_loss: 0.0776 - 3s/epoch - 64ms/step\n",
      "Epoch 5/100\n",
      "53/53 - 4s - loss: 0.0383 - val_loss: 0.1210 - 4s/epoch - 66ms/step\n",
      "Epoch 6/100\n",
      "53/53 - 3s - loss: 0.0380 - val_loss: 0.1791 - 3s/epoch - 65ms/step\n",
      "Epoch 7/100\n",
      "53/53 - 3s - loss: 0.0364 - val_loss: 0.1176 - 3s/epoch - 65ms/step\n",
      "Epoch 8/100\n",
      "53/53 - 3s - loss: 0.0348 - val_loss: 0.0832 - 3s/epoch - 64ms/step\n",
      "Epoch 9/100\n",
      "53/53 - 3s - loss: 0.0356 - val_loss: 0.0886 - 3s/epoch - 65ms/step\n",
      "Epoch 10/100\n",
      "53/53 - 3s - loss: 0.0351 - val_loss: 0.1341 - 3s/epoch - 66ms/step\n",
      "Epoch 11/100\n",
      "53/53 - 3s - loss: 0.0352 - val_loss: 0.0661 - 3s/epoch - 65ms/step\n",
      "Epoch 12/100\n",
      "53/53 - 3s - loss: 0.0336 - val_loss: 0.0560 - 3s/epoch - 66ms/step\n",
      "Epoch 13/100\n",
      "53/53 - 3s - loss: 0.0328 - val_loss: 0.1218 - 3s/epoch - 63ms/step\n",
      "Epoch 14/100\n",
      "53/53 - 4s - loss: 0.0325 - val_loss: 0.0779 - 4s/epoch - 67ms/step\n",
      "Epoch 15/100\n",
      "53/53 - 3s - loss: 0.0319 - val_loss: 0.0249 - 3s/epoch - 63ms/step\n",
      "Epoch 16/100\n",
      "53/53 - 3s - loss: 0.0323 - val_loss: 0.0431 - 3s/epoch - 65ms/step\n",
      "Epoch 17/100\n",
      "53/53 - 3s - loss: 0.0316 - val_loss: 0.0607 - 3s/epoch - 66ms/step\n",
      "Epoch 18/100\n",
      "53/53 - 4s - loss: 0.0301 - val_loss: 0.0626 - 4s/epoch - 69ms/step\n",
      "Epoch 19/100\n",
      "53/53 - 4s - loss: 0.0304 - val_loss: 0.0403 - 4s/epoch - 66ms/step\n",
      "Epoch 20/100\n",
      "53/53 - 3s - loss: 0.0302 - val_loss: 0.0570 - 3s/epoch - 65ms/step\n",
      "Epoch 21/100\n",
      "53/53 - 3s - loss: 0.0291 - val_loss: 0.0487 - 3s/epoch - 64ms/step\n",
      "Epoch 22/100\n",
      "53/53 - 3s - loss: 0.0288 - val_loss: 0.0471 - 3s/epoch - 65ms/step\n",
      "Epoch 23/100\n",
      "53/53 - 4s - loss: 0.0297 - val_loss: 0.0461 - 4s/epoch - 66ms/step\n",
      "Epoch 24/100\n",
      "53/53 - 3s - loss: 0.0290 - val_loss: 0.0385 - 3s/epoch - 65ms/step\n",
      "Epoch 25/100\n",
      "53/53 - 3s - loss: 0.0279 - val_loss: 0.0312 - 3s/epoch - 64ms/step\n",
      "Epoch 26/100\n",
      "53/53 - 3s - loss: 0.0277 - val_loss: 0.0349 - 3s/epoch - 64ms/step\n",
      "Epoch 27/100\n",
      "53/53 - 4s - loss: 0.0273 - val_loss: 0.0388 - 4s/epoch - 69ms/step\n",
      "Epoch 28/100\n",
      "53/53 - 3s - loss: 0.0272 - val_loss: 0.0276 - 3s/epoch - 64ms/step\n",
      "Epoch 29/100\n",
      "53/53 - 3s - loss: 0.0265 - val_loss: 0.0219 - 3s/epoch - 66ms/step\n",
      "Epoch 30/100\n",
      "53/53 - 3s - loss: 0.0264 - val_loss: 0.0177 - 3s/epoch - 65ms/step\n",
      "Epoch 31/100\n",
      "53/53 - 3s - loss: 0.0261 - val_loss: 0.0340 - 3s/epoch - 65ms/step\n",
      "Epoch 32/100\n",
      "53/53 - 3s - loss: 0.0267 - val_loss: 0.0237 - 3s/epoch - 65ms/step\n",
      "Epoch 33/100\n",
      "53/53 - 3s - loss: 0.0261 - val_loss: 0.0173 - 3s/epoch - 65ms/step\n",
      "Epoch 34/100\n",
      "53/53 - 3s - loss: 0.0258 - val_loss: 0.0173 - 3s/epoch - 63ms/step\n",
      "Epoch 35/100\n",
      "53/53 - 3s - loss: 0.0259 - val_loss: 0.0181 - 3s/epoch - 64ms/step\n",
      "Epoch 36/100\n",
      "53/53 - 4s - loss: 0.0241 - val_loss: 0.0360 - 4s/epoch - 66ms/step\n",
      "Epoch 37/100\n",
      "53/53 - 3s - loss: 0.0254 - val_loss: 0.0149 - 3s/epoch - 65ms/step\n",
      "Epoch 38/100\n",
      "53/53 - 3s - loss: 0.0258 - val_loss: 0.0173 - 3s/epoch - 65ms/step\n",
      "Epoch 39/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0146 - 3s/epoch - 63ms/step\n",
      "Epoch 40/100\n",
      "53/53 - 3s - loss: 0.0244 - val_loss: 0.0147 - 3s/epoch - 65ms/step\n",
      "Epoch 41/100\n",
      "53/53 - 4s - loss: 0.0242 - val_loss: 0.0192 - 4s/epoch - 67ms/step\n",
      "Epoch 42/100\n",
      "53/53 - 4s - loss: 0.0240 - val_loss: 0.0179 - 4s/epoch - 70ms/step\n",
      "Epoch 43/100\n",
      "53/53 - 3s - loss: 0.0247 - val_loss: 0.0273 - 3s/epoch - 64ms/step\n",
      "Epoch 44/100\n",
      "53/53 - 4s - loss: 0.0239 - val_loss: 0.0155 - 4s/epoch - 67ms/step\n",
      "Epoch 45/100\n",
      "53/53 - 4s - loss: 0.0236 - val_loss: 0.0235 - 4s/epoch - 67ms/step\n",
      "Epoch 46/100\n",
      "53/53 - 4s - loss: 0.0229 - val_loss: 0.0175 - 4s/epoch - 68ms/step\n",
      "Epoch 47/100\n",
      "53/53 - 3s - loss: 0.0236 - val_loss: 0.0266 - 3s/epoch - 64ms/step\n",
      "Epoch 48/100\n",
      "53/53 - 3s - loss: 0.0228 - val_loss: 0.0142 - 3s/epoch - 66ms/step\n",
      "Epoch 49/100\n",
      "53/53 - 3s - loss: 0.0231 - val_loss: 0.0151 - 3s/epoch - 65ms/step\n",
      "Epoch 50/100\n",
      "53/53 - 3s - loss: 0.0227 - val_loss: 0.0134 - 3s/epoch - 64ms/step\n",
      "Epoch 51/100\n",
      "53/53 - 3s - loss: 0.0222 - val_loss: 0.0155 - 3s/epoch - 63ms/step\n",
      "Epoch 52/100\n",
      "53/53 - 3s - loss: 0.0223 - val_loss: 0.0587 - 3s/epoch - 65ms/step\n",
      "Epoch 53/100\n",
      "53/53 - 4s - loss: 0.0229 - val_loss: 0.0183 - 4s/epoch - 70ms/step\n",
      "Epoch 54/100\n",
      "53/53 - 3s - loss: 0.0219 - val_loss: 0.0285 - 3s/epoch - 64ms/step\n",
      "Epoch 55/100\n",
      "53/53 - 3s - loss: 0.0230 - val_loss: 0.0425 - 3s/epoch - 65ms/step\n",
      "Epoch 56/100\n",
      "53/53 - 3s - loss: 0.0214 - val_loss: 0.0134 - 3s/epoch - 63ms/step\n",
      "Epoch 57/100\n",
      "53/53 - 3s - loss: 0.0216 - val_loss: 0.0130 - 3s/epoch - 65ms/step\n",
      "Epoch 58/100\n",
      "53/53 - 3s - loss: 0.0216 - val_loss: 0.0183 - 3s/epoch - 64ms/step\n",
      "Epoch 59/100\n",
      "53/53 - 3s - loss: 0.0211 - val_loss: 0.0130 - 3s/epoch - 64ms/step\n",
      "Epoch 60/100\n",
      "53/53 - 3s - loss: 0.0212 - val_loss: 0.0145 - 3s/epoch - 63ms/step\n",
      "Epoch 61/100\n",
      "53/53 - 3s - loss: 0.0213 - val_loss: 0.0204 - 3s/epoch - 65ms/step\n",
      "Epoch 62/100\n",
      "53/53 - 3s - loss: 0.0215 - val_loss: 0.0164 - 3s/epoch - 65ms/step\n",
      "Epoch 63/100\n",
      "53/53 - 3s - loss: 0.0212 - val_loss: 0.0548 - 3s/epoch - 63ms/step\n",
      "Epoch 64/100\n",
      "53/53 - 3s - loss: 0.0210 - val_loss: 0.0159 - 3s/epoch - 64ms/step\n",
      "Epoch 65/100\n",
      "53/53 - 3s - loss: 0.0204 - val_loss: 0.0130 - 3s/epoch - 64ms/step\n",
      "Epoch 66/100\n",
      "53/53 - 3s - loss: 0.0212 - val_loss: 0.0190 - 3s/epoch - 64ms/step\n",
      "Epoch 67/100\n",
      "53/53 - 3s - loss: 0.0198 - val_loss: 0.0135 - 3s/epoch - 63ms/step\n",
      "Epoch 68/100\n",
      "53/53 - 3s - loss: 0.0207 - val_loss: 0.0261 - 3s/epoch - 64ms/step\n",
      "Epoch 69/100\n",
      "53/53 - 3s - loss: 0.0208 - val_loss: 0.0142 - 3s/epoch - 65ms/step\n",
      "Epoch 70/100\n",
      "53/53 - 4s - loss: 0.0204 - val_loss: 0.0235 - 4s/epoch - 67ms/step\n",
      "Epoch 71/100\n",
      "53/53 - 3s - loss: 0.0204 - val_loss: 0.0533 - 3s/epoch - 64ms/step\n",
      "Epoch 72/100\n",
      "53/53 - 3s - loss: 0.0202 - val_loss: 0.0337 - 3s/epoch - 65ms/step\n",
      "Epoch 73/100\n",
      "53/53 - 3s - loss: 0.0202 - val_loss: 0.0429 - 3s/epoch - 66ms/step\n",
      "Epoch 74/100\n",
      "53/53 - 3s - loss: 0.0197 - val_loss: 0.0526 - 3s/epoch - 64ms/step\n",
      "Epoch 75/100\n",
      "53/53 - 3s - loss: 0.0201 - val_loss: 0.0661 - 3s/epoch - 63ms/step\n",
      "Epoch 76/100\n",
      "53/53 - 3s - loss: 0.0204 - val_loss: 0.0317 - 3s/epoch - 64ms/step\n",
      "Epoch 77/100\n",
      "53/53 - 3s - loss: 0.0190 - val_loss: 0.0548 - 3s/epoch - 65ms/step\n",
      "Epoch 78/100\n",
      "53/53 - 3s - loss: 0.0202 - val_loss: 0.0320 - 3s/epoch - 65ms/step\n",
      "Epoch 79/100\n",
      "53/53 - 3s - loss: 0.0198 - val_loss: 0.0407 - 3s/epoch - 64ms/step\n",
      "Epoch 80/100\n",
      "53/53 - 3s - loss: 0.0195 - val_loss: 0.0186 - 3s/epoch - 63ms/step\n",
      "Epoch 81/100\n",
      "53/53 - 3s - loss: 0.0198 - val_loss: 0.0251 - 3s/epoch - 65ms/step\n",
      "Epoch 82/100\n",
      "53/53 - 3s - loss: 0.0187 - val_loss: 0.0608 - 3s/epoch - 63ms/step\n",
      "Epoch 83/100\n",
      "53/53 - 3s - loss: 0.0193 - val_loss: 0.0484 - 3s/epoch - 63ms/step\n",
      "Epoch 84/100\n",
      "53/53 - 3s - loss: 0.0189 - val_loss: 0.0594 - 3s/epoch - 65ms/step\n",
      "Epoch 85/100\n",
      "53/53 - 3s - loss: 0.0196 - val_loss: 0.0833 - 3s/epoch - 63ms/step\n",
      "Epoch 86/100\n",
      "53/53 - 3s - loss: 0.0185 - val_loss: 0.0795 - 3s/epoch - 65ms/step\n",
      "Epoch 87/100\n",
      "53/53 - 3s - loss: 0.0188 - val_loss: 0.0687 - 3s/epoch - 66ms/step\n",
      "Epoch 88/100\n",
      "53/53 - 3s - loss: 0.0188 - val_loss: 0.0644 - 3s/epoch - 64ms/step\n",
      "Epoch 89/100\n",
      "53/53 - 4s - loss: 0.0192 - val_loss: 0.0344 - 4s/epoch - 67ms/step\n",
      "Epoch 90/100\n",
      "53/53 - 3s - loss: 0.0184 - val_loss: 0.0674 - 3s/epoch - 65ms/step\n",
      "Epoch 91/100\n",
      "53/53 - 3s - loss: 0.0182 - val_loss: 0.0647 - 3s/epoch - 65ms/step\n",
      "Epoch 92/100\n",
      "53/53 - 3s - loss: 0.0179 - val_loss: 0.0544 - 3s/epoch - 62ms/step\n",
      "Epoch 93/100\n",
      "53/53 - 4s - loss: 0.0178 - val_loss: 0.0612 - 4s/epoch - 66ms/step\n",
      "Epoch 94/100\n",
      "53/53 - 3s - loss: 0.0185 - val_loss: 0.0763 - 3s/epoch - 61ms/step\n",
      "Epoch 95/100\n",
      "53/53 - 3s - loss: 0.0186 - val_loss: 0.0607 - 3s/epoch - 61ms/step\n",
      "Epoch 96/100\n",
      "53/53 - 3s - loss: 0.0176 - val_loss: 0.0545 - 3s/epoch - 61ms/step\n",
      "Epoch 97/100\n",
      "53/53 - 3s - loss: 0.0179 - val_loss: 0.0877 - 3s/epoch - 60ms/step\n",
      "Epoch 98/100\n",
      "53/53 - 3s - loss: 0.0174 - val_loss: 0.0579 - 3s/epoch - 60ms/step\n",
      "Epoch 99/100\n",
      "53/53 - 3s - loss: 0.0177 - val_loss: 0.0909 - 3s/epoch - 62ms/step\n",
      "Epoch 100/100\n",
      "53/53 - 3s - loss: 0.0180 - val_loss: 0.0543 - 3s/epoch - 60ms/step\n",
      "Evaluating the Performance of bidirectional_lstm Model\n",
      "53/53 [==============================] - 2s 19ms/step\n",
      "10/10 [==============================] - 0s 19ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 96.62093923119605\n",
      "Accuarcy of Testing Data 94.68181033526128\n",
      "Saving the bidirectional_lstm Model\n",
      "shape of the dataset (2467, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                  Close\n",
      "Date                   \n",
      "2013-12-13  6168.399902\n",
      "2013-12-16  6154.700195\n",
      "2013-12-17  6139.049805\n",
      "2013-12-18  6217.149902\n",
      "2013-12-19  6166.649902\n",
      "Performing MinMaxScaling\n",
      "               Close\n",
      "Date                \n",
      "2013-12-13  0.011169\n",
      "2013-12-16  0.010256\n",
      "2013-12-17  0.009212\n",
      "2013-12-18  0.014420\n",
      "2013-12-19  0.011053\n",
      "Length of Training data (1717, 1)\n",
      "Length of Testing data (368, 1)\n",
      "Length of Validation data (368, 1)\n",
      "Shape of dataset is features (1667, 50, 1) and targets (1667, 1)\n",
      "Shape of dataset is features (318, 50, 1) and targets (318, 1)\n",
      "Shape of dataset is features (318, 50, 1) and targets (318, 1)\n",
      "-------------Preparing bidirectional_lSTM Model----------------\n",
      "========================Summary of bidirectional_lstm==========================\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_22 (Bidirect  (None, 50, 128)           33792     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 50, 128)           0         \n",
      "                                                                 \n",
      " bidirectional_23 (Bidirect  (None, 128)               98816     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136769 (534.25 KB)\n",
      "Trainable params: 136769 (534.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the bidirectional_lstm Model====================\n",
      "Epoch 1/100\n",
      "53/53 - 11s - loss: 0.1738 - val_loss: 0.4993 - 11s/epoch - 199ms/step\n",
      "Epoch 2/100\n",
      "53/53 - 3s - loss: 0.0637 - val_loss: 0.2229 - 3s/epoch - 55ms/step\n",
      "Epoch 3/100\n",
      "53/53 - 3s - loss: 0.0451 - val_loss: 0.0449 - 3s/epoch - 55ms/step\n",
      "Epoch 4/100\n",
      "53/53 - 3s - loss: 0.0391 - val_loss: 0.0338 - 3s/epoch - 54ms/step\n",
      "Epoch 5/100\n",
      "53/53 - 3s - loss: 0.0369 - val_loss: 0.0716 - 3s/epoch - 55ms/step\n",
      "Epoch 6/100\n",
      "53/53 - 3s - loss: 0.0349 - val_loss: 0.0516 - 3s/epoch - 65ms/step\n",
      "Epoch 7/100\n",
      "53/53 - 3s - loss: 0.0340 - val_loss: 0.0401 - 3s/epoch - 60ms/step\n",
      "Epoch 8/100\n",
      "53/53 - 3s - loss: 0.0327 - val_loss: 0.1696 - 3s/epoch - 61ms/step\n",
      "Epoch 9/100\n",
      "53/53 - 3s - loss: 0.0318 - val_loss: 0.0938 - 3s/epoch - 58ms/step\n",
      "Epoch 10/100\n",
      "53/53 - 3s - loss: 0.0309 - val_loss: 0.1222 - 3s/epoch - 62ms/step\n",
      "Epoch 11/100\n",
      "53/53 - 3s - loss: 0.0299 - val_loss: 0.0783 - 3s/epoch - 60ms/step\n",
      "Epoch 12/100\n",
      "53/53 - 3s - loss: 0.0312 - val_loss: 0.0805 - 3s/epoch - 64ms/step\n",
      "Epoch 13/100\n",
      "53/53 - 3s - loss: 0.0296 - val_loss: 0.0642 - 3s/epoch - 63ms/step\n",
      "Epoch 14/100\n",
      "53/53 - 3s - loss: 0.0295 - val_loss: 0.1136 - 3s/epoch - 59ms/step\n",
      "Epoch 15/100\n",
      "53/53 - 3s - loss: 0.0294 - val_loss: 0.1225 - 3s/epoch - 61ms/step\n",
      "Epoch 16/100\n",
      "53/53 - 3s - loss: 0.0274 - val_loss: 0.1131 - 3s/epoch - 61ms/step\n",
      "Epoch 17/100\n",
      "53/53 - 3s - loss: 0.0287 - val_loss: 0.0539 - 3s/epoch - 61ms/step\n",
      "Epoch 18/100\n",
      "53/53 - 3s - loss: 0.0281 - val_loss: 0.0510 - 3s/epoch - 58ms/step\n",
      "Epoch 19/100\n",
      "53/53 - 3s - loss: 0.0271 - val_loss: 0.0666 - 3s/epoch - 61ms/step\n",
      "Epoch 20/100\n",
      "53/53 - 3s - loss: 0.0275 - val_loss: 0.0432 - 3s/epoch - 59ms/step\n",
      "Epoch 21/100\n",
      "53/53 - 3s - loss: 0.0275 - val_loss: 0.0535 - 3s/epoch - 61ms/step\n",
      "Epoch 22/100\n",
      "53/53 - 3s - loss: 0.0259 - val_loss: 0.0423 - 3s/epoch - 61ms/step\n",
      "Epoch 23/100\n",
      "53/53 - 3s - loss: 0.0266 - val_loss: 0.0485 - 3s/epoch - 65ms/step\n",
      "Epoch 24/100\n",
      "53/53 - 3s - loss: 0.0262 - val_loss: 0.0641 - 3s/epoch - 61ms/step\n",
      "Epoch 25/100\n",
      "53/53 - 3s - loss: 0.0273 - val_loss: 0.0372 - 3s/epoch - 61ms/step\n",
      "Epoch 26/100\n",
      "53/53 - 3s - loss: 0.0257 - val_loss: 0.0507 - 3s/epoch - 60ms/step\n",
      "Epoch 27/100\n",
      "53/53 - 3s - loss: 0.0249 - val_loss: 0.0542 - 3s/epoch - 61ms/step\n",
      "Epoch 28/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0263 - 3s/epoch - 61ms/step\n",
      "Epoch 29/100\n",
      "53/53 - 3s - loss: 0.0252 - val_loss: 0.0548 - 3s/epoch - 60ms/step\n",
      "Epoch 30/100\n",
      "53/53 - 3s - loss: 0.0246 - val_loss: 0.0448 - 3s/epoch - 61ms/step\n",
      "Epoch 31/100\n",
      "53/53 - 3s - loss: 0.0246 - val_loss: 0.0397 - 3s/epoch - 59ms/step\n",
      "Epoch 32/100\n",
      "53/53 - 3s - loss: 0.0241 - val_loss: 0.0284 - 3s/epoch - 62ms/step\n",
      "Epoch 33/100\n",
      "53/53 - 3s - loss: 0.0249 - val_loss: 0.0295 - 3s/epoch - 59ms/step\n",
      "Epoch 34/100\n",
      "53/53 - 3s - loss: 0.0243 - val_loss: 0.0155 - 3s/epoch - 61ms/step\n",
      "Epoch 35/100\n",
      "53/53 - 3s - loss: 0.0235 - val_loss: 0.0179 - 3s/epoch - 58ms/step\n",
      "Epoch 36/100\n",
      "53/53 - 3s - loss: 0.0239 - val_loss: 0.0214 - 3s/epoch - 63ms/step\n",
      "Epoch 37/100\n",
      "53/53 - 3s - loss: 0.0233 - val_loss: 0.0212 - 3s/epoch - 60ms/step\n",
      "Epoch 38/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.0351 - 3s/epoch - 59ms/step\n",
      "Epoch 39/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.0486 - 3s/epoch - 60ms/step\n",
      "Epoch 40/100\n",
      "53/53 - 3s - loss: 0.0234 - val_loss: 0.0168 - 3s/epoch - 63ms/step\n",
      "Epoch 41/100\n",
      "53/53 - 3s - loss: 0.0233 - val_loss: 0.0365 - 3s/epoch - 60ms/step\n",
      "Epoch 42/100\n",
      "53/53 - 3s - loss: 0.0232 - val_loss: 0.0462 - 3s/epoch - 61ms/step\n",
      "Epoch 43/100\n",
      "53/53 - 3s - loss: 0.0220 - val_loss: 0.0239 - 3s/epoch - 61ms/step\n",
      "Epoch 44/100\n",
      "53/53 - 3s - loss: 0.0222 - val_loss: 0.0311 - 3s/epoch - 60ms/step\n",
      "Epoch 45/100\n",
      "53/53 - 3s - loss: 0.0232 - val_loss: 0.0202 - 3s/epoch - 60ms/step\n",
      "Epoch 46/100\n",
      "53/53 - 3s - loss: 0.0230 - val_loss: 0.0610 - 3s/epoch - 60ms/step\n",
      "Epoch 47/100\n",
      "53/53 - 3s - loss: 0.0222 - val_loss: 0.0577 - 3s/epoch - 60ms/step\n",
      "Epoch 48/100\n",
      "53/53 - 3s - loss: 0.0222 - val_loss: 0.0356 - 3s/epoch - 60ms/step\n",
      "Epoch 49/100\n",
      "53/53 - 3s - loss: 0.0220 - val_loss: 0.0539 - 3s/epoch - 60ms/step\n",
      "Epoch 50/100\n",
      "53/53 - 3s - loss: 0.0218 - val_loss: 0.0378 - 3s/epoch - 60ms/step\n",
      "Epoch 51/100\n",
      "53/53 - 3s - loss: 0.0222 - val_loss: 0.0327 - 3s/epoch - 60ms/step\n",
      "Epoch 52/100\n",
      "53/53 - 3s - loss: 0.0219 - val_loss: 0.0504 - 3s/epoch - 60ms/step\n",
      "Epoch 53/100\n",
      "53/53 - 3s - loss: 0.0215 - val_loss: 0.0468 - 3s/epoch - 60ms/step\n",
      "Epoch 54/100\n",
      "53/53 - 3s - loss: 0.0211 - val_loss: 0.0193 - 3s/epoch - 60ms/step\n",
      "Epoch 55/100\n",
      "53/53 - 3s - loss: 0.0212 - val_loss: 0.0241 - 3s/epoch - 61ms/step\n",
      "Epoch 56/100\n",
      "53/53 - 3s - loss: 0.0217 - val_loss: 0.0424 - 3s/epoch - 59ms/step\n",
      "Epoch 57/100\n",
      "53/53 - 3s - loss: 0.0212 - val_loss: 0.0545 - 3s/epoch - 60ms/step\n",
      "Epoch 58/100\n",
      "53/53 - 3s - loss: 0.0205 - val_loss: 0.0413 - 3s/epoch - 61ms/step\n",
      "Epoch 59/100\n",
      "53/53 - 3s - loss: 0.0202 - val_loss: 0.0380 - 3s/epoch - 61ms/step\n",
      "Epoch 60/100\n",
      "53/53 - 3s - loss: 0.0195 - val_loss: 0.0142 - 3s/epoch - 63ms/step\n",
      "Epoch 61/100\n",
      "53/53 - 3s - loss: 0.0209 - val_loss: 0.0382 - 3s/epoch - 62ms/step\n",
      "Epoch 62/100\n",
      "53/53 - 3s - loss: 0.0200 - val_loss: 0.0144 - 3s/epoch - 61ms/step\n",
      "Epoch 63/100\n",
      "53/53 - 3s - loss: 0.0206 - val_loss: 0.0665 - 3s/epoch - 62ms/step\n",
      "Epoch 64/100\n",
      "53/53 - 3s - loss: 0.0203 - val_loss: 0.0557 - 3s/epoch - 61ms/step\n",
      "Epoch 65/100\n",
      "53/53 - 3s - loss: 0.0201 - val_loss: 0.0771 - 3s/epoch - 64ms/step\n",
      "Epoch 66/100\n",
      "53/53 - 3s - loss: 0.0205 - val_loss: 0.0249 - 3s/epoch - 64ms/step\n",
      "Epoch 67/100\n",
      "53/53 - 3s - loss: 0.0210 - val_loss: 0.0629 - 3s/epoch - 61ms/step\n",
      "Epoch 68/100\n",
      "53/53 - 3s - loss: 0.0200 - val_loss: 0.0364 - 3s/epoch - 61ms/step\n",
      "Epoch 69/100\n",
      "53/53 - 3s - loss: 0.0202 - val_loss: 0.0633 - 3s/epoch - 61ms/step\n",
      "Epoch 70/100\n",
      "53/53 - 3s - loss: 0.0200 - val_loss: 0.0320 - 3s/epoch - 60ms/step\n",
      "Epoch 71/100\n",
      "53/53 - 3s - loss: 0.0192 - val_loss: 0.0792 - 3s/epoch - 61ms/step\n",
      "Epoch 72/100\n",
      "53/53 - 3s - loss: 0.0197 - val_loss: 0.0511 - 3s/epoch - 61ms/step\n",
      "Epoch 73/100\n",
      "53/53 - 3s - loss: 0.0195 - val_loss: 0.0631 - 3s/epoch - 60ms/step\n",
      "Epoch 74/100\n",
      "53/53 - 3s - loss: 0.0194 - val_loss: 0.0519 - 3s/epoch - 62ms/step\n",
      "Epoch 75/100\n",
      "53/53 - 3s - loss: 0.0191 - val_loss: 0.0694 - 3s/epoch - 62ms/step\n",
      "Epoch 76/100\n",
      "53/53 - 3s - loss: 0.0191 - val_loss: 0.0743 - 3s/epoch - 61ms/step\n",
      "Epoch 77/100\n",
      "53/53 - 3s - loss: 0.0200 - val_loss: 0.0500 - 3s/epoch - 61ms/step\n",
      "Epoch 78/100\n",
      "53/53 - 3s - loss: 0.0189 - val_loss: 0.0832 - 3s/epoch - 63ms/step\n",
      "Epoch 79/100\n",
      "53/53 - 3s - loss: 0.0189 - val_loss: 0.0831 - 3s/epoch - 63ms/step\n",
      "Epoch 80/100\n",
      "53/53 - 3s - loss: 0.0194 - val_loss: 0.0676 - 3s/epoch - 62ms/step\n",
      "Epoch 81/100\n",
      "53/53 - 3s - loss: 0.0180 - val_loss: 0.0716 - 3s/epoch - 61ms/step\n",
      "Epoch 82/100\n",
      "53/53 - 3s - loss: 0.0189 - val_loss: 0.0663 - 3s/epoch - 61ms/step\n",
      "Epoch 83/100\n",
      "53/53 - 3s - loss: 0.0182 - val_loss: 0.0684 - 3s/epoch - 63ms/step\n",
      "Epoch 84/100\n",
      "53/53 - 3s - loss: 0.0192 - val_loss: 0.0726 - 3s/epoch - 65ms/step\n",
      "Epoch 85/100\n",
      "53/53 - 3s - loss: 0.0179 - val_loss: 0.0758 - 3s/epoch - 61ms/step\n",
      "Epoch 86/100\n",
      "53/53 - 3s - loss: 0.0188 - val_loss: 0.0469 - 3s/epoch - 61ms/step\n",
      "Epoch 87/100\n",
      "53/53 - 3s - loss: 0.0179 - val_loss: 0.0886 - 3s/epoch - 61ms/step\n",
      "Epoch 88/100\n",
      "53/53 - 3s - loss: 0.0180 - val_loss: 0.0561 - 3s/epoch - 61ms/step\n",
      "Epoch 89/100\n",
      "53/53 - 3s - loss: 0.0181 - val_loss: 0.0439 - 3s/epoch - 61ms/step\n",
      "Epoch 90/100\n",
      "53/53 - 3s - loss: 0.0174 - val_loss: 0.0805 - 3s/epoch - 61ms/step\n",
      "Epoch 91/100\n",
      "53/53 - 3s - loss: 0.0182 - val_loss: 0.0797 - 3s/epoch - 61ms/step\n",
      "Epoch 92/100\n",
      "53/53 - 3s - loss: 0.0183 - val_loss: 0.0961 - 3s/epoch - 61ms/step\n",
      "Epoch 93/100\n",
      "53/53 - 3s - loss: 0.0184 - val_loss: 0.0585 - 3s/epoch - 63ms/step\n",
      "Epoch 94/100\n",
      "53/53 - 3s - loss: 0.0186 - val_loss: 0.0584 - 3s/epoch - 62ms/step\n",
      "Epoch 95/100\n",
      "53/53 - 3s - loss: 0.0174 - val_loss: 0.0797 - 3s/epoch - 61ms/step\n",
      "Epoch 96/100\n",
      "53/53 - 3s - loss: 0.0180 - val_loss: 0.1157 - 3s/epoch - 65ms/step\n",
      "Epoch 97/100\n",
      "53/53 - 3s - loss: 0.0170 - val_loss: 0.1046 - 3s/epoch - 61ms/step\n",
      "Epoch 98/100\n",
      "53/53 - 3s - loss: 0.0170 - val_loss: 0.0905 - 3s/epoch - 62ms/step\n",
      "Epoch 99/100\n",
      "53/53 - 3s - loss: 0.0167 - val_loss: 0.0958 - 3s/epoch - 59ms/step\n",
      "Epoch 100/100\n",
      "53/53 - 3s - loss: 0.0177 - val_loss: 0.0543 - 3s/epoch - 62ms/step\n",
      "Evaluating the Performance of bidirectional_lstm Model\n",
      "53/53 [==============================] - 2s 20ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 96.53109013406235\n",
      "Accuarcy of Testing Data 94.78706042610386\n",
      "Saving the bidirectional_lstm Model\n"
     ]
    }
   ],
   "source": [
    "## Building Bidirectional_lstm model - open feature\n",
    "build_model(data=nifty50_data_url,stock_name='Nifyt50',features_names=['Open'],model='bidirectional_lstm')\n",
    "## Building Bidirectional_lstm model - close feature\n",
    "build_model(data=nifty50_data_url,stock_name='Nifyt50',features_names=['Close'],model='bidirectional_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset (2467, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                  Open\n",
      "Date                  \n",
      "2013-12-13  429.429443\n",
      "2013-12-16  425.962311\n",
      "2013-12-17  420.365356\n",
      "2013-12-18  415.659973\n",
      "2013-12-19  428.141632\n",
      "Performing MinMaxScaling\n",
      "                Open\n",
      "Date                \n",
      "2013-12-13  0.013471\n",
      "2013-12-16  0.012061\n",
      "2013-12-17  0.009786\n",
      "2013-12-18  0.007873\n",
      "2013-12-19  0.012947\n",
      "Length of Training data (1725, 1)\n",
      "Length of Testing data (370, 1)\n",
      "Length of Validation data (370, 1)\n",
      "Shape of dataset is features (1675, 50, 1) and targets (1675, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "-------------Preparing LSTM Model----------------\n",
      "========================Summary of lstm==========================\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_52 (LSTM)              (None, 50, 50)            10400     \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 50, 50)            0         \n",
      "                                                                 \n",
      " lstm_53 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 32)                1632      \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32265 (126.04 KB)\n",
      "Trainable params: 32265 (126.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the lstm Model====================\n",
      "Epoch 1/100\n",
      "53/53 - 8s - loss: 0.1586 - val_loss: 0.4771 - 8s/epoch - 152ms/step\n",
      "Epoch 2/100\n",
      "53/53 - 3s - loss: 0.0665 - val_loss: 0.0568 - 3s/epoch - 52ms/step\n",
      "Epoch 3/100\n",
      "53/53 - 3s - loss: 0.0391 - val_loss: 0.0308 - 3s/epoch - 50ms/step\n",
      "Epoch 4/100\n",
      "53/53 - 3s - loss: 0.0361 - val_loss: 0.0304 - 3s/epoch - 50ms/step\n",
      "Epoch 5/100\n",
      "53/53 - 3s - loss: 0.0342 - val_loss: 0.0286 - 3s/epoch - 55ms/step\n",
      "Epoch 6/100\n",
      "53/53 - 3s - loss: 0.0341 - val_loss: 0.0615 - 3s/epoch - 51ms/step\n",
      "Epoch 7/100\n",
      "53/53 - 3s - loss: 0.0340 - val_loss: 0.0305 - 3s/epoch - 52ms/step\n",
      "Epoch 8/100\n",
      "53/53 - 3s - loss: 0.0330 - val_loss: 0.0369 - 3s/epoch - 49ms/step\n",
      "Epoch 9/100\n",
      "53/53 - 3s - loss: 0.0316 - val_loss: 0.0263 - 3s/epoch - 55ms/step\n",
      "Epoch 10/100\n",
      "53/53 - 3s - loss: 0.0330 - val_loss: 0.0298 - 3s/epoch - 51ms/step\n",
      "Epoch 11/100\n",
      "53/53 - 3s - loss: 0.0322 - val_loss: 0.0326 - 3s/epoch - 54ms/step\n",
      "Epoch 12/100\n",
      "53/53 - 3s - loss: 0.0334 - val_loss: 0.0348 - 3s/epoch - 57ms/step\n",
      "Epoch 13/100\n",
      "53/53 - 3s - loss: 0.0322 - val_loss: 0.0280 - 3s/epoch - 57ms/step\n",
      "Epoch 14/100\n",
      "53/53 - 3s - loss: 0.0318 - val_loss: 0.0248 - 3s/epoch - 58ms/step\n",
      "Epoch 15/100\n",
      "53/53 - 3s - loss: 0.0313 - val_loss: 0.0481 - 3s/epoch - 55ms/step\n",
      "Epoch 16/100\n",
      "53/53 - 3s - loss: 0.0307 - val_loss: 0.0253 - 3s/epoch - 51ms/step\n",
      "Epoch 17/100\n",
      "53/53 - 3s - loss: 0.0297 - val_loss: 0.0248 - 3s/epoch - 54ms/step\n",
      "Epoch 18/100\n",
      "53/53 - 3s - loss: 0.0305 - val_loss: 0.0340 - 3s/epoch - 53ms/step\n",
      "Epoch 19/100\n",
      "53/53 - 3s - loss: 0.0292 - val_loss: 0.0566 - 3s/epoch - 55ms/step\n",
      "Epoch 20/100\n",
      "53/53 - 3s - loss: 0.0302 - val_loss: 0.0289 - 3s/epoch - 53ms/step\n",
      "Epoch 21/100\n",
      "53/53 - 3s - loss: 0.0305 - val_loss: 0.0437 - 3s/epoch - 52ms/step\n",
      "Epoch 22/100\n",
      "53/53 - 3s - loss: 0.0292 - val_loss: 0.0342 - 3s/epoch - 50ms/step\n",
      "Epoch 23/100\n",
      "53/53 - 3s - loss: 0.0302 - val_loss: 0.0451 - 3s/epoch - 51ms/step\n",
      "Epoch 24/100\n",
      "53/53 - 3s - loss: 0.0289 - val_loss: 0.0463 - 3s/epoch - 53ms/step\n",
      "Epoch 25/100\n",
      "53/53 - 3s - loss: 0.0292 - val_loss: 0.0306 - 3s/epoch - 54ms/step\n",
      "Epoch 26/100\n",
      "53/53 - 3s - loss: 0.0297 - val_loss: 0.0270 - 3s/epoch - 50ms/step\n",
      "Epoch 27/100\n",
      "53/53 - 3s - loss: 0.0278 - val_loss: 0.0456 - 3s/epoch - 54ms/step\n",
      "Epoch 28/100\n",
      "53/53 - 3s - loss: 0.0286 - val_loss: 0.0471 - 3s/epoch - 54ms/step\n",
      "Epoch 29/100\n",
      "53/53 - 3s - loss: 0.0282 - val_loss: 0.0572 - 3s/epoch - 54ms/step\n",
      "Epoch 30/100\n",
      "53/53 - 3s - loss: 0.0284 - val_loss: 0.0421 - 3s/epoch - 53ms/step\n",
      "Epoch 31/100\n",
      "53/53 - 3s - loss: 0.0282 - val_loss: 0.0659 - 3s/epoch - 49ms/step\n",
      "Epoch 32/100\n",
      "53/53 - 3s - loss: 0.0278 - val_loss: 0.0468 - 3s/epoch - 50ms/step\n",
      "Epoch 33/100\n",
      "53/53 - 3s - loss: 0.0282 - val_loss: 0.0464 - 3s/epoch - 51ms/step\n",
      "Epoch 34/100\n",
      "53/53 - 3s - loss: 0.0272 - val_loss: 0.0391 - 3s/epoch - 51ms/step\n",
      "Epoch 35/100\n",
      "53/53 - 3s - loss: 0.0280 - val_loss: 0.0801 - 3s/epoch - 50ms/step\n",
      "Epoch 36/100\n",
      "53/53 - 3s - loss: 0.0286 - val_loss: 0.0537 - 3s/epoch - 50ms/step\n",
      "Epoch 37/100\n",
      "53/53 - 3s - loss: 0.0263 - val_loss: 0.0406 - 3s/epoch - 52ms/step\n",
      "Epoch 38/100\n",
      "53/53 - 3s - loss: 0.0270 - val_loss: 0.0519 - 3s/epoch - 48ms/step\n",
      "Epoch 39/100\n",
      "53/53 - 3s - loss: 0.0283 - val_loss: 0.0706 - 3s/epoch - 51ms/step\n",
      "Epoch 40/100\n",
      "53/53 - 3s - loss: 0.0265 - val_loss: 0.0606 - 3s/epoch - 51ms/step\n",
      "Epoch 41/100\n",
      "53/53 - 3s - loss: 0.0287 - val_loss: 0.0490 - 3s/epoch - 51ms/step\n",
      "Epoch 42/100\n",
      "53/53 - 3s - loss: 0.0277 - val_loss: 0.0834 - 3s/epoch - 52ms/step\n",
      "Epoch 43/100\n",
      "53/53 - 3s - loss: 0.0275 - val_loss: 0.0649 - 3s/epoch - 53ms/step\n",
      "Epoch 44/100\n",
      "53/53 - 3s - loss: 0.0276 - val_loss: 0.0516 - 3s/epoch - 50ms/step\n",
      "Epoch 45/100\n",
      "53/53 - 3s - loss: 0.0271 - val_loss: 0.0799 - 3s/epoch - 52ms/step\n",
      "Epoch 46/100\n",
      "53/53 - 3s - loss: 0.0267 - val_loss: 0.0565 - 3s/epoch - 50ms/step\n",
      "Epoch 47/100\n",
      "53/53 - 3s - loss: 0.0272 - val_loss: 0.0917 - 3s/epoch - 51ms/step\n",
      "Epoch 48/100\n",
      "53/53 - 3s - loss: 0.0275 - val_loss: 0.0376 - 3s/epoch - 51ms/step\n",
      "Epoch 49/100\n",
      "53/53 - 3s - loss: 0.0265 - val_loss: 0.0556 - 3s/epoch - 52ms/step\n",
      "Epoch 50/100\n",
      "53/53 - 3s - loss: 0.0276 - val_loss: 0.0821 - 3s/epoch - 54ms/step\n",
      "Epoch 51/100\n",
      "53/53 - 3s - loss: 0.0258 - val_loss: 0.0346 - 3s/epoch - 53ms/step\n",
      "Epoch 52/100\n",
      "53/53 - 3s - loss: 0.0262 - val_loss: 0.0762 - 3s/epoch - 53ms/step\n",
      "Epoch 53/100\n",
      "53/53 - 2s - loss: 0.0277 - val_loss: 0.0545 - 2s/epoch - 45ms/step\n",
      "Epoch 54/100\n",
      "53/53 - 3s - loss: 0.0266 - val_loss: 0.0375 - 3s/epoch - 55ms/step\n",
      "Epoch 55/100\n",
      "53/53 - 3s - loss: 0.0268 - val_loss: 0.0341 - 3s/epoch - 50ms/step\n",
      "Epoch 56/100\n",
      "53/53 - 3s - loss: 0.0273 - val_loss: 0.0658 - 3s/epoch - 53ms/step\n",
      "Epoch 57/100\n",
      "53/53 - 3s - loss: 0.0268 - val_loss: 0.0706 - 3s/epoch - 52ms/step\n",
      "Epoch 58/100\n",
      "53/53 - 3s - loss: 0.0259 - val_loss: 0.0576 - 3s/epoch - 52ms/step\n",
      "Epoch 59/100\n",
      "53/53 - 3s - loss: 0.0261 - val_loss: 0.0538 - 3s/epoch - 54ms/step\n",
      "Epoch 60/100\n",
      "53/53 - 3s - loss: 0.0257 - val_loss: 0.0748 - 3s/epoch - 51ms/step\n",
      "Epoch 61/100\n",
      "53/53 - 3s - loss: 0.0268 - val_loss: 0.0402 - 3s/epoch - 53ms/step\n",
      "Epoch 62/100\n",
      "53/53 - 3s - loss: 0.0260 - val_loss: 0.0419 - 3s/epoch - 53ms/step\n",
      "Epoch 63/100\n",
      "53/53 - 3s - loss: 0.0260 - val_loss: 0.0655 - 3s/epoch - 53ms/step\n",
      "Epoch 64/100\n",
      "53/53 - 3s - loss: 0.0262 - val_loss: 0.0518 - 3s/epoch - 51ms/step\n",
      "Epoch 65/100\n",
      "53/53 - 3s - loss: 0.0267 - val_loss: 0.0383 - 3s/epoch - 50ms/step\n",
      "Epoch 66/100\n",
      "53/53 - 3s - loss: 0.0269 - val_loss: 0.0605 - 3s/epoch - 51ms/step\n",
      "Epoch 67/100\n",
      "53/53 - 3s - loss: 0.0257 - val_loss: 0.0507 - 3s/epoch - 54ms/step\n",
      "Epoch 68/100\n",
      "53/53 - 3s - loss: 0.0263 - val_loss: 0.0422 - 3s/epoch - 52ms/step\n",
      "Epoch 69/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.0341 - 3s/epoch - 49ms/step\n",
      "Epoch 70/100\n",
      "53/53 - 3s - loss: 0.0256 - val_loss: 0.0443 - 3s/epoch - 53ms/step\n",
      "Epoch 71/100\n",
      "53/53 - 3s - loss: 0.0254 - val_loss: 0.0388 - 3s/epoch - 53ms/step\n",
      "Epoch 72/100\n",
      "53/53 - 3s - loss: 0.0254 - val_loss: 0.0294 - 3s/epoch - 54ms/step\n",
      "Epoch 73/100\n",
      "53/53 - 3s - loss: 0.0262 - val_loss: 0.0280 - 3s/epoch - 50ms/step\n",
      "Epoch 74/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0294 - 3s/epoch - 52ms/step\n",
      "Epoch 75/100\n",
      "53/53 - 3s - loss: 0.0263 - val_loss: 0.0248 - 3s/epoch - 53ms/step\n",
      "Epoch 76/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0421 - 3s/epoch - 51ms/step\n",
      "Epoch 77/100\n",
      "53/53 - 3s - loss: 0.0262 - val_loss: 0.0424 - 3s/epoch - 50ms/step\n",
      "Epoch 78/100\n",
      "53/53 - 3s - loss: 0.0263 - val_loss: 0.0412 - 3s/epoch - 53ms/step\n",
      "Epoch 79/100\n",
      "53/53 - 3s - loss: 0.0261 - val_loss: 0.0327 - 3s/epoch - 54ms/step\n",
      "Epoch 80/100\n",
      "53/53 - 3s - loss: 0.0261 - val_loss: 0.0309 - 3s/epoch - 54ms/step\n",
      "Epoch 81/100\n",
      "53/53 - 3s - loss: 0.0267 - val_loss: 0.0541 - 3s/epoch - 51ms/step\n",
      "Epoch 82/100\n",
      "53/53 - 3s - loss: 0.0254 - val_loss: 0.0450 - 3s/epoch - 49ms/step\n",
      "Epoch 83/100\n",
      "53/53 - 3s - loss: 0.0262 - val_loss: 0.0952 - 3s/epoch - 52ms/step\n",
      "Epoch 84/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0606 - 3s/epoch - 50ms/step\n",
      "Epoch 85/100\n",
      "53/53 - 3s - loss: 0.0256 - val_loss: 0.0504 - 3s/epoch - 52ms/step\n",
      "Epoch 86/100\n",
      "53/53 - 3s - loss: 0.0244 - val_loss: 0.0442 - 3s/epoch - 53ms/step\n",
      "Epoch 87/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0544 - 3s/epoch - 52ms/step\n",
      "Epoch 88/100\n",
      "53/53 - 3s - loss: 0.0252 - val_loss: 0.0465 - 3s/epoch - 50ms/step\n",
      "Epoch 89/100\n",
      "53/53 - 3s - loss: 0.0269 - val_loss: 0.0749 - 3s/epoch - 52ms/step\n",
      "Epoch 90/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0547 - 3s/epoch - 53ms/step\n",
      "Epoch 91/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0319 - 3s/epoch - 53ms/step\n",
      "Epoch 92/100\n",
      "53/53 - 3s - loss: 0.0261 - val_loss: 0.0504 - 3s/epoch - 50ms/step\n",
      "Epoch 93/100\n",
      "53/53 - 3s - loss: 0.0239 - val_loss: 0.0517 - 3s/epoch - 51ms/step\n",
      "Epoch 94/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0587 - 3s/epoch - 51ms/step\n",
      "Epoch 95/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0431 - 3s/epoch - 50ms/step\n",
      "Epoch 96/100\n",
      "53/53 - 3s - loss: 0.0258 - val_loss: 0.0357 - 3s/epoch - 50ms/step\n",
      "Epoch 97/100\n",
      "53/53 - 3s - loss: 0.0258 - val_loss: 0.0467 - 3s/epoch - 51ms/step\n",
      "Epoch 98/100\n",
      "53/53 - 3s - loss: 0.0260 - val_loss: 0.0538 - 3s/epoch - 52ms/step\n",
      "Epoch 99/100\n",
      "53/53 - 3s - loss: 0.0254 - val_loss: 0.0620 - 3s/epoch - 53ms/step\n",
      "Epoch 100/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0403 - 3s/epoch - 51ms/step\n",
      "Evaluating the Performance of lstm Model\n",
      "53/53 [==============================] - 2s 15ms/step\n",
      "10/10 [==============================] - 0s 15ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 94.4364620026568\n",
      "Accuarcy of Testing Data 95.10626241329223\n",
      "Saving the lstm Model\n",
      "shape of the dataset (2467, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                 Close\n",
      "Date                  \n",
      "2013-12-13  428.290222\n",
      "2013-12-16  418.557495\n",
      "2013-12-17  415.659973\n",
      "2013-12-18  425.937531\n",
      "2013-12-19  423.015228\n",
      "Performing MinMaxScaling\n",
      "               Close\n",
      "Date                \n",
      "2013-12-13  0.013114\n",
      "2013-12-16  0.009134\n",
      "2013-12-17  0.007949\n",
      "2013-12-18  0.012152\n",
      "2013-12-19  0.010957\n",
      "Length of Training data (1725, 1)\n",
      "Length of Testing data (370, 1)\n",
      "Length of Validation data (370, 1)\n",
      "Shape of dataset is features (1675, 50, 1) and targets (1675, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "-------------Preparing LSTM Model----------------\n",
      "========================Summary of lstm==========================\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_54 (LSTM)              (None, 50, 50)            10400     \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 50, 50)            0         \n",
      "                                                                 \n",
      " lstm_55 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 32)                1632      \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32265 (126.04 KB)\n",
      "Trainable params: 32265 (126.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the lstm Model====================\n",
      "Epoch 1/100\n",
      "53/53 - 8s - loss: 0.1701 - val_loss: 0.6117 - 8s/epoch - 144ms/step\n",
      "Epoch 2/100\n",
      "53/53 - 3s - loss: 0.0815 - val_loss: 0.0346 - 3s/epoch - 51ms/step\n",
      "Epoch 3/100\n",
      "53/53 - 3s - loss: 0.0349 - val_loss: 0.0437 - 3s/epoch - 49ms/step\n",
      "Epoch 4/100\n",
      "53/53 - 3s - loss: 0.0324 - val_loss: 0.0328 - 3s/epoch - 52ms/step\n",
      "Epoch 5/100\n",
      "53/53 - 3s - loss: 0.0322 - val_loss: 0.0310 - 3s/epoch - 50ms/step\n",
      "Epoch 6/100\n",
      "53/53 - 3s - loss: 0.0319 - val_loss: 0.0310 - 3s/epoch - 59ms/step\n",
      "Epoch 7/100\n",
      "53/53 - 3s - loss: 0.0313 - val_loss: 0.0324 - 3s/epoch - 54ms/step\n",
      "Epoch 8/100\n",
      "53/53 - 3s - loss: 0.0308 - val_loss: 0.0298 - 3s/epoch - 52ms/step\n",
      "Epoch 9/100\n",
      "53/53 - 3s - loss: 0.0297 - val_loss: 0.0316 - 3s/epoch - 52ms/step\n",
      "Epoch 10/100\n",
      "53/53 - 3s - loss: 0.0304 - val_loss: 0.0403 - 3s/epoch - 51ms/step\n",
      "Epoch 11/100\n",
      "53/53 - 3s - loss: 0.0297 - val_loss: 0.0401 - 3s/epoch - 51ms/step\n",
      "Epoch 12/100\n",
      "53/53 - 3s - loss: 0.0291 - val_loss: 0.0349 - 3s/epoch - 52ms/step\n",
      "Epoch 13/100\n",
      "53/53 - 3s - loss: 0.0287 - val_loss: 0.0607 - 3s/epoch - 53ms/step\n",
      "Epoch 14/100\n",
      "53/53 - 3s - loss: 0.0296 - val_loss: 0.0364 - 3s/epoch - 53ms/step\n",
      "Epoch 15/100\n",
      "53/53 - 3s - loss: 0.0297 - val_loss: 0.0251 - 3s/epoch - 51ms/step\n",
      "Epoch 16/100\n",
      "53/53 - 3s - loss: 0.0283 - val_loss: 0.0278 - 3s/epoch - 53ms/step\n",
      "Epoch 17/100\n",
      "53/53 - 3s - loss: 0.0277 - val_loss: 0.0303 - 3s/epoch - 55ms/step\n",
      "Epoch 18/100\n",
      "53/53 - 3s - loss: 0.0279 - val_loss: 0.0489 - 3s/epoch - 47ms/step\n",
      "Epoch 19/100\n",
      "53/53 - 3s - loss: 0.0295 - val_loss: 0.0370 - 3s/epoch - 56ms/step\n",
      "Epoch 20/100\n",
      "53/53 - 3s - loss: 0.0269 - val_loss: 0.0256 - 3s/epoch - 52ms/step\n",
      "Epoch 21/100\n",
      "53/53 - 3s - loss: 0.0285 - val_loss: 0.0402 - 3s/epoch - 55ms/step\n",
      "Epoch 22/100\n",
      "53/53 - 3s - loss: 0.0271 - val_loss: 0.0245 - 3s/epoch - 52ms/step\n",
      "Epoch 23/100\n",
      "53/53 - 3s - loss: 0.0272 - val_loss: 0.0315 - 3s/epoch - 50ms/step\n",
      "Epoch 24/100\n",
      "53/53 - 3s - loss: 0.0285 - val_loss: 0.0279 - 3s/epoch - 54ms/step\n",
      "Epoch 25/100\n",
      "53/53 - 3s - loss: 0.0279 - val_loss: 0.0233 - 3s/epoch - 51ms/step\n",
      "Epoch 26/100\n",
      "53/53 - 3s - loss: 0.0273 - val_loss: 0.0384 - 3s/epoch - 56ms/step\n",
      "Epoch 27/100\n",
      "53/53 - 3s - loss: 0.0267 - val_loss: 0.0233 - 3s/epoch - 52ms/step\n",
      "Epoch 28/100\n",
      "53/53 - 2s - loss: 0.0261 - val_loss: 0.0390 - 2s/epoch - 45ms/step\n",
      "Epoch 29/100\n",
      "53/53 - 3s - loss: 0.0263 - val_loss: 0.0275 - 3s/epoch - 56ms/step\n",
      "Epoch 30/100\n",
      "53/53 - 3s - loss: 0.0262 - val_loss: 0.0560 - 3s/epoch - 55ms/step\n",
      "Epoch 31/100\n",
      "53/53 - 3s - loss: 0.0260 - val_loss: 0.0384 - 3s/epoch - 51ms/step\n",
      "Epoch 32/100\n",
      "53/53 - 3s - loss: 0.0267 - val_loss: 0.0316 - 3s/epoch - 48ms/step\n",
      "Epoch 33/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0309 - 3s/epoch - 57ms/step\n",
      "Epoch 34/100\n",
      "53/53 - 3s - loss: 0.0249 - val_loss: 0.0540 - 3s/epoch - 55ms/step\n",
      "Epoch 35/100\n",
      "53/53 - 3s - loss: 0.0267 - val_loss: 0.0293 - 3s/epoch - 53ms/step\n",
      "Epoch 36/100\n",
      "53/53 - 3s - loss: 0.0264 - val_loss: 0.0359 - 3s/epoch - 51ms/step\n",
      "Epoch 37/100\n",
      "53/53 - 3s - loss: 0.0263 - val_loss: 0.0387 - 3s/epoch - 51ms/step\n",
      "Epoch 38/100\n",
      "53/53 - 3s - loss: 0.0266 - val_loss: 0.0305 - 3s/epoch - 53ms/step\n",
      "Epoch 39/100\n",
      "53/53 - 3s - loss: 0.0263 - val_loss: 0.0691 - 3s/epoch - 53ms/step\n",
      "Epoch 40/100\n",
      "53/53 - 3s - loss: 0.0248 - val_loss: 0.0394 - 3s/epoch - 50ms/step\n",
      "Epoch 41/100\n",
      "53/53 - 3s - loss: 0.0259 - val_loss: 0.0357 - 3s/epoch - 51ms/step\n",
      "Epoch 42/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0391 - 3s/epoch - 54ms/step\n",
      "Epoch 43/100\n",
      "53/53 - 3s - loss: 0.0255 - val_loss: 0.0294 - 3s/epoch - 56ms/step\n",
      "Epoch 44/100\n",
      "53/53 - 3s - loss: 0.0260 - val_loss: 0.0379 - 3s/epoch - 55ms/step\n",
      "Epoch 45/100\n",
      "53/53 - 3s - loss: 0.0244 - val_loss: 0.0694 - 3s/epoch - 53ms/step\n",
      "Epoch 46/100\n",
      "53/53 - 3s - loss: 0.0258 - val_loss: 0.0451 - 3s/epoch - 48ms/step\n",
      "Epoch 47/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0384 - 3s/epoch - 51ms/step\n",
      "Epoch 48/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0563 - 3s/epoch - 52ms/step\n",
      "Epoch 49/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0377 - 3s/epoch - 53ms/step\n",
      "Epoch 50/100\n",
      "53/53 - 3s - loss: 0.0259 - val_loss: 0.0246 - 3s/epoch - 53ms/step\n",
      "Epoch 51/100\n",
      "53/53 - 3s - loss: 0.0249 - val_loss: 0.0690 - 3s/epoch - 52ms/step\n",
      "Epoch 52/100\n",
      "53/53 - 3s - loss: 0.0239 - val_loss: 0.0228 - 3s/epoch - 51ms/step\n",
      "Epoch 53/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0543 - 3s/epoch - 55ms/step\n",
      "Epoch 54/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0274 - 3s/epoch - 54ms/step\n",
      "Epoch 55/100\n",
      "53/53 - 3s - loss: 0.0252 - val_loss: 0.0713 - 3s/epoch - 48ms/step\n",
      "Epoch 56/100\n",
      "53/53 - 3s - loss: 0.0242 - val_loss: 0.0617 - 3s/epoch - 52ms/step\n",
      "Epoch 57/100\n",
      "53/53 - 3s - loss: 0.0239 - val_loss: 0.0555 - 3s/epoch - 52ms/step\n",
      "Epoch 58/100\n",
      "53/53 - 3s - loss: 0.0241 - val_loss: 0.0616 - 3s/epoch - 51ms/step\n",
      "Epoch 59/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0493 - 3s/epoch - 49ms/step\n",
      "Epoch 60/100\n",
      "53/53 - 3s - loss: 0.0245 - val_loss: 0.0607 - 3s/epoch - 56ms/step\n",
      "Epoch 61/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.0500 - 3s/epoch - 53ms/step\n",
      "Epoch 62/100\n",
      "53/53 - 3s - loss: 0.0237 - val_loss: 0.0820 - 3s/epoch - 51ms/step\n",
      "Epoch 63/100\n",
      "53/53 - 3s - loss: 0.0234 - val_loss: 0.0733 - 3s/epoch - 55ms/step\n",
      "Epoch 64/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0261 - 3s/epoch - 55ms/step\n",
      "Epoch 65/100\n",
      "53/53 - 3s - loss: 0.0245 - val_loss: 0.0650 - 3s/epoch - 51ms/step\n",
      "Epoch 66/100\n",
      "53/53 - 3s - loss: 0.0241 - val_loss: 0.0780 - 3s/epoch - 55ms/step\n",
      "Epoch 67/100\n",
      "53/53 - 3s - loss: 0.0245 - val_loss: 0.0860 - 3s/epoch - 53ms/step\n",
      "Epoch 68/100\n",
      "53/53 - 3s - loss: 0.0246 - val_loss: 0.0582 - 3s/epoch - 53ms/step\n",
      "Epoch 69/100\n",
      "53/53 - 3s - loss: 0.0247 - val_loss: 0.0604 - 3s/epoch - 53ms/step\n",
      "Epoch 70/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0338 - 3s/epoch - 52ms/step\n",
      "Epoch 71/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0549 - 3s/epoch - 53ms/step\n",
      "Epoch 72/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0349 - 3s/epoch - 51ms/step\n",
      "Epoch 73/100\n",
      "53/53 - 3s - loss: 0.0232 - val_loss: 0.0304 - 3s/epoch - 53ms/step\n",
      "Epoch 74/100\n",
      "53/53 - 3s - loss: 0.0237 - val_loss: 0.0617 - 3s/epoch - 56ms/step\n",
      "Epoch 75/100\n",
      "53/53 - 3s - loss: 0.0228 - val_loss: 0.0472 - 3s/epoch - 53ms/step\n",
      "Epoch 76/100\n",
      "53/53 - 3s - loss: 0.0242 - val_loss: 0.0736 - 3s/epoch - 52ms/step\n",
      "Epoch 77/100\n",
      "53/53 - 3s - loss: 0.0239 - val_loss: 0.0725 - 3s/epoch - 53ms/step\n",
      "Epoch 78/100\n",
      "53/53 - 3s - loss: 0.0236 - val_loss: 0.0385 - 3s/epoch - 54ms/step\n",
      "Epoch 79/100\n",
      "53/53 - 3s - loss: 0.0242 - val_loss: 0.0448 - 3s/epoch - 55ms/step\n",
      "Epoch 80/100\n",
      "53/53 - 3s - loss: 0.0230 - val_loss: 0.0226 - 3s/epoch - 54ms/step\n",
      "Epoch 81/100\n",
      "53/53 - 3s - loss: 0.0245 - val_loss: 0.0268 - 3s/epoch - 49ms/step\n",
      "Epoch 82/100\n",
      "53/53 - 3s - loss: 0.0246 - val_loss: 0.0479 - 3s/epoch - 54ms/step\n",
      "Epoch 83/100\n",
      "53/53 - 3s - loss: 0.0236 - val_loss: 0.0490 - 3s/epoch - 55ms/step\n",
      "Epoch 84/100\n",
      "53/53 - 3s - loss: 0.0243 - val_loss: 0.0311 - 3s/epoch - 51ms/step\n",
      "Epoch 85/100\n",
      "53/53 - 3s - loss: 0.0236 - val_loss: 0.0527 - 3s/epoch - 50ms/step\n",
      "Epoch 86/100\n",
      "53/53 - 3s - loss: 0.0224 - val_loss: 0.0290 - 3s/epoch - 53ms/step\n",
      "Epoch 87/100\n",
      "53/53 - 3s - loss: 0.0241 - val_loss: 0.0482 - 3s/epoch - 55ms/step\n",
      "Epoch 88/100\n",
      "53/53 - 3s - loss: 0.0241 - val_loss: 0.0350 - 3s/epoch - 54ms/step\n",
      "Epoch 89/100\n",
      "53/53 - 3s - loss: 0.0228 - val_loss: 0.0454 - 3s/epoch - 53ms/step\n",
      "Epoch 90/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0657 - 3s/epoch - 50ms/step\n",
      "Epoch 91/100\n",
      "53/53 - 3s - loss: 0.0246 - val_loss: 0.0364 - 3s/epoch - 55ms/step\n",
      "Epoch 92/100\n",
      "53/53 - 3s - loss: 0.0230 - val_loss: 0.0574 - 3s/epoch - 56ms/step\n",
      "Epoch 93/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0601 - 3s/epoch - 53ms/step\n",
      "Epoch 94/100\n",
      "53/53 - 3s - loss: 0.0225 - val_loss: 0.0496 - 3s/epoch - 51ms/step\n",
      "Epoch 95/100\n",
      "53/53 - 3s - loss: 0.0237 - val_loss: 0.0453 - 3s/epoch - 51ms/step\n",
      "Epoch 96/100\n",
      "53/53 - 3s - loss: 0.0235 - val_loss: 0.0212 - 3s/epoch - 57ms/step\n",
      "Epoch 97/100\n",
      "53/53 - 3s - loss: 0.0233 - val_loss: 0.0585 - 3s/epoch - 52ms/step\n",
      "Epoch 98/100\n",
      "53/53 - 3s - loss: 0.0233 - val_loss: 0.0514 - 3s/epoch - 54ms/step\n",
      "Epoch 99/100\n",
      "53/53 - 3s - loss: 0.0233 - val_loss: 0.0479 - 3s/epoch - 52ms/step\n",
      "Epoch 100/100\n",
      "53/53 - 3s - loss: 0.0238 - val_loss: 0.0360 - 3s/epoch - 48ms/step\n",
      "Evaluating the Performance of lstm Model\n",
      "53/53 [==============================] - 2s 15ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 94.57561789598921\n",
      "Accuarcy of Testing Data 95.5432008538373\n",
      "Saving the lstm Model\n"
     ]
    }
   ],
   "source": [
    "## Building lstm model - open feature\n",
    "build_model(data=reliance_data_url,stock_name='Reliance',features_names=['Open'],model='lstm')\n",
    "## Building lstm model - close feature\n",
    "build_model(data=reliance_data_url,stock_name='Reliance',features_names=['Close'],model='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataset (2467, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                  Open\n",
      "Date                  \n",
      "2013-12-13  429.429443\n",
      "2013-12-16  425.962311\n",
      "2013-12-17  420.365356\n",
      "2013-12-18  415.659973\n",
      "2013-12-19  428.141632\n",
      "Performing MinMaxScaling\n",
      "                Open\n",
      "Date                \n",
      "2013-12-13  0.013471\n",
      "2013-12-16  0.012061\n",
      "2013-12-17  0.009786\n",
      "2013-12-18  0.007873\n",
      "2013-12-19  0.012947\n",
      "Length of Training data (1725, 1)\n",
      "Length of Testing data (370, 1)\n",
      "Length of Validation data (370, 1)\n",
      "Shape of dataset is features (1675, 50, 1) and targets (1675, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "-------------Preparing bidirectional_lSTM Model----------------\n",
      "========================Summary of bidirectional_lstm==========================\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_24 (Bidirect  (None, 50, 128)           33792     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 50, 128)           0         \n",
      "                                                                 \n",
      " bidirectional_25 (Bidirect  (None, 128)               98816     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136769 (534.25 KB)\n",
      "Trainable params: 136769 (534.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the bidirectional_lstm Model====================\n",
      "Epoch 1/100\n",
      "53/53 - 10s - loss: 0.1514 - val_loss: 0.4498 - 10s/epoch - 189ms/step\n",
      "Epoch 2/100\n",
      "53/53 - 3s - loss: 0.0624 - val_loss: 0.1379 - 3s/epoch - 63ms/step\n",
      "Epoch 3/100\n",
      "53/53 - 4s - loss: 0.0377 - val_loss: 0.0413 - 4s/epoch - 67ms/step\n",
      "Epoch 4/100\n",
      "53/53 - 4s - loss: 0.0364 - val_loss: 0.0387 - 4s/epoch - 66ms/step\n",
      "Epoch 5/100\n",
      "53/53 - 4s - loss: 0.0360 - val_loss: 0.0667 - 4s/epoch - 69ms/step\n",
      "Epoch 6/100\n",
      "53/53 - 3s - loss: 0.0327 - val_loss: 0.0368 - 3s/epoch - 65ms/step\n",
      "Epoch 7/100\n",
      "53/53 - 3s - loss: 0.0328 - val_loss: 0.0329 - 3s/epoch - 62ms/step\n",
      "Epoch 8/100\n",
      "53/53 - 3s - loss: 0.0319 - val_loss: 0.0453 - 3s/epoch - 62ms/step\n",
      "Epoch 9/100\n",
      "53/53 - 3s - loss: 0.0315 - val_loss: 0.0307 - 3s/epoch - 63ms/step\n",
      "Epoch 10/100\n",
      "53/53 - 3s - loss: 0.0306 - val_loss: 0.0270 - 3s/epoch - 61ms/step\n",
      "Epoch 11/100\n",
      "53/53 - 3s - loss: 0.0306 - val_loss: 0.0266 - 3s/epoch - 65ms/step\n",
      "Epoch 12/100\n",
      "53/53 - 3s - loss: 0.0297 - val_loss: 0.0280 - 3s/epoch - 63ms/step\n",
      "Epoch 13/100\n",
      "53/53 - 3s - loss: 0.0295 - val_loss: 0.0252 - 3s/epoch - 64ms/step\n",
      "Epoch 14/100\n",
      "53/53 - 3s - loss: 0.0294 - val_loss: 0.0250 - 3s/epoch - 62ms/step\n",
      "Epoch 15/100\n",
      "53/53 - 3s - loss: 0.0293 - val_loss: 0.0246 - 3s/epoch - 63ms/step\n",
      "Epoch 16/100\n",
      "53/53 - 3s - loss: 0.0276 - val_loss: 0.0256 - 3s/epoch - 63ms/step\n",
      "Epoch 17/100\n",
      "53/53 - 3s - loss: 0.0280 - val_loss: 0.0251 - 3s/epoch - 65ms/step\n",
      "Epoch 18/100\n",
      "53/53 - 3s - loss: 0.0291 - val_loss: 0.0238 - 3s/epoch - 63ms/step\n",
      "Epoch 19/100\n",
      "53/53 - 4s - loss: 0.0284 - val_loss: 0.0240 - 4s/epoch - 68ms/step\n",
      "Epoch 20/100\n",
      "53/53 - 3s - loss: 0.0275 - val_loss: 0.0506 - 3s/epoch - 63ms/step\n",
      "Epoch 21/100\n",
      "53/53 - 3s - loss: 0.0271 - val_loss: 0.0241 - 3s/epoch - 63ms/step\n",
      "Epoch 22/100\n",
      "53/53 - 3s - loss: 0.0271 - val_loss: 0.0222 - 3s/epoch - 64ms/step\n",
      "Epoch 23/100\n",
      "53/53 - 3s - loss: 0.0272 - val_loss: 0.0295 - 3s/epoch - 64ms/step\n",
      "Epoch 24/100\n",
      "53/53 - 4s - loss: 0.0271 - val_loss: 0.0277 - 4s/epoch - 74ms/step\n",
      "Epoch 25/100\n",
      "53/53 - 3s - loss: 0.0262 - val_loss: 0.0210 - 3s/epoch - 65ms/step\n",
      "Epoch 26/100\n",
      "53/53 - 3s - loss: 0.0269 - val_loss: 0.0234 - 3s/epoch - 61ms/step\n",
      "Epoch 27/100\n",
      "53/53 - 3s - loss: 0.0269 - val_loss: 0.0319 - 3s/epoch - 61ms/step\n",
      "Epoch 28/100\n",
      "53/53 - 3s - loss: 0.0266 - val_loss: 0.0219 - 3s/epoch - 60ms/step\n",
      "Epoch 29/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0202 - 3s/epoch - 61ms/step\n",
      "Epoch 30/100\n",
      "53/53 - 3s - loss: 0.0255 - val_loss: 0.0262 - 3s/epoch - 59ms/step\n",
      "Epoch 31/100\n",
      "53/53 - 3s - loss: 0.0248 - val_loss: 0.0221 - 3s/epoch - 60ms/step\n",
      "Epoch 32/100\n",
      "53/53 - 3s - loss: 0.0261 - val_loss: 0.0398 - 3s/epoch - 59ms/step\n",
      "Epoch 33/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0187 - 3s/epoch - 60ms/step\n",
      "Epoch 34/100\n",
      "53/53 - 3s - loss: 0.0259 - val_loss: 0.0332 - 3s/epoch - 59ms/step\n",
      "Epoch 35/100\n",
      "53/53 - 3s - loss: 0.0254 - val_loss: 0.0186 - 3s/epoch - 60ms/step\n",
      "Epoch 36/100\n",
      "53/53 - 3s - loss: 0.0252 - val_loss: 0.0213 - 3s/epoch - 59ms/step\n",
      "Epoch 37/100\n",
      "53/53 - 3s - loss: 0.0256 - val_loss: 0.0562 - 3s/epoch - 60ms/step\n",
      "Epoch 38/100\n",
      "53/53 - 3s - loss: 0.0254 - val_loss: 0.0429 - 3s/epoch - 59ms/step\n",
      "Epoch 39/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0475 - 3s/epoch - 59ms/step\n",
      "Epoch 40/100\n",
      "53/53 - 3s - loss: 0.0245 - val_loss: 0.0380 - 3s/epoch - 60ms/step\n",
      "Epoch 41/100\n",
      "53/53 - 3s - loss: 0.0252 - val_loss: 0.0225 - 3s/epoch - 63ms/step\n",
      "Epoch 42/100\n",
      "53/53 - 4s - loss: 0.0250 - val_loss: 0.0179 - 4s/epoch - 70ms/step\n",
      "Epoch 43/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0211 - 3s/epoch - 61ms/step\n",
      "Epoch 44/100\n",
      "53/53 - 3s - loss: 0.0239 - val_loss: 0.0380 - 3s/epoch - 65ms/step\n",
      "Epoch 45/100\n",
      "53/53 - 3s - loss: 0.0251 - val_loss: 0.0212 - 3s/epoch - 64ms/step\n",
      "Epoch 46/100\n",
      "53/53 - 3s - loss: 0.0248 - val_loss: 0.0285 - 3s/epoch - 61ms/step\n",
      "Epoch 47/100\n",
      "53/53 - 4s - loss: 0.0243 - val_loss: 0.0728 - 4s/epoch - 67ms/step\n",
      "Epoch 48/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0308 - 3s/epoch - 63ms/step\n",
      "Epoch 49/100\n",
      "53/53 - 3s - loss: 0.0230 - val_loss: 0.0332 - 3s/epoch - 62ms/step\n",
      "Epoch 50/100\n",
      "53/53 - 3s - loss: 0.0246 - val_loss: 0.0333 - 3s/epoch - 64ms/step\n",
      "Epoch 51/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0354 - 3s/epoch - 63ms/step\n",
      "Epoch 52/100\n",
      "53/53 - 3s - loss: 0.0246 - val_loss: 0.0501 - 3s/epoch - 60ms/step\n",
      "Epoch 53/100\n",
      "53/53 - 3s - loss: 0.0244 - val_loss: 0.0346 - 3s/epoch - 61ms/step\n",
      "Epoch 54/100\n",
      "53/53 - 3s - loss: 0.0235 - val_loss: 0.0425 - 3s/epoch - 63ms/step\n",
      "Epoch 55/100\n",
      "53/53 - 3s - loss: 0.0237 - val_loss: 0.0512 - 3s/epoch - 63ms/step\n",
      "Epoch 56/100\n",
      "53/53 - 3s - loss: 0.0237 - val_loss: 0.0189 - 3s/epoch - 62ms/step\n",
      "Epoch 57/100\n",
      "53/53 - 3s - loss: 0.0228 - val_loss: 0.0323 - 3s/epoch - 62ms/step\n",
      "Epoch 58/100\n",
      "53/53 - 3s - loss: 0.0227 - val_loss: 0.0486 - 3s/epoch - 62ms/step\n",
      "Epoch 59/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0501 - 3s/epoch - 63ms/step\n",
      "Epoch 60/100\n",
      "53/53 - 3s - loss: 0.0239 - val_loss: 0.0387 - 3s/epoch - 62ms/step\n",
      "Epoch 61/100\n",
      "53/53 - 3s - loss: 0.0235 - val_loss: 0.0321 - 3s/epoch - 61ms/step\n",
      "Epoch 62/100\n",
      "53/53 - 3s - loss: 0.0244 - val_loss: 0.0456 - 3s/epoch - 62ms/step\n",
      "Epoch 63/100\n",
      "53/53 - 3s - loss: 0.0225 - val_loss: 0.0174 - 3s/epoch - 62ms/step\n",
      "Epoch 64/100\n",
      "53/53 - 4s - loss: 0.0225 - val_loss: 0.0623 - 4s/epoch - 70ms/step\n",
      "Epoch 65/100\n",
      "53/53 - 4s - loss: 0.0237 - val_loss: 0.0185 - 4s/epoch - 71ms/step\n",
      "Epoch 66/100\n",
      "53/53 - 3s - loss: 0.0233 - val_loss: 0.0319 - 3s/epoch - 63ms/step\n",
      "Epoch 67/100\n",
      "53/53 - 3s - loss: 0.0230 - val_loss: 0.0464 - 3s/epoch - 63ms/step\n",
      "Epoch 68/100\n",
      "53/53 - 3s - loss: 0.0223 - val_loss: 0.0164 - 3s/epoch - 62ms/step\n",
      "Epoch 69/100\n",
      "53/53 - 3s - loss: 0.0231 - val_loss: 0.0426 - 3s/epoch - 61ms/step\n",
      "Epoch 70/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0539 - 3s/epoch - 65ms/step\n",
      "Epoch 71/100\n",
      "53/53 - 4s - loss: 0.0223 - val_loss: 0.0226 - 4s/epoch - 68ms/step\n",
      "Epoch 72/100\n",
      "53/53 - 3s - loss: 0.0225 - val_loss: 0.0680 - 3s/epoch - 65ms/step\n",
      "Epoch 73/100\n",
      "53/53 - 3s - loss: 0.0229 - val_loss: 0.0558 - 3s/epoch - 64ms/step\n",
      "Epoch 74/100\n",
      "53/53 - 3s - loss: 0.0224 - val_loss: 0.0229 - 3s/epoch - 62ms/step\n",
      "Epoch 75/100\n",
      "53/53 - 3s - loss: 0.0234 - val_loss: 0.0348 - 3s/epoch - 62ms/step\n",
      "Epoch 76/100\n",
      "53/53 - 3s - loss: 0.0227 - val_loss: 0.0281 - 3s/epoch - 62ms/step\n",
      "Epoch 77/100\n",
      "53/53 - 3s - loss: 0.0228 - val_loss: 0.0300 - 3s/epoch - 62ms/step\n",
      "Epoch 78/100\n",
      "53/53 - 3s - loss: 0.0228 - val_loss: 0.0401 - 3s/epoch - 62ms/step\n",
      "Epoch 79/100\n",
      "53/53 - 3s - loss: 0.0222 - val_loss: 0.0500 - 3s/epoch - 63ms/step\n",
      "Epoch 80/100\n",
      "53/53 - 3s - loss: 0.0228 - val_loss: 0.0448 - 3s/epoch - 62ms/step\n",
      "Epoch 81/100\n",
      "53/53 - 3s - loss: 0.0215 - val_loss: 0.0500 - 3s/epoch - 61ms/step\n",
      "Epoch 82/100\n",
      "53/53 - 3s - loss: 0.0226 - val_loss: 0.0476 - 3s/epoch - 63ms/step\n",
      "Epoch 83/100\n",
      "53/53 - 4s - loss: 0.0226 - val_loss: 0.0185 - 4s/epoch - 66ms/step\n",
      "Epoch 84/100\n",
      "53/53 - 3s - loss: 0.0227 - val_loss: 0.0371 - 3s/epoch - 65ms/step\n",
      "Epoch 85/100\n",
      "53/53 - 3s - loss: 0.0224 - val_loss: 0.0661 - 3s/epoch - 62ms/step\n",
      "Epoch 86/100\n",
      "53/53 - 3s - loss: 0.0228 - val_loss: 0.0471 - 3s/epoch - 63ms/step\n",
      "Epoch 87/100\n",
      "53/53 - 3s - loss: 0.0216 - val_loss: 0.0488 - 3s/epoch - 61ms/step\n",
      "Epoch 88/100\n",
      "53/53 - 3s - loss: 0.0220 - val_loss: 0.0732 - 3s/epoch - 63ms/step\n",
      "Epoch 89/100\n",
      "53/53 - 3s - loss: 0.0223 - val_loss: 0.0420 - 3s/epoch - 62ms/step\n",
      "Epoch 90/100\n",
      "53/53 - 3s - loss: 0.0229 - val_loss: 0.0514 - 3s/epoch - 62ms/step\n",
      "Epoch 91/100\n",
      "53/53 - 3s - loss: 0.0230 - val_loss: 0.0496 - 3s/epoch - 63ms/step\n",
      "Epoch 92/100\n",
      "53/53 - 3s - loss: 0.0225 - val_loss: 0.0191 - 3s/epoch - 63ms/step\n",
      "Epoch 93/100\n",
      "53/53 - 4s - loss: 0.0220 - val_loss: 0.0580 - 4s/epoch - 69ms/step\n",
      "Epoch 94/100\n",
      "53/53 - 3s - loss: 0.0225 - val_loss: 0.0323 - 3s/epoch - 65ms/step\n",
      "Epoch 95/100\n",
      "53/53 - 4s - loss: 0.0234 - val_loss: 0.0390 - 4s/epoch - 68ms/step\n",
      "Epoch 96/100\n",
      "53/53 - 3s - loss: 0.0216 - val_loss: 0.0524 - 3s/epoch - 63ms/step\n",
      "Epoch 97/100\n",
      "53/53 - 3s - loss: 0.0217 - val_loss: 0.0157 - 3s/epoch - 65ms/step\n",
      "Epoch 98/100\n",
      "53/53 - 3s - loss: 0.0231 - val_loss: 0.0415 - 3s/epoch - 62ms/step\n",
      "Epoch 99/100\n",
      "53/53 - 4s - loss: 0.0221 - val_loss: 0.0327 - 4s/epoch - 71ms/step\n",
      "Epoch 100/100\n",
      "53/53 - 3s - loss: 0.0216 - val_loss: 0.0203 - 3s/epoch - 63ms/step\n",
      "Evaluating the Performance of bidirectional_lstm Model\n",
      "53/53 [==============================] - 2s 19ms/step\n",
      "10/10 [==============================] - 0s 20ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 94.91127417799709\n",
      "Accuarcy of Testing Data 96.86866437652115\n",
      "Saving the bidirectional_lstm Model\n",
      "shape of the dataset (2467, 6)\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n",
      "0\n",
      "Features selected\n",
      "                 Close\n",
      "Date                  \n",
      "2013-12-13  428.290222\n",
      "2013-12-16  418.557495\n",
      "2013-12-17  415.659973\n",
      "2013-12-18  425.937531\n",
      "2013-12-19  423.015228\n",
      "Performing MinMaxScaling\n",
      "               Close\n",
      "Date                \n",
      "2013-12-13  0.013114\n",
      "2013-12-16  0.009134\n",
      "2013-12-17  0.007949\n",
      "2013-12-18  0.012152\n",
      "2013-12-19  0.010957\n",
      "Length of Training data (1725, 1)\n",
      "Length of Testing data (370, 1)\n",
      "Length of Validation data (370, 1)\n",
      "Shape of dataset is features (1675, 50, 1) and targets (1675, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "Shape of dataset is features (320, 50, 1) and targets (320, 1)\n",
      "-------------Preparing bidirectional_lSTM Model----------------\n",
      "========================Summary of bidirectional_lstm==========================\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_26 (Bidirect  (None, 50, 128)           33792     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 50, 128)           0         \n",
      "                                                                 \n",
      " bidirectional_27 (Bidirect  (None, 128)               98816     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136769 (534.25 KB)\n",
      "Trainable params: 136769 (534.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "===============Training the bidirectional_lstm Model====================\n",
      "Epoch 1/100\n",
      "53/53 - 10s - loss: 0.1463 - val_loss: 0.4215 - 10s/epoch - 190ms/step\n",
      "Epoch 2/100\n",
      "53/53 - 3s - loss: 0.0638 - val_loss: 0.1771 - 3s/epoch - 61ms/step\n",
      "Epoch 3/100\n",
      "53/53 - 3s - loss: 0.0360 - val_loss: 0.0956 - 3s/epoch - 64ms/step\n",
      "Epoch 4/100\n",
      "53/53 - 3s - loss: 0.0362 - val_loss: 0.0578 - 3s/epoch - 65ms/step\n",
      "Epoch 5/100\n",
      "53/53 - 3s - loss: 0.0348 - val_loss: 0.0332 - 3s/epoch - 63ms/step\n",
      "Epoch 6/100\n",
      "53/53 - 4s - loss: 0.0340 - val_loss: 0.0352 - 4s/epoch - 68ms/step\n",
      "Epoch 7/100\n",
      "53/53 - 3s - loss: 0.0323 - val_loss: 0.0350 - 3s/epoch - 66ms/step\n",
      "Epoch 8/100\n",
      "53/53 - 3s - loss: 0.0315 - val_loss: 0.0396 - 3s/epoch - 62ms/step\n",
      "Epoch 9/100\n",
      "53/53 - 3s - loss: 0.0315 - val_loss: 0.0491 - 3s/epoch - 63ms/step\n",
      "Epoch 10/100\n",
      "53/53 - 3s - loss: 0.0307 - val_loss: 0.0673 - 3s/epoch - 62ms/step\n",
      "Epoch 11/100\n",
      "53/53 - 3s - loss: 0.0305 - val_loss: 0.0474 - 3s/epoch - 62ms/step\n",
      "Epoch 12/100\n",
      "53/53 - 3s - loss: 0.0309 - val_loss: 0.0325 - 3s/epoch - 61ms/step\n",
      "Epoch 13/100\n",
      "53/53 - 3s - loss: 0.0293 - val_loss: 0.0453 - 3s/epoch - 66ms/step\n",
      "Epoch 14/100\n",
      "53/53 - 3s - loss: 0.0290 - val_loss: 0.0319 - 3s/epoch - 64ms/step\n",
      "Epoch 15/100\n",
      "53/53 - 3s - loss: 0.0291 - val_loss: 0.0265 - 3s/epoch - 66ms/step\n",
      "Epoch 16/100\n",
      "53/53 - 3s - loss: 0.0290 - val_loss: 0.0259 - 3s/epoch - 64ms/step\n",
      "Epoch 17/100\n",
      "53/53 - 3s - loss: 0.0287 - val_loss: 0.0233 - 3s/epoch - 64ms/step\n",
      "Epoch 18/100\n",
      "53/53 - 3s - loss: 0.0272 - val_loss: 0.0251 - 3s/epoch - 63ms/step\n",
      "Epoch 19/100\n",
      "53/53 - 3s - loss: 0.0287 - val_loss: 0.0415 - 3s/epoch - 64ms/step\n",
      "Epoch 20/100\n",
      "53/53 - 3s - loss: 0.0275 - val_loss: 0.0332 - 3s/epoch - 64ms/step\n",
      "Epoch 21/100\n",
      "53/53 - 3s - loss: 0.0270 - val_loss: 0.0214 - 3s/epoch - 63ms/step\n",
      "Epoch 22/100\n",
      "53/53 - 3s - loss: 0.0264 - val_loss: 0.0216 - 3s/epoch - 63ms/step\n",
      "Epoch 23/100\n",
      "53/53 - 3s - loss: 0.0298 - val_loss: 0.0213 - 3s/epoch - 63ms/step\n",
      "Epoch 24/100\n",
      "53/53 - 3s - loss: 0.0266 - val_loss: 0.0237 - 3s/epoch - 65ms/step\n",
      "Epoch 25/100\n",
      "53/53 - 3s - loss: 0.0263 - val_loss: 0.0208 - 3s/epoch - 61ms/step\n",
      "Epoch 26/100\n",
      "53/53 - 3s - loss: 0.0260 - val_loss: 0.0204 - 3s/epoch - 63ms/step\n",
      "Epoch 27/100\n",
      "53/53 - 3s - loss: 0.0260 - val_loss: 0.0203 - 3s/epoch - 63ms/step\n",
      "Epoch 28/100\n",
      "53/53 - 3s - loss: 0.0257 - val_loss: 0.0257 - 3s/epoch - 62ms/step\n",
      "Epoch 29/100\n",
      "53/53 - 3s - loss: 0.0260 - val_loss: 0.0202 - 3s/epoch - 63ms/step\n",
      "Epoch 30/100\n",
      "53/53 - 3s - loss: 0.0263 - val_loss: 0.0199 - 3s/epoch - 63ms/step\n",
      "Epoch 31/100\n",
      "53/53 - 3s - loss: 0.0259 - val_loss: 0.0359 - 3s/epoch - 61ms/step\n",
      "Epoch 32/100\n",
      "53/53 - 3s - loss: 0.0254 - val_loss: 0.0490 - 3s/epoch - 63ms/step\n",
      "Epoch 33/100\n",
      "53/53 - 3s - loss: 0.0260 - val_loss: 0.0209 - 3s/epoch - 65ms/step\n",
      "Epoch 34/100\n",
      "53/53 - 3s - loss: 0.0249 - val_loss: 0.0306 - 3s/epoch - 61ms/step\n",
      "Epoch 35/100\n",
      "53/53 - 3s - loss: 0.0247 - val_loss: 0.0290 - 3s/epoch - 63ms/step\n",
      "Epoch 36/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0344 - 3s/epoch - 64ms/step\n",
      "Epoch 37/100\n",
      "53/53 - 3s - loss: 0.0245 - val_loss: 0.0468 - 3s/epoch - 63ms/step\n",
      "Epoch 38/100\n",
      "53/53 - 3s - loss: 0.0264 - val_loss: 0.0245 - 3s/epoch - 64ms/step\n",
      "Epoch 39/100\n",
      "53/53 - 3s - loss: 0.0241 - val_loss: 0.0234 - 3s/epoch - 65ms/step\n",
      "Epoch 40/100\n",
      "53/53 - 3s - loss: 0.0252 - val_loss: 0.0183 - 3s/epoch - 63ms/step\n",
      "Epoch 41/100\n",
      "53/53 - 3s - loss: 0.0253 - val_loss: 0.0182 - 3s/epoch - 64ms/step\n",
      "Epoch 42/100\n",
      "53/53 - 3s - loss: 0.0240 - val_loss: 0.0245 - 3s/epoch - 65ms/step\n",
      "Epoch 43/100\n",
      "53/53 - 3s - loss: 0.0233 - val_loss: 0.0204 - 3s/epoch - 63ms/step\n",
      "Epoch 44/100\n",
      "53/53 - 3s - loss: 0.0250 - val_loss: 0.0271 - 3s/epoch - 62ms/step\n",
      "Epoch 45/100\n",
      "53/53 - 3s - loss: 0.0242 - val_loss: 0.0189 - 3s/epoch - 61ms/step\n",
      "Epoch 46/100\n",
      "53/53 - 3s - loss: 0.0247 - val_loss: 0.0317 - 3s/epoch - 62ms/step\n",
      "Epoch 47/100\n",
      "53/53 - 3s - loss: 0.0236 - val_loss: 0.0281 - 3s/epoch - 63ms/step\n",
      "Epoch 48/100\n",
      "53/53 - 3s - loss: 0.0229 - val_loss: 0.0242 - 3s/epoch - 63ms/step\n",
      "Epoch 49/100\n",
      "53/53 - 3s - loss: 0.0235 - val_loss: 0.0485 - 3s/epoch - 61ms/step\n",
      "Epoch 50/100\n",
      "53/53 - 3s - loss: 0.0235 - val_loss: 0.0202 - 3s/epoch - 64ms/step\n",
      "Epoch 51/100\n",
      "53/53 - 3s - loss: 0.0236 - val_loss: 0.0390 - 3s/epoch - 65ms/step\n",
      "Epoch 52/100\n",
      "53/53 - 3s - loss: 0.0243 - val_loss: 0.0672 - 3s/epoch - 62ms/step\n",
      "Epoch 53/100\n",
      "53/53 - 3s - loss: 0.0225 - val_loss: 0.0262 - 3s/epoch - 62ms/step\n",
      "Epoch 54/100\n",
      "53/53 - 3s - loss: 0.0236 - val_loss: 0.0244 - 3s/epoch - 63ms/step\n",
      "Epoch 55/100\n",
      "53/53 - 3s - loss: 0.0233 - val_loss: 0.0528 - 3s/epoch - 61ms/step\n",
      "Epoch 56/100\n",
      "53/53 - 3s - loss: 0.0239 - val_loss: 0.0284 - 3s/epoch - 62ms/step\n",
      "Epoch 57/100\n",
      "53/53 - 3s - loss: 0.0235 - val_loss: 0.0334 - 3s/epoch - 62ms/step\n",
      "Epoch 58/100\n",
      "53/53 - 3s - loss: 0.0237 - val_loss: 0.0216 - 3s/epoch - 66ms/step\n",
      "Epoch 59/100\n",
      "53/53 - 4s - loss: 0.0235 - val_loss: 0.0170 - 4s/epoch - 67ms/step\n",
      "Epoch 60/100\n",
      "53/53 - 4s - loss: 0.0228 - val_loss: 0.0531 - 4s/epoch - 69ms/step\n",
      "Epoch 61/100\n",
      "53/53 - 4s - loss: 0.0232 - val_loss: 0.0253 - 4s/epoch - 67ms/step\n",
      "Epoch 62/100\n",
      "53/53 - 4s - loss: 0.0220 - val_loss: 0.0454 - 4s/epoch - 70ms/step\n",
      "Epoch 63/100\n",
      "53/53 - 4s - loss: 0.0226 - val_loss: 0.0440 - 4s/epoch - 70ms/step\n",
      "Epoch 64/100\n",
      "53/53 - 4s - loss: 0.0223 - val_loss: 0.0251 - 4s/epoch - 71ms/step\n",
      "Epoch 65/100\n",
      "53/53 - 3s - loss: 0.0244 - val_loss: 0.0316 - 3s/epoch - 64ms/step\n",
      "Epoch 66/100\n",
      "53/53 - 4s - loss: 0.0235 - val_loss: 0.0328 - 4s/epoch - 70ms/step\n",
      "Epoch 67/100\n",
      "53/53 - 4s - loss: 0.0225 - val_loss: 0.0180 - 4s/epoch - 71ms/step\n",
      "Epoch 68/100\n",
      "53/53 - 4s - loss: 0.0228 - val_loss: 0.0387 - 4s/epoch - 67ms/step\n",
      "Epoch 69/100\n",
      "53/53 - 3s - loss: 0.0224 - val_loss: 0.0725 - 3s/epoch - 65ms/step\n",
      "Epoch 70/100\n",
      "53/53 - 3s - loss: 0.0226 - val_loss: 0.0224 - 3s/epoch - 65ms/step\n",
      "Epoch 71/100\n",
      "53/53 - 3s - loss: 0.0226 - val_loss: 0.0387 - 3s/epoch - 62ms/step\n",
      "Epoch 72/100\n",
      "53/53 - 3s - loss: 0.0224 - val_loss: 0.0171 - 3s/epoch - 62ms/step\n",
      "Epoch 73/100\n",
      "53/53 - 3s - loss: 0.0227 - val_loss: 0.0347 - 3s/epoch - 63ms/step\n",
      "Epoch 74/100\n",
      "53/53 - 3s - loss: 0.0229 - val_loss: 0.0171 - 3s/epoch - 63ms/step\n",
      "Epoch 75/100\n",
      "53/53 - 3s - loss: 0.0224 - val_loss: 0.0612 - 3s/epoch - 63ms/step\n",
      "Epoch 76/100\n",
      "53/53 - 3s - loss: 0.0221 - val_loss: 0.0399 - 3s/epoch - 64ms/step\n",
      "Epoch 77/100\n",
      "53/53 - 4s - loss: 0.0224 - val_loss: 0.0196 - 4s/epoch - 68ms/step\n",
      "Epoch 78/100\n",
      "53/53 - 3s - loss: 0.0214 - val_loss: 0.0403 - 3s/epoch - 64ms/step\n",
      "Epoch 79/100\n",
      "53/53 - 3s - loss: 0.0223 - val_loss: 0.0252 - 3s/epoch - 63ms/step\n",
      "Epoch 80/100\n",
      "53/53 - 3s - loss: 0.0217 - val_loss: 0.0342 - 3s/epoch - 62ms/step\n",
      "Epoch 81/100\n",
      "53/53 - 3s - loss: 0.0218 - val_loss: 0.0372 - 3s/epoch - 64ms/step\n",
      "Epoch 82/100\n",
      "53/53 - 4s - loss: 0.0219 - val_loss: 0.0180 - 4s/epoch - 67ms/step\n",
      "Epoch 83/100\n",
      "53/53 - 3s - loss: 0.0218 - val_loss: 0.0384 - 3s/epoch - 65ms/step\n",
      "Epoch 84/100\n",
      "53/53 - 4s - loss: 0.0220 - val_loss: 0.0235 - 4s/epoch - 70ms/step\n",
      "Epoch 85/100\n",
      "53/53 - 4s - loss: 0.0217 - val_loss: 0.0212 - 4s/epoch - 73ms/step\n",
      "Epoch 86/100\n",
      "53/53 - 4s - loss: 0.0213 - val_loss: 0.0403 - 4s/epoch - 71ms/step\n",
      "Epoch 87/100\n",
      "53/53 - 4s - loss: 0.0225 - val_loss: 0.0486 - 4s/epoch - 67ms/step\n",
      "Epoch 88/100\n",
      "53/53 - 3s - loss: 0.0234 - val_loss: 0.0233 - 3s/epoch - 65ms/step\n",
      "Epoch 89/100\n",
      "53/53 - 3s - loss: 0.0224 - val_loss: 0.0307 - 3s/epoch - 62ms/step\n",
      "Epoch 90/100\n",
      "53/53 - 3s - loss: 0.0213 - val_loss: 0.0369 - 3s/epoch - 63ms/step\n",
      "Epoch 91/100\n",
      "53/53 - 3s - loss: 0.0225 - val_loss: 0.0573 - 3s/epoch - 65ms/step\n",
      "Epoch 92/100\n",
      "53/53 - 4s - loss: 0.0221 - val_loss: 0.0168 - 4s/epoch - 68ms/step\n",
      "Epoch 93/100\n",
      "53/53 - 3s - loss: 0.0219 - val_loss: 0.0355 - 3s/epoch - 65ms/step\n",
      "Epoch 94/100\n",
      "53/53 - 3s - loss: 0.0219 - val_loss: 0.0162 - 3s/epoch - 66ms/step\n",
      "Epoch 95/100\n",
      "53/53 - 3s - loss: 0.0221 - val_loss: 0.0338 - 3s/epoch - 63ms/step\n",
      "Epoch 96/100\n",
      "53/53 - 3s - loss: 0.0231 - val_loss: 0.0550 - 3s/epoch - 64ms/step\n",
      "Epoch 97/100\n",
      "53/53 - 3s - loss: 0.0231 - val_loss: 0.0162 - 3s/epoch - 63ms/step\n",
      "Epoch 98/100\n",
      "53/53 - 3s - loss: 0.0224 - val_loss: 0.0437 - 3s/epoch - 65ms/step\n",
      "Epoch 99/100\n",
      "53/53 - 4s - loss: 0.0214 - val_loss: 0.0346 - 4s/epoch - 72ms/step\n",
      "Epoch 100/100\n",
      "53/53 - 4s - loss: 0.0214 - val_loss: 0.0219 - 4s/epoch - 67ms/step\n",
      "Evaluating the Performance of bidirectional_lstm Model\n",
      "53/53 [==============================] - 2s 21ms/step\n",
      "10/10 [==============================] - 0s 21ms/step\n",
      "Metrics used is <function mean_absolute_error at 0x0000024A018BE8B0>\n",
      "Accuracy of Training Data 95.11048446417051\n",
      "Accuarcy of Testing Data 96.74724945917887\n",
      "Saving the bidirectional_lstm Model\n"
     ]
    }
   ],
   "source": [
    "## Building Bidirectional_lstm model - open feature\n",
    "build_model(data=reliance_data_url,stock_name='Reliance',features_names=['Open'],model='bidirectional_lstm')\n",
    "## Building Bidirectional_lstm model - close feature\n",
    "build_model(data=reliance_data_url,stock_name='Reliance',features_names=['Close'],model='bidirectional_lstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function To Predict Stocks Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_todays_trend(model_name,stock_name,feature_name):\n",
    "\n",
    "    ticker_symbol=stock_name\n",
    "\n",
    "    # Get today's date\n",
    "    today_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    end_date=datetime.now()-timedelta(days=1)\n",
    "    ## fetch atleast 100 rows\n",
    "    start_date=(datetime.today() - timedelta(days=100)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    ## fetch data from yfinance\n",
    "    historical_data = yf.download(ticker_symbol, start=start_date, end=end_date)\n",
    "    print(historical_data[feature_name].tail(5))\n",
    "    # Load your trained LSTM model\n",
    "    model = load_model(model_name) \n",
    "    # print(data.tail)\n",
    "    last_n_days = 50\n",
    "    \n",
    "    # Extract the last n days of data for prediction\n",
    "    n_days_data = historical_data[feature_name].values[-last_n_days:].reshape(-1,1)\n",
    "    # Scale the data using the same scaler used during training\n",
    "    scaler=MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(n_days_data)\n",
    "    \n",
    "    # Reshape the data to match the input shape of the LSTM model\n",
    "    scaled = scaled.reshape((1, last_n_days, 1))\n",
    "\n",
    "    # Make the prediction\n",
    "    predicted_price = model.predict(scaled)\n",
    "    print(predicted_price.shape)\n",
    "    # Inverse transform the predicted price to get the actual predicted stock price\n",
    "    predicted_price = scaler.inverse_transform(predicted_price)[0][0]\n",
    "    # Get yesterday's stock price\n",
    "    print(\"Today's predicted price\",predicted_price)\n",
    "    yesterday_price = historical_data[feature_name].iloc[-1]\n",
    "    print(\"Yesterdays Price\",yesterday_price)\n",
    "    # Determine if the predicted price is up or down compared to yesterday\n",
    "    price_change = \"Up\" if predicted_price > yesterday_price else \"Down\"\n",
    "    \n",
    "\n",
    "    # Display whether the stock price is up or down\n",
    "    print(f\"For {today_date}, the predicted stock price for {stock_name} is {price_change} compared to yesterday.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Advanced Projects\\\\Stock-Price-Prediction\\\\Notebook'"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Advanced Projects\\Stock-Price-Prediction\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Date\n",
      "2023-12-07    845.549988\n",
      "2023-12-08    872.000000\n",
      "2023-12-11    859.900024\n",
      "2023-12-12    852.650024\n",
      "2023-12-13    854.900024\n",
      "Name: Open, dtype: float64\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "(1, 1)\n",
      "Today's predicted price 848.282\n",
      "Yesterdays Price 854.9000244140625\n",
      "For 2023-12-14, the predicted stock price for VOLTAS.NS is Down compared to yesterday.\n"
     ]
    }
   ],
   "source": [
    "predict_todays_trend(model_name='Models/Voltas_bidirectional_lstm_Open.h5',stock_name='VOLTAS.NS',feature_name='Open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Date\n",
      "2023-12-07    4140.049805\n",
      "2023-12-08    4155.950195\n",
      "2023-12-11    4070.649902\n",
      "2023-12-12    4080.899902\n",
      "2023-12-13    4075.000000\n",
      "Name: Open, dtype: float64\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "(1, 1)\n",
      "Today's predicted price 4009.3806\n",
      "Yesterdays Price 4075.0\n",
      "For 2023-12-14, the predicted stock price for DMART.NS is Down compared to yesterday.\n"
     ]
    }
   ],
   "source": [
    "predict_todays_trend(model_name='Models/Dmart_bidirectional_lstm_Open.h5',stock_name='DMART.NS',feature_name='Open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Date\n",
      "2023-12-07    20932.400391\n",
      "2023-12-08    20934.099609\n",
      "2023-12-11    20965.300781\n",
      "2023-12-12    21018.550781\n",
      "2023-12-13    20929.750000\n",
      "Name: Open, dtype: float64\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "(1, 1)\n",
      "Today's predicted price 20779.35\n",
      "Yesterdays Price 20929.75\n",
      "For 2023-12-14, the predicted stock price for ^NSEI is Down compared to yesterday.\n"
     ]
    }
   ],
   "source": [
    "predict_todays_trend(model_name='Models/Nifyt50_bidirectional_lstm_Open.h5',stock_name='^NSEI',feature_name='Open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Date\n",
      "2023-12-07    2460.000000\n",
      "2023-12-08    2463.850098\n",
      "2023-12-11    2456.000000\n",
      "2023-12-12    2460.000000\n",
      "2023-12-13    2422.000000\n",
      "Name: Open, dtype: float64\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "(1, 1)\n",
      "Today's predicted price 2444.7366\n",
      "Yesterdays Price 2422.0\n",
      "For 2023-12-14, the predicted stock price for RELIANCE.NS is Up compared to yesterday.\n"
     ]
    }
   ],
   "source": [
    "predict_todays_trend(model_name='Models/Reliance_bidirectional_lstm_Open.h5',stock_name='RELIANCE.NS',feature_name='Open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1912819,
     "sourceId": 3141205,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
